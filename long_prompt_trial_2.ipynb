{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ceef088-5d0a-40c0-a776-a109c20f1cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (0.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /abr/coss45/.local/lib/python3.8/site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from llama-cpp-python) (1.24.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /abr/coss45/.local/lib/python3.8/site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /abr/coss45/.local/lib/python3.8/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8f0b4b-1c77-4853-908c-29501a78b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger(\"llama_cpp\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9d9d60-c519-45f2-864e-399335b478ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 629\u001b[0m\n\u001b[1;32m     17\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mOverview\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124mYou are an AI assistant designed for a coffee kiosk. Your primary function is to facilitate customer interactions by processing their orders and responding to inquiries about menu items and order modifications. Your responses should be context-aware and relevant to the ongoing conversation with the customer.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;124m### Response:\u001b[39m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;66;03m# Generate a response\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m response_text \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# Structure the output as a dictionary\u001b[39;00m\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/llama_cpp/llama.py:1900\u001b[0m, in \u001b[0;36mLlama.__call__\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1838\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1862\u001b[0m     logit_bias: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1863\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[CreateCompletionResponse, Iterator[CreateCompletionStreamResponse]]:\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate text from a prompt.\u001b[39;00m\n\u001b[1;32m   1865\u001b[0m \n\u001b[1;32m   1866\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;124;03m        Response object containing the generated text.\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mecho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/llama_cpp/llama.py:1833\u001b[0m, in \u001b[0;36mLlama.create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1831\u001b[0m     chunks: Iterator[CreateCompletionStreamResponse] \u001b[38;5;241m=\u001b[39m completion_or_chunks\n\u001b[1;32m   1832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n\u001b[0;32m-> 1833\u001b[0m completion: Completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcompletion_or_chunks\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/llama_cpp/llama.py:1318\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1316\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1317\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m   1319\u001b[0m     prompt_tokens,\n\u001b[1;32m   1320\u001b[0m     top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m   1321\u001b[0m     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m   1322\u001b[0m     min_p\u001b[38;5;241m=\u001b[39mmin_p,\n\u001b[1;32m   1323\u001b[0m     typical_p\u001b[38;5;241m=\u001b[39mtypical_p,\n\u001b[1;32m   1324\u001b[0m     temp\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m   1325\u001b[0m     tfs_z\u001b[38;5;241m=\u001b[39mtfs_z,\n\u001b[1;32m   1326\u001b[0m     mirostat_mode\u001b[38;5;241m=\u001b[39mmirostat_mode,\n\u001b[1;32m   1327\u001b[0m     mirostat_tau\u001b[38;5;241m=\u001b[39mmirostat_tau,\n\u001b[1;32m   1328\u001b[0m     mirostat_eta\u001b[38;5;241m=\u001b[39mmirostat_eta,\n\u001b[1;32m   1329\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39mfrequency_penalty,\n\u001b[1;32m   1330\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39mpresence_penalty,\n\u001b[1;32m   1331\u001b[0m     repeat_penalty\u001b[38;5;241m=\u001b[39mrepeat_penalty,\n\u001b[1;32m   1332\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[1;32m   1333\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[1;32m   1334\u001b[0m     grammar\u001b[38;5;241m=\u001b[39mgrammar,\n\u001b[1;32m   1335\u001b[0m ):\n\u001b[1;32m   1336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llama_cpp\u001b[38;5;241m.\u001b[39mllama_token_is_eog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mmodel, token):\n\u001b[1;32m   1337\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetokenize(completion_tokens, prev_tokens\u001b[38;5;241m=\u001b[39mprompt_tokens)\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/llama_cpp/llama.py:910\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tokens:\n\u001b[1;32m    912\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    913\u001b[0m             top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    914\u001b[0m             top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    928\u001b[0m             idx\u001b[38;5;241m=\u001b[39msample_idx,\n\u001b[1;32m    929\u001b[0m         )\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/llama_cpp/llama.py:643\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    639\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[1;32m    641\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[1;32m    642\u001b[0m )\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/llama_cpp/_internals.py:300\u001b[0m, in \u001b[0;36mLlamaContext.decode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: LlamaBatch):\n\u001b[0;32m--> 300\u001b[0m     return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "from IPython.utils import io\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# Define the model path\n",
    "model_path = \"models/llama-3-Korean-Bllossom-8B-Q4_K_M.gguf\"\n",
    "\n",
    "# Suppress output during model loading\n",
    "with io.capture_output() as captured:\n",
    "    model = Llama(\n",
    "        model_path=model_path,\n",
    "        n_ctx=8192,\n",
    "        n_gpu_layers=20\n",
    "    )\n",
    "\n",
    "# Define your prompt directly as a string\n",
    "prompt = \"\"\"\n",
    "Overview\n",
    "You are an AI assistant designed for a coffee kiosk. Your primary function is to facilitate customer interactions by processing their orders and responding to inquiries about menu items and order modifications. Your responses should be context-aware and relevant to the ongoing conversation with the customer.\n",
    "\n",
    "Key Responsibilities\n",
    "Order Processing: Accurately process customer requests to add, update, remove, or cancel items in their order.\n",
    "Contextual Awareness: Maintain an understanding of the current order and previous customer inputs to generate relevant responses.\n",
    "Clarification and Recommendations: When user input is ambiguous, provide clarifying questions or recommendations based on the context.\n",
    "Current Order Details\n",
    "The current order may contain one or more drinks, each with attributes such as:\n",
    "\n",
    "Always Hot Drinks\n",
    "허브티 (Herbal Tea)\n",
    "Temperature: [핫 (Hot) Only]\n",
    "Add-ons: None\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "\n",
    "Always Iced Drinks\n",
    "토마토주스 (Tomato Juice)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: None\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "키위주스 (Kiwi Juice)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: None\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "망고스무디 (Mango Smoothie)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: [휘핑크림 (Whipped Cream)]\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "딸기스무디 (Strawberry Smoothie)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: [휘핑크림 (Whipped Cream)]\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "레몬에이드 (Lemonade)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: None\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "복숭아아이스티 (Peach Iced Tea)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: [샷 추가 (Extra Shot)]\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "쿠키앤크림 (Cookies and Cream)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: [휘핑크림 (Whipped Cream)]\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "\n",
    "Hot and Iced Drinks\n",
    "카페라떼 (Cafe Latte)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "아메리카노 (Americano)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "카푸치노 (Cappuccino)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "에스프레소 (Espresso)\n",
    "Available Sizes: [미디움 (Medium)]\n",
    "Temperatures: [핫 (Hot) Only]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "카라멜마끼아또 (Caramel Macchiato)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "바닐라라떼 (Vanilla Latte)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "말차라떼 (Matcha Latte)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "아포카토 (Affogato)\n",
    "Available Sizes: [미디움 (Medium)]\n",
    "Temperatures: [아이스 (Iced) Only]\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "초콜릿라떼 (Chocolate Latte)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "카페모카 (Cafe Mocha)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "\n",
    "\n",
    "Extra Options\n",
    "샷 (Shots): Add an extra shot to the drink.\n",
    "카라멜시럽 (Caramel Syrup): Add caramel syrup for extra sweetness.\n",
    "바닐라시럽 (Vanilla Syrup): Add vanilla syrup for flavor.\n",
    "휘핑크림 (Whipped Cream): Add whipped cream as a topping. \n",
    "Add-ons for Hot and Iced Drinks: [샷 추가 (Extra Shot), 바닐라시럽 (Vanilla Syrup), 휘핑크림 (Whipped Cream),카라멜시럽 (Caramel Syrup)]\n",
    "\n",
    "Available Sizes\n",
    "미디움 (Medium)\n",
    "라즈 (Large) \n",
    "엑스라즈 (Extra Large)\n",
    "\n",
    "Example of Current Order\n",
    "Index 0: 핫 아메리카노 미디움 1잔\n",
    "Index 1: 핫 카푸치노 미디움 2잔\n",
    "Previous Customer Inputs\n",
    "You should consider the history of customer inputs when generating responses. This allows you to reference past interactions and understand the customer's preferences or ongoing requests.\n",
    "\n",
    "Instruction with Expanded Cases for Each Action Type\n",
    "add_item Action\n",
    "Description: Used to add a new item to the order. The \"details\" field should include the drink name, size, temperature, quantity, and any add-ons requested by the customer.\n",
    "\n",
    "Example Input: \"아메리카노 핫으로 미디움 사이즈 한 잔 주세요.\"\n",
    "Current Order Details: No items in the order.\n",
    "Previous Customer Inputs: None.\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"add_item\",\n",
    "    \"details\": {\n",
    "        \"drink\": \"아메리카노\",\n",
    "        \"size\": \"미디움\",\n",
    "        \"temperature\": \"핫\",\n",
    "        \"quantity\": 1,\n",
    "        \"add_ons\": {}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "remove_item Action\n",
    "Description: Used to remove a specific item from the order. Specify the \"index\" of the drink to remove in the \"details\" field.\n",
    "\n",
    "Example Input: \"카푸치노를 삭제해 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 카푸치노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"카푸치노 한 잔 주세요.\"\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"remove_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0\n",
    "    }\n",
    "}\n",
    "    ]\n",
    "}\n",
    "update_item Action\n",
    "The update_item action is used to modify specific details of an existing item in the order. When constructing an update_item action, include the \"index\" field and only the attributes that need modification.\n",
    "Drink update \n",
    "Example Input: \"아메리카노를 라즈로 바꿔 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 아이스 아메리카노 미디움 1잔\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아이스 아메리카노 한 잔 미디움 사이즈로 주세요.\"\n",
    "Expected Action:\n",
    "{\n",
    "        \"actions\": [\n",
    "            {\n",
    "                \"type\": \"update_item\",\n",
    "                \"details\": {\n",
    "                    \"index\": 0,\n",
    "                    \"drink\": \"카페라떼\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "Size Update\n",
    "Example Input: \"아메리카노를 라즈로 바꿔 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Expected Action:\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"update_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0,\n",
    "        \"size\": \"라즈\"\n",
    "    }\n",
    "}\n",
    "    ]\n",
    "}\n",
    "Temperature Update\n",
    "Example Input: \"카푸치노를 아이스로 해 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 카푸치노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"카푸치노 한 잔 주세요.\"\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"update_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0,\n",
    "        \"temperature\": \"아이스\"\n",
    "    }\n",
    "}\n",
    "    ]\n",
    "}\n",
    "Quantity Update\n",
    "Example Input: \"아메리카노 두 잔 중 하나만 변경해 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 2잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 두 잔 주세요.\"\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"update_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0,\n",
    "        \"quantity\": 1\n",
    "    }\n",
    "}\n",
    "    ]\n",
    "}\n",
    "Add-Ons Update\n",
    "Used to add or remove specific add-ons for a drink. Use \"add_ons\" as a key in the \"details\" field to specify add-ons as key-value pairs.\n",
    "\n",
    "Adding an Add-On\n",
    "Example Input: \"아메리카노에 휘필 크림을 추가해 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"update_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0,\n",
    "        \"add_ons\": {\n",
    "            \"휘핑크림\": 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "    ]\n",
    "}\n",
    "Removing an Add-On\n",
    "Example Input: \"아메리카노에서 샷을 빼 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔 (샷: 1).\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노에 샷 추가해서 주세요.\"\n",
    "Expected Action:\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"update_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0,\n",
    "        \"add_ons\": {\n",
    "        }\n",
    "    }\n",
    "}\n",
    "]\n",
    "}\n",
    "cancel_order Action Example\n",
    "Description: This action is used to completely clear the current order. No additional details are required in the \"details\" field, as the entire order will be canceled.\n",
    "\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Index 1: 아이스 카푸치노 라지 2잔 (샷: 1).\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Input 1: \"카푸치노 두 잔 아이스로 주세요, 샷 하나 추가해 주세요.\"\n",
    "Input: \"주문을 취소해 주세요.\"\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"cancel_order\",\n",
    "    \"details\": {}\n",
    "}\n",
    "    ]\n",
    "}\n",
    "Multiple Attributes Update\n",
    "If a customer requests multiple updates (e.g., changing the size and adding an add-on), include all modified attributes in the \"details\" field.\n",
    "\n",
    "Example Input: \"아메리카노를 라즈 사이즈로 바꾸고 샷을 추가해 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"update_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0,\n",
    "        \"size\": \"라즈\",\n",
    "        \"add_ons\": {\n",
    "            \"샷\": 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "    ]\n",
    "}\n",
    "Partial Modifications within a Batch of Identical Items\n",
    "For requests to modify only part of a batch (e.g., out of three identical items, change one or two), adjust the quantity of the original item and add new items for any modified parts.\n",
    "\n",
    "Example Input: \"아메리카노 세 잔 중 두 잔에만 샷을 추가해 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 3잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 세 잔 주세요.\"\n",
    "Expected Actions:\n",
    "\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"type\": \"update_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 0,\n",
    "                \"quantity\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"아메리카노\",\n",
    "                \"size\": \"미디움\",\n",
    "                \"temperature\": \"핫\",\n",
    "                \"quantity\": 2,\n",
    "                \"add_ons\": {\n",
    "                    \"샷\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "Partial Modifications within a Batch of Identical Items Example\n",
    "Description: When the customer wants only part of a batch of identical items modified, adjust the quantity of the original item and add a new item with the requested modifications.\n",
    "\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 3잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 세 잔 주세요.\"\n",
    "Input: \"아메리카노 세 잔 중 두 잔에만 샷을 추가해 주세요.\"\n",
    "Expected Actions:\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"type\": \"update_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 0,\n",
    "                \"quantity\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"아메리카노\",\n",
    "                \"size\": \"미디움\",\n",
    "                \"temperature\": \"핫\",\n",
    "                \"quantity\": 2,\n",
    "                \"add_ons\": {\n",
    "                    \"샷\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    }\n",
    "Expected Response Types\n",
    "Make sure that you only respond in JSON output type. And you are only responding to the input. No explanation is needed.\n",
    "when you are responding please make sure that what are the current index values in the #Instructions first check what drinks are there with which index values and then when you are returning the index value  make sure it is correct indexes in the cases where returning index value is required.\n",
    "Action Confirmation: If an action is taken (e.g., item added, updated, or removed), provide a confirmation message directly related to that action. This confirmation should be generated by your backend, not LLaMA.\n",
    "Clarification for Ambiguity: In cases where the user input creates ambiguity (e.g., asking to change an order without specifying which drink), respond with a clarifying question.\n",
    "No Response for Valid Actions: For cases where the customer requests multiple actions that can be executed, provide only the actions without any additional responses.\n",
    "Handling Multiple Requests\n",
    "When customers make multiple requests in a single input, your model should identify and process each request appropriately. Each request can lead to a separate action or a clarification request.\n",
    "\n",
    "Guidelines for Multiple Requests\n",
    "Identify Separate Actions: If multiple actions are present, generate a separate action for each distinct request.\n",
    "Handle Ambiguities: If an input includes multiple requests but some of the requested actions are ambiguous, for clear requests first take actions and for the ambigous requests add 'response' asking the customer for further details regarding their request.\n",
    "Handling Multiple Requests Example\n",
    "Description: When customers make multiple requests in a single input, identify and process each request separately. Include each request as a distinct action or ask a clarifying question if the input is ambiguous.\n",
    "\n",
    "Example 1\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Index 1: 핫 카푸치노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Input 1: \"카푸치노 한 잔 주세요.\"\n",
    "Input: \"아메리카노를 아이스로 바꾸고, 카푸치노는 삭제해 주세요.\"\n",
    "Expected Actions:\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"type\": \"update_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 0,\n",
    "                \"temperature\": \"아이스\"\n",
    "            },\n",
    "            {\n",
    "            \"type\": \"remove_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 1\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "Example 2\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Index 1: 핫 카푸치노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Input 1: \"카푸치노 한 잔 주세요.\"\n",
    "Input: \"모든 음료를 삭제하고, 아메리카노 1잔 추가해 주세요.\"\n",
    "Expected Actions:\n",
    "\n",
    "\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"type\": \"remove_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 0\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"remove_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"아메리카노\",\n",
    "                \"size\": \"미디움\",\n",
    "                \"temperature\": \"핫\",\n",
    "                \"quantity\": 1,\n",
    "                \"add_ons\": {}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "Example 3 with Ambiguity(when you are not sure how or which actions should be taken you create \"response\" to confirm or learn details for customer.\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Index 1: 핫 카푸치노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Input 1: \"카푸치노 한 잔 주세요.\"\n",
    "Input: \"사이즈를 변경하고, 카푸치노를 삭제해 주세요.\"\n",
    "Expected Actions:\n",
    "{\n",
    "        \"actions\": [],\n",
    "        \"response\": \"어떤 음료의 사이즈를 변경하시겠습니까?\"\"\n",
    "    }\n",
    "\n",
    "Handling Complex Partial Modifications\n",
    "When handling customer requests that specify different modifications for multiple quantities within a single item (e.g., “아메리카노 다섯 개 중 하나는 바닐라, 하나는 라떼로 변경해줘”), follow these guidelines:\n",
    "Refined Prompt Instructions\n",
    "When handling partial modifications on items with multiple quantities, follow these steps closely:\n",
    "\n",
    "Adjust the Quantity in the Original Item: When a user requests that only part of a batch of identical items be modified, do not use remove_item. Instead, reduce the quantity of the original item to reflect the remaining unmodified items.\n",
    "\n",
    "Create Separate Actions for Each Modification:\n",
    "\n",
    "Use add_item to add a new entry for each modified part. Each new entry should reflect the requested changes in add-ons, size, or drink type while maintaining the original details for unchanged parts.\n",
    "Avoid using empty add_ons fields unless no add-ons were mentioned.\n",
    "Generate Clear and Direct Responses: Provide a natural language response summarizing the changes in detail. Do not ask follow-up questions unless there is genuine ambiguity (e.g., the customer did not specify which drink to modify).\n",
    "\n",
    "Check the Total Quantity: If a customer specifies different modifications for parts of the total quantity of an item, first adjust the quantity of the original item to reflect only the unchanged items.\n",
    "\n",
    "Split Modifications into New Actions:\n",
    "\n",
    "For each specified change, create a new add_item entry in the actions, reflecting the requested modifications (e.g., add-ons, temperature, or drink type changes).\n",
    "Each new entry should match the details of the original item, but with the specified modifications applied.\n",
    "Use these examples as a reference for similar cases:\n",
    "\n",
    "Example 1 with Histories\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 3잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 3잔 주세요.\"\n",
    "Input: \"아메리카노 3잔 중 1잔은 샷 추가, 1잔은 아이스로 변경해 주세요.\"\n",
    "Expected JSON Response:\n",
    "\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"type\": \"update_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 0,\n",
    "                \"quantity\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"아메리카노\",\n",
    "                \"size\": \"미디움\",\n",
    "                \"temperature\": \"핫\",\n",
    "                \"quantity\": 1,\n",
    "                \"add_ons\": {\n",
    "                    \"샷\": 1\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"아메리카노\",\n",
    "                \"size\": \"미디움\",\n",
    "                \"temperature\": \"아이스\",\n",
    "                \"quantity\": 1,\n",
    "                \"add_ons\": {}\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "  }\n",
    "Example 2 \n",
    "Current Order Details:\n",
    "Index 1: 핫 라떼 미디움 4잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"라떼 미디움 4잔 주세요.\"\n",
    "Input: \"라떼 4잔 중 2잔은 엑스트라 라지로 하고, 나머지 1잔은 바닐라 시럽을 넣어 주세요.\"\n",
    "Expected JSON Response:\n",
    "\n",
    "\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"type\": \"update_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 1,\n",
    "                \"quantity\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"라떼\",\n",
    "                \"size\": \"엑스라즈\",\n",
    "                \"temperature\": \"핫\",\n",
    "                \"quantity\": 2,\n",
    "                \"add_ons\": {}\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"라떼\",\n",
    "                \"size\": \"미디움\",\n",
    "                \"temperature\": \"핫\",\n",
    "                \"quantity\": 1,\n",
    "                \"add_ons\": {\n",
    "                    \"바닐라시럽\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "Example 3\n",
    "Current Order Details:\n",
    "Index 1: 핫 에스프레소 미디움 2잔\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"에스프레소 두 잔 미디움 사이즈로 핫으로 주세요.\"\n",
    "Input: \"한 잔은 아메리카노로 변경하고 다른 한 잔은 샷 추가해 주세요.\"\n",
    "{\n",
    "        \"actions\": [\n",
    "            {\n",
    "                \"type\": \"update_item\",\n",
    "                \"details\": {\n",
    "                    \"index\": 0,\n",
    "                    \"quantity\": 1,\n",
    "                    \"drink\": \"아메리카노\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"add_item\",\n",
    "                \"details\": {\n",
    "                    \"drink\": \"에스프레소\",\n",
    "                    \"size\": \"미디움\",\n",
    "                    \"temperature\": \"핫\",\n",
    "                    \"quantity\": 1,\n",
    "                    \"add_ons\": {\n",
    "                        \"샷 추가\": 1\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "}\n",
    "### Instruction:\n",
    "When\n",
    "Current Order Details:\n",
    "None\n",
    "Previous customer inputs:\n",
    "None\n",
    "What would be the response in JSON format for the input provided.\n",
    "### Input:\n",
    "라떼 두 잔 부탁드려요.\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "# Generate a response\n",
    "output = model(prompt, max_tokens=300)\n",
    "response_text = output[\"choices\"][0][\"text\"]\n",
    "\n",
    "# Structure the output as a dictionary\n",
    "output_data = {\n",
    "    \"response\": response_text\n",
    "}\n",
    "\n",
    "# Save the output as a JSON file\n",
    "with open(\"output.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(output_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Output saved to output.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5312bf4-055f-4ab5-8598-a5f77c808545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
