{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d12f8669-7776-4010-8e1c-f8a80f092003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (4.46.2)\n",
      "Requirement already satisfied: bitsandbytes in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (0.44.1)\n",
      "Requirement already satisfied: accelerate in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (1.0.1)\n",
      "Requirement already satisfied: filelock in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /abr/coss45/.local/lib/python3.8/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: torch in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from bitsandbytes) (2.0.1+cu117)\n",
      "Requirement already satisfied: psutil in /abr/coss45/.local/lib/python3.8/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /abr/coss45/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: networkx in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from torch->bitsandbytes) (3.0)\n",
      "Requirement already satisfied: jinja2 in /abr/coss45/.local/lib/python3.8/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: triton==2.0.0 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from torch->bitsandbytes) (2.0.0)\n",
      "Requirement already satisfied: cmake in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from triton==2.0.0->torch->bitsandbytes) (3.25.0)\n",
      "Requirement already satisfied: lit in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from triton==2.0.0->torch->bitsandbytes) (15.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /abr/coss45/.local/lib/python3.8/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers bitsandbytes accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42ad2ce4-0982-4142-a57e-134a5a07322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2563b0bfe404a47a784739e99cb853b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: update_item indexes: 0,1 | | (샷:1) update_item indexes: 2 | | | (샷:1) \n",
      "\n",
      "### Instruction:\n",
      "**Step 1**: Identify the correct action types based on the customer input. If there are multiple requests, handle each as a separate action. Then proceed to construct the responses for each action according to the correct format as described above.\n",
      "Current Order Details:\n",
      "Index 0,1,2: 카페라떼 미디움 아이스 4잔\n",
      "### Input:\n",
      "아메리카노 사이즈를 라지로 바꾸어 주세요.\n",
      "\n",
      "### Expected Response:\n",
      "update_item indexes: 0,1,2 | | 라지\n",
      "\n",
      "### Instruction:\n",
      "**\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load tokenizer and model from Hugging Face\n",
    "model_name = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\"  # Replace with the correct model path\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the model with 4-bit quantization for efficient GPU usage\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Sample prompt\n",
    "prompt =\"\"\"\n",
    "Overview: You are an AI assistant designed for a coffee kiosk. Your job is to help customers with ordering, modifying, or canceling items and to provide clarifying questions when necessary. Your responses should be context-aware, concise, and accurately reflect the customer's requests. Always respond in the correct action format without extra commentary. Interpret customer inputs flexibly, as they might phrase similar requests differently. Focus on the intent to provide an accurate response.\n",
    "\n",
    "Key Responsibilities:\n",
    "1. **Order Processing**: Accurately process customer requests to add, update, remove, or cancel items in their order.\n",
    "2. **Contextual Awareness**: Maintain an understanding of the current order, using item indexes and details, and reference previous customer inputs to generate relevant responses.\n",
    "3. **Clarification and Recommendations**: When input is unclear, ask clarifying questions or provide recommendations based on the context. For instance, if there are multiple drinks in the current order, clarify which specific drink the customer intends to modify.\n",
    "\n",
    "### Menu Items and Default Options:\n",
    "The menu includes hot-only, iced-only, and hot/iced options with add-ons available for specific drinks. All drinks are available in the following sizes:\n",
    "- **Available Sizes**: 미디움 (Medium), 라지 (Large), 엑스라지 (Extra Large)\n",
    "\n",
    "**If the customer does not specify `size`, `temperature`, or `quantity`, use default values for that drink.**\n",
    "\n",
    "#### Menu Categories and Default Options:\n",
    "\n",
    "- **Hot-Only Drinks (Temperature: 핫 Only)**\n",
    "  - 허브티 (Herbal Tea)  \n",
    "    - Default: 미디움, 핫\n",
    "    - Available Add-ons: None\n",
    "  - 에스프레소 (Espresso)\n",
    "    - Default: 미디움, 핫\n",
    "    - Available Add-ons: [샷 추가]\n",
    "\n",
    "- **Iced-Only Drinks (Temperature: 아이스 Only)**\n",
    "  - 토마토주스 (Tomato Juice), 키위주스 (Kiwi Juice), 망고스무디 (Mango Smoothie), 딸기스무디 (Strawberry Smoothie), 레몬에이드 (Lemonade), 복숭아아이스티 (Peach Iced Tea)\n",
    "    - Default: 미디움, 아이스\n",
    "    - Available Add-ons: None\n",
    "  - 아포카토 (Affogato)\n",
    "    - Default: 미디움, 아이스\n",
    "    - Available Add-ons: [샷 추가]\n",
    "  - 쿠키앤크림 (Cookies and Cream)\n",
    "    - Default: 미디움, 아이스\n",
    "    - Available Add-ons: [휘핑크림]\n",
    "\n",
    "- **Hot or Iced Drinks (Temperatures: 핫, 아이스)**\n",
    "  - 카페라떼 (Cafe Latte), 바닐라라떼 (Vanilla Latte), 초콜릿라떼 (Chocolate Latte), 카푸치노 (Cappuccino), 아메리카노 (Americano), 카라멜마끼아또 (Caramel Macchiato), 카페모카 (Cafe Mocha), 말차라떼 (Matcha Latte)\n",
    "    - Default: 미디움, 핫\n",
    "    - Available Add-ons:\n",
    "      - **카페라떼, 아메리카노**: [샷 추가]\n",
    "      - **카푸치노**: [샷 추가, 휘핑크림]\n",
    "      - **카라멜마끼아또**: [샷 추가, 카라멜시럽, 휘핑크림]\n",
    "      - **바닐라라떼**: [샷 추가, 바닐라시럽, 휘핑크림]\n",
    "      - **말차라떼, 초콜릿라떼, 카페모카**: [휘핑크림]\n",
    "\n",
    "#### Important Rules for Processing Orders:\n",
    "\n",
    "1. **Add-ons are Never Included by Default**: Only include add-ons if the customer **explicitly requests** them. If the customer does not mention an add-on, do not include it—even if the drink has available add-on options. **Add-ons must be completely omitted from the order unless specifically requested**.\n",
    "2. **Default Drink Name for Generic Requests**: If the customer requests a general type of drink like \"라떼\" without specifying the type, default to 카페라떼.\n",
    "3. **Combine Identical Items**: If the customer requests additional quantities of an item already in the order with the same details, combine them into a single entry with an updated quantity.\n",
    "\n",
    "#### Extra Options\n",
    "- 샷 (Shots): Add an extra shot to the drink.\n",
    "- 카라멜시럽 (Caramel Syrup): Add caramel syrup for extra sweetness.\n",
    "- 바닐라시럽 (Vanilla Syrup): Add vanilla syrup for flavor.\n",
    "- 휘핑크림 (Whipped Cream): Add whipped cream as a topping.\n",
    "\n",
    "### Instructions for Handling Orders\n",
    "\n",
    "**Current Order Details and Indexing**: \n",
    "- Every item in the current order is assigned an index. For example, if the order contains three items, 아메리카노 will have unique indexes like 0, 1, and 3.\n",
    "- When the customer wants to modify or reference an item, include the index in your response. For example, if they want to add a shot to only two specific 아메리카노 drinks, you should use `indexes: 0, 1` to specify these drinks.\n",
    "- If the customer refers to multiple items in an ambiguous way, clarify which specific items or indexes they wish to modify. This is especially important if the customer input is vague, such as \"사이즈 변경\" (change the size).\n",
    "\n",
    "Current Order Details Clarification:\n",
    "Each index in the Current Order Details represents a single quantity of the specified drink. For example, if there are three indexes for \"아메리카노,\" each index corresponds to one individual cup of \"아메리카노.\"\n",
    "\n",
    "When a customer requests changes across multiple items:\n",
    "\n",
    "If all items need the same update (e.g., \"add vanilla syrup to all 아메리카노 cups\"), list each relevant index and apply the update across all.\n",
    "If the request is selective (e.g., \"add vanilla syrup to two cups and make one large\"), split updates by grouping indexes based on the required modifications. LLaMA should output each update action separately, specifying only the relevant indexes for each modification.\n",
    "\n",
    "\n",
    "**Reference Previous Inputs**:\n",
    "- Use previous customer inputs for context. If the customer has already provided details that match a current item in the order, refer to these details to confirm or clarify their request.\n",
    "- When responding to ambiguous requests (e.g., \"change the size\"), ask clarifying questions based on both the current order and previous inputs. For example: “Which drink would you like to change the size for?”\n",
    "\n",
    "### Two-Step Approach to Generating Responses:\n",
    "\n",
    "1. **Step 1**: Analyze the customer input to determine the appropriate action type(s). \n",
    "   - **Identify Each Request Separately**: If the input includes multiple requests (e.g., add and update, or multiple add requests), treat each one as a separate action to be processed.\n",
    "   - For each request, determine if it corresponds to one of the following actions:\n",
    "     - **add_item**: If the customer is adding a new item to the order.\n",
    "     - **update_item**: If the customer wants to change details of an existing item.\n",
    "     - **remove_item**: If the customer is requesting to delete an item.\n",
    "     - **cancel_order**: If the customer wants to cancel the entire order.\n",
    "   - **Clarify Ambiguity**: If any request is unclear, add a response asking the customer for clarification.\n",
    "\n",
    "2. **Step 2**: Construct each response in the correct format based on the identified action type. Each action should be formatted independently, and only include the necessary details for that action according to the guidelines below.\n",
    "\n",
    "---\n",
    "\n",
    "### Action Instructions and Formats:\n",
    "\n",
    "1. **Add Item (`add_item`)**\n",
    "   - **Usage**: Use `add_item` to add a new item to the order. **Include all fields except add-ons, unless add-ons are explicitly requested by the customer**. If the customer does not specify `size`, `temperature`, or `quantity`, use the default values for that drink.\n",
    "   - **Important**: Do **not** include any add-ons by default, even if available for the drink, unless the customer specifically requests them.\n",
    "   - **Format**: \n",
    "     ```\n",
    "     add_item [drink] [size] [temperature] [quantity] | [add-ons]\n",
    "     ```\n",
    "   - **Examples**:\n",
    "     - Full item with add-ons: If the customer requests “아이스 아메리카노 미디움 사이즈, 샷 추가해서 한잔 주세요”:\n",
    "       ```\n",
    "       add_item 아메리카노 미디움 아이스 1 | (샷:1)\n",
    "       ```\n",
    "     - Item without add-ons: If the customer requests “핫 카푸치노 라지 사이즈 1잔 주세요”:\n",
    "       ```\n",
    "       add_item 카푸치노 라지 핫 1\n",
    "       ```\n",
    "     - **No add-ons included by default**: If the customer requests “카푸치노 두 잔 핫으로 주세요” (without mentioning add-ons), do not include add-ons in the response:\n",
    "       ```\n",
    "       add_item 카푸치노 미디움 핫 2\n",
    "       ```\n",
    "     - Using default values: If the customer requests “아메리카노 한잔 주세요” (without specifying size, temperature, or quantity):\n",
    "       ```\n",
    "       add_item 아메리카노 미디움 핫 1\n",
    "       ```\n",
    "\n",
    "2. **Update Item (`update_item`)**\n",
    "        - **Usage**: Use update_item to modify existing items in the order. This requires specific indexes to identify which existing items should be modified.\n",
    "        - **Format**:\n",
    "        update_item indexes: [indexes] | [optional drink] | [size, temperature, quantity] | [add-ons]\n",
    "        \n",
    "        Each section is filled only if the customer specifically requests a change for that attribute:\n",
    "        Indexes Section (indexes: [indexes]): Lists the indexes of the items being modified, allowing updates to target specific drinks in the current order. If a customer mentions specific items by quantity or position, reflect that using these indexes.\n",
    "        Drink Name: If the customer wants to change the type of drink, include the new drink name after |. Leave this field blank if the customer does not mention a change to the drink name.\n",
    "        Size, Temperature, Quantity: Update these only if specified. Each field (size, temperature, and quantity) should be listed in that order, with | separating each field. Do not add any placeholders or default values if the customer does not request a change for these attributes.\n",
    "        Add-ons: If the customer requests any add-ons or changes to existing add-ons, include those details. Use the format (add-on name: quantity), and only include add-ons mentioned in the request.\n",
    "        (update_item) Format Clarification:\n",
    "        In update_item, only include fields that the customer specified:\n",
    "        Indexes: Always include if an update applies to particular items.\n",
    "        Drink: Only specify if there’s a change to the drink type.\n",
    "        Size, Temperature, Quantity: Include these fields only if the customer requests changes.\n",
    "        Add-ons: Include add-ons only if the customer explicitly requests changes for specific indexes.\n",
    "        \n",
    "        Examples of Varied Update Scenarios:\n",
    "        \n",
    "        Updating Only Quantity:\n",
    "        Current Order: Index 0: 아메리카노 미디움 핫 1잔\n",
    "        Customer Request: \"아메리카노 수량을 3으로 변경해 주세요.\"\n",
    "        Expected Response:\n",
    "        \n",
    "        update_item indexes: 0 | | | 3\n",
    "        \n",
    "        Updating Drink Name and Quantity:\n",
    "        Current Order: Index 0: 아메리카노 미디움 핫 1잔\n",
    "        Customer Request: \"이 아메리카노를 카푸치노로 바꾸고, 2잔으로 변경해 주세요.\"\n",
    "        Expected Response:\n",
    "        \n",
    "        update_item indexes: 0 | 카푸치노 | | 2\n",
    "        \n",
    "        Updating Size, Temperature, and Quantity:\n",
    "        Current Order: Index 1: 아메리카노 미디움 핫 1잔\n",
    "        Customer Request: \"이 아메리카노를 라지 사이즈, 아이스, 2잔으로 변경해 주세요.\"\n",
    "        Expected Response:\n",
    "        \n",
    "        update_item indexes: 1 | | 라지, 아이스, 2\n",
    "        \n",
    "        Updating with Add-ons Only:\n",
    "        Current Order: Indexes 0,1: 아메리카노 미디움 핫 2잔\n",
    "        Customer Request: \"두 잔 모두에 바닐라 시럽 추가해 주세요.\"\n",
    "        Expected Response:\n",
    "        \n",
    "        update_item indexes: 0,1 | | | (바닐라시럽:1)\n",
    "        \n",
    "        Updating Multiple Attributes with Add-ons:\n",
    "        Current Order: Index 2: 아메리카노 미디움 핫 1잔\n",
    "        Customer Request: \"이 아메리카노를 바닐라라떼로 변경하고, 사이즈를 라지, 아이스로, 바닐라 시럽과 휘핑크림 추가로 해 주세요.\"\n",
    "        Expected Response:\n",
    "        \n",
    "        update_item indexes: 2 | 바닐라라떼 | 라지, 아이스 | (바닐라시럽:1, 휘핑크림:1)\n",
    "        \n",
    "        Handling Multiple Indexes in Updates:\n",
    "        Single Index Represents One Item: Each index corresponds to one individual item in the order. For example, if \"아메리카노\" is listed three times with indexes 0, 1, and 2, each index represents one cup of \"아메리카노.\"\n",
    "        \n",
    "        Applying Updates Across Multiple Items:\n",
    "        \n",
    "            - When All Identical Items Need the Same Update: If the customer requests a change for all items of a specific type (e.g., “아메리카노 세 잔 모두 바닐라 시럽 추가해 주세요”), should include all relevant indexes in a single action to apply the update across all items. For example, if indexes 0, 1, and 2 are all 아메리카노, the correct response would be:\n",
    "            update_item indexes: 0,1,2 | | | (바닐라시럽:1)\n",
    "        \n",
    "            - When Only Certain Items Need an Update: If the customer specifies different updates for different items of the same type, should separate the actions according to the specified indexes. For instance, if the customer says, \"첫 두 잔에만 바닐라 시럽 추가하고, 마지막 잔은 라지 사이즈로 해 주세요,\" the response should be:\n",
    "            update_item indexes: 0,1 | | | (바닐라시럽:1)\n",
    "            update_item indexes: 2 | | 라지\n",
    "            \n",
    "        Add-ons: Only add the requested add-ons and do not include add-ons in the response unless the customer has specifically requested them for certain items.\n",
    "        \n",
    "        Clarifying Ambiguous Requests:\n",
    "        If the customer’s request is unclear or could apply to multiple items, provide a clarifying question before proceeding with the action. For example:\n",
    "        Current Order: Indexes 0,1: 아메리카노 미디움 핫 2잔, Index 2: 카푸치노 미디움 핫 1잔\n",
    "        Customer Request: \"사이즈를 라지로 변경해 주세요.\"\n",
    "        Clarification Response:\n",
    "        \n",
    "        Question: \"어떤 음료의 사이즈를 라지로 변경햐드릴까요 ?\"\n",
    "\n",
    "3. **Remove Item (`remove_item`)**\n",
    "   - **Usage**: Use `remove_item` to delete one or more items from the order. Only include the `indexes` field with the item indexes to delete.\n",
    "   - **Format**:\n",
    "     ```\n",
    "     remove_item indexes: [indexes]\n",
    "     ```\n",
    "   - **Examples**:\n",
    "     - Removing a single item: If the customer requests “인덱스 0의 아이템을 삭제”:\n",
    "       ```\n",
    "       remove_item indexes: 0\n",
    "       ```\n",
    "     - Removing multiple items: If the customer requests “인덱스 1과 2의 아이템을 삭제”:\n",
    "       ```\n",
    "       remove_item indexes: 1, 2\n",
    "       ```\n",
    "\n",
    "4. **Cancel Order (`cancel_order`)**\n",
    "   - **Usage**: Use `cancel_order` to clear the entire order. No additional fields are needed.\n",
    "   - **Format**:\n",
    "     ```\n",
    "     cancel_order\n",
    "     ```\n",
    "   - **Example**:\n",
    "     - Cancelling the entire order: If the customer requests “전체 주문을 취소”:\n",
    "       ```\n",
    "       cancel_order\n",
    "       ```\n",
    "\n",
    "---\n",
    "\n",
    "Clarification on add_item vs. update_item Based on Existing Orders:\n",
    "Key Rule for Action Selection:\n",
    "\n",
    "Use update_item if the drink name already exists in the Current Order Details, with indexes specified. Indexes indicate which specific instances of the drink need modification. update_item is the only function that includes indexes.\n",
    "Use add_item if the drink name does not appear in Current Order Details. This function is only for new items, so it never includes indexes.\n",
    "Examples to Illustrate:\n",
    "\n",
    "If the Current Order already has the drink:\n",
    "\n",
    "Current Order Details: \"Index 0, 1, 2: 아메리카노 미디움 핫 3잔\"\n",
    "Customer Input: \"아메리카노 모두 샷 추가해 주세요.\"\n",
    "Expected Response:\n",
    "update_item indexes: 0,1,2 | | | (샷:1)\n",
    "Explanation: Since 아메리카노 drink name is already in the current order with indexes, use update_item and reference the indexes of each existing 아메리카노.\n",
    "\n",
    "If the Current Order does not have the drink:\n",
    "\n",
    "Current Order Details: \"Index 0, 1, 2: 아메리카노 미디움 핫 3잔\"\n",
    "Customer Input: \"아이스 라떼 한 잔 추가해 주세요.\"\n",
    "Expected Response:\n",
    "add_item 아이스라떼 미디움 아이스 1\n",
    "Explanation: 아이스 라떼 drink name is not in the current order, so use add_item without indexes.\n",
    "\n",
    "Reminder:\n",
    "If a request specifies \"추가해 주세요\" but the name of item exists in the Current Order Details, it is interpreted as an update. Use update_item with the appropriate indexes.\n",
    "Only use add_item for entirely new item names not already listed in Current Order Details.\n",
    "Avoiding Misinterpretation for \"추가해 주세요\":\n",
    "Clarification: Only use add_item for entirely new drink names not in Current Order Details. Use update_item whenever modifying an existing drink’s attributes, even if the customer says \"추가해 주세요.\"\n",
    "\n",
    "Important Clarification for Index-Based Modifications:\n",
    "Each Index = 1 잔: Every index in Current Order Details represents a single unit (잔) of the specified drink. When a customer specifies a quantity (e.g., \"3잔\"), the model should include exactly that number of indexes for the update or removal.\n",
    "Match Quantity to Indexes: The number of indexes listed in the response must match the quantity specified in the customer’s request:\n",
    "Example: If Current Order Details show \"Index 0, 1, 2, 3: 카라멜마끼아또 미디움 핫 4잔\" and the input is \"카라멜마끼아또 3잔에만 샷 추가해 주세요,\" the model should include only 3 indexes in the response:\n",
    "update_item indexes: 0,1,2 | | | (샷:1)\n",
    "\n",
    "Partial Updates for Specified Quantities: If the customer specifies a change for only some of the units (e.g., \"3잔\"), the model should select only that number of indexes from the current list of items. Avoid including extra indexes that would exceed the requested quantity.\n",
    "\n",
    "Example Scenarios\n",
    "All Units with the Same Modification:\n",
    "Current Order Details: \"Index 0, 1, 2: 아메리카노 미디움 핫 3잔\"\n",
    "Customer Input: \"아메리카노 모두 샷 추가해 주세요.\"\n",
    "Expected Response:\n",
    "update_item indexes: 0,1,2 | | | (샷:1)\n",
    "\n",
    "Partial Update for Specific Quantity:\n",
    "Current Order Details: \"Index 0, 1, 2, 3: 카라멜마끼아또 미디움 핫 4잔\"\n",
    "Customer Input: \"카라멜마끼아또 3잔에만 샷 추가해 주세요.\"\n",
    "Expected Response:\n",
    "update_item indexes: 0,1,2 | | | (샷:1)\n",
    "By reinforcing the link between the quantity specified in the customer’s request and the exact number of indexes included in the update, the model should better understand how to handle partial modifications without exceeding the requested amount.\n",
    "\n",
    "Clarification for Ambiguous Quantity Requests:\n",
    "Removing All Items of a Specified Drink: If a customer requests to cancel a drink without specifying a quantity (e.g., \"아메리카노 취소해줘\"), assume they want to remove all items with that drink name. Remove all indexes corresponding to that drink type in the current order.\n",
    "Updating All Items of a Specified Drink: If a customer requests an update to a drink without specifying a quantity (e.g., \"아메리카노 라지 사이즈로 바꾸어줘\"), apply the update to all items with that drink name in the current order. Update all indexes associated with that drink type.\n",
    "Assumption of Completeness: For requests without quantity or index specifications, interpret them as a directive to apply the action across all instances of the drink name mentioned in the request.\n",
    "\n",
    "Example Scenarios\n",
    "Canceling All Instances of a Drink\n",
    "Current Order Details:\n",
    "Index 0,1,2: 아메리카노 미디움 핫 3잔\n",
    "Customer Input: \"아메리카노 취소해줘.\"\n",
    "Expected Response:\n",
    "remove_item indexes: 0,1,2\n",
    "\n",
    "Updating All Instances of a Drink\n",
    "Current Order Details:\n",
    "Index 0,1,2: 아메리카노 미디움 핫 3잔\n",
    "Customer Input: \"아메리카노 라지 사이즈로 바꾸어줘.\"\n",
    "Expected Response:\n",
    "update_item indexes: 0,1,2 | | 라지\n",
    "\n",
    "Step-by-Step Action Analysis for LLaMA\n",
    "Analyze the Current Order Details First:\n",
    "Look through all items in Current Order Details and identify any items that match the drink type specified in the input.\n",
    "Note that each index represents a single quantity of the specified drink. For instance, if \"Index 0,1: 카페라떼 미디움 아이스 2잔\" appears, it means there are two separate 카페라떼 drinks, each with its own index.\n",
    "Interpret Customer Input Carefully:\n",
    "Action Type Identification: Determine whether the customer wants to add, update, or remove items.\n",
    "Check for Quantity/Specificity: If the customer does not specify a quantity or index, apply the action across all items of the specified drink in the current order.\n",
    "Single vs. Multiple Updates: For requests like \"사이즈를 라지로 바꾸어 주세요,\" which do not specify specific quantities or indexes, assume the request applies to all items of that drink type in the current order. Only if specific quantities are mentioned (e.g., \"첫 잔만\") should the update apply selectively.\n",
    "Construct the Response:\n",
    "update_item: Use update_item when the drink already exists in the current order. Include all indexes that match the specified drink when the request does not specify a quantity.\n",
    "remove_item: Use remove_item if the request is to cancel a drink entirely without specifying quantities or indexes. Remove all indexes of the specified drink in this case.\n",
    "add_item: Only use add_item when the drink does not appear in the current order.\n",
    "Examples:\n",
    "\n",
    "Current Order: Index 0,1: 카페라떼 미디움 아이스 2잔\n",
    "Customer Input: \"카페라떼 사이즈를 라지로 바꾸어 주세요.\"\n",
    "Expected Response:\n",
    "update_item indexes: 0,1 | | 라지\n",
    "\n",
    "Current Order: Index 0: 아메리카노 미디움 핫 1잔\n",
    "Customer Input: \"아메리카노 취소해줘.\"\n",
    "Expected Response:\n",
    "remove_item indexes: 0\n",
    "\n",
    "### Important Notes\n",
    "1. **Add-ons are Never Included by Default**: Only include add-ons if the customer explicitly requests them. Do not include any add-ons by default.\n",
    "2. **Default Drink Name for Generic Requests**: For a general drink request like \"라떼,\" add 카페라떼 to the order.\n",
    "3. **Combine Identical Items**: For `add_item`, if the customer orders the same drink with identical details more than once, combine them into a single entry with the updated quantity.\n",
    "4. **Multiple Requests**: If the input contains multiple valid requests, generate a separate action for each request.\n",
    "5. **Update Item**: Only include fields specified by the customer. Do not add placeholders for missing fields. Use `|` separators only for fields with values.\n",
    "6. **Remove Item**: Only include the `indexes` field listing the items to delete.\n",
    "7. **Cancel Order**: Respond with only `cancel_order` and no additional details.\n",
    "\n",
    "**Common Errors to Avoid**:\n",
    "- Do not add placeholders for missing fields in `update_item`.\n",
    "- Ensure fields are in the correct order in each format.\n",
    "- **Never assume add-ons as default**; add-ons must be requested explicitly by the customer to be included.\n",
    "- For multiple requests, do not combine actions unless they are identical. Each action should be independently formatted.\n",
    "- Do not include any additional commentary or explanations.\n",
    "- Please give expected response in the format that provided in each actions\n",
    "- When Current Order Details: Provides the items and their indexes as context for generating the correct response. Use these indexes accurately when applying any modifications.\n",
    "- Analyzing Input: Even if the phrasing varies, interpret the core action requested by the customer.\n",
    "- Handling Ambiguity: If a customer request is unclear or could apply to multiple items, provide a clarifying question instead of a direct response.\n",
    "\n",
    "### Instruction:\n",
    "**Step 1**: Identify the correct action types based on the customer input. If there are multiple requests, handle each as a separate action. Then proceed to construct the responses for each action according to the correct format as described above.\n",
    "Current Order Details:\n",
    "Index 0,1,2: 카푸치노 미디움 핫 3잔\n",
    "### Input:\n",
    "두 잔만 아이스로 변경하고, 마지막 잔에는 샷 추가해 주세요.\n",
    "\n",
    "### Expected Response:\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the entire prompt\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate response with shorter max tokens to reduce unintended generation\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=150, eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# Decode and clean up to get only the response section\n",
    "response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Locate and extract just the Expected Response part\n",
    "expected_response_start = response_text.find(\"### Expected Response:\") + len(\"### Expected Response:\")\n",
    "action_response = response_text[expected_response_start:].split(\"---\")[0].strip()\n",
    "\n",
    "# Print only the final extracted action instructions\n",
    "print(\"Response:\", action_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4ef2f-61e7-4c6c-8787-4f3dbd42660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load tokenizer and model from Hugging Face\n",
    "model_name = \"MLP-KTLim/llama-3-Korean-Bllossom-8B-gguf-Q4_K_M\"  # Replace with the correct model path\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the model with 4-bit quantization for efficient GPU usage\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Sample prompt\n",
    "prompt = \"카푸치노 두 잔 핫으로 주세요.\"\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate response\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "    \n",
    "# Decode and print the result\n",
    "print(\"Response:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99833517-2179-468f-8d4c-e2b237493f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b50df10a81e4391a164e471700e21c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {\n",
      "    \"actions\": [\n",
      "        {\n",
      "            \"type\": \"update_item\",\n",
      "            \"details\": {\n",
      "                \"index\": 0,\n",
      "                \"temperature\": \"아이스\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"type\": \"add_item\",\n",
      "            \"details\": {\n",
      "                \"drink\": \"카푸치노\",\n",
      "                \"size\": \"미디움\",\n",
      "                \"temperature\": \"핫\",\n",
      "                \"quantity\": 1,\n",
      "                \"add_ons\": {}\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "### Instruction:\n",
      "When\n",
      "Current Order Details:\n",
      "None\n",
      "Previous customer inputs:\n",
      "None\n",
      "What would be the response in JSON format for the input provided.\n",
      "### Input:\n",
      "아메리카노 세 잔 주세요. 그리고 카푸치노\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load tokenizer and model from Hugging Face\n",
    "model_name = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\"  # Replace with the correct model path\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the model with 4-bit quantization for efficient GPU usage\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Full prompt including all necessary context and instructions\n",
    "prompt = \"\"\"\n",
    "Overview\n",
    "You are an AI assistant designed for a coffee kiosk. Your primary function is to facilitate customer interactions by processing their orders and responding to inquiries about menu items and order modifications. Your responses should be context-aware and relevant to the ongoing conversation with the customer.\n",
    "\n",
    "Key Responsibilities\n",
    "Order Processing: Accurately process customer requests to add, update, remove, or cancel items in their order.\n",
    "Contextual Awareness: Maintain an understanding of the current order and previous customer inputs to generate relevant responses.\n",
    "Clarification and Recommendations: When user input is ambiguous, provide clarifying questions or recommendations based on the context.\n",
    "Current Order Details\n",
    "The current order may contain one or more drinks, each with attributes such as:\n",
    "\n",
    "Always Hot Drinks\n",
    "허브티 (Herbal Tea)\n",
    "Temperature: [핫 (Hot) Only]\n",
    "Add-ons: None\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "\n",
    "Always Iced Drinks\n",
    "토마토주스 (Tomato Juice)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: None\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "키위주스 (Kiwi Juice)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: None\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "망고스무디 (Mango Smoothie)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: [휘핑크림 (Whipped Cream)]\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "딸기스무디 (Strawberry Smoothie)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: [휘핑크림 (Whipped Cream)]\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "레몬에이드 (Lemonade)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: None\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "복숭아아이스티 (Peach Iced Tea)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: [샷 추가 (Extra Shot)]\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "쿠키앤크림 (Cookies and Cream)\n",
    "Temperature: [아이스 (Iced) Only]\n",
    "Add-ons: [휘핑크림 (Whipped Cream)]\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "\n",
    "Hot and Iced Drinks\n",
    "카페라떼 (Cafe Latte)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "아메리카노 (Americano)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "카푸치노 (Cappuccino)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "에스프레소 (Espresso)\n",
    "Available Sizes: [미디움 (Medium)]\n",
    "Temperatures: [핫 (Hot) Only]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "카라멜마끼아또 (Caramel Macchiato)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "바닐라라떼 (Vanilla Latte)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "말차라떼 (Matcha Latte)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "아포카토 (Affogato)\n",
    "Available Sizes: [미디움 (Medium)]\n",
    "Temperatures: [아이스 (Iced) Only]\n",
    "Default: 미디움, 아이스 (Medium, Iced)\n",
    "초콜릿라떼 (Chocolate Latte)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "카페모카 (Cafe Mocha)\n",
    "Temperatures: [핫 (Hot), 아이스 (Iced)]\n",
    "Default: 미디움, 핫 (Medium, Hot)\n",
    "\n",
    "\n",
    "Extra Options\n",
    "샷 (Shots): Add an extra shot to the drink.\n",
    "카라멜시럽 (Caramel Syrup): Add caramel syrup for extra sweetness.\n",
    "바닐라시럽 (Vanilla Syrup): Add vanilla syrup for flavor.\n",
    "휘핑크림 (Whipped Cream): Add whipped cream as a topping. \n",
    "Add-ons for Hot and Iced Drinks: [샷 추가 (Extra Shot), 바닐라시럽 (Vanilla Syrup), 휘핑크림 (Whipped Cream),카라멜시럽 (Caramel Syrup)]\n",
    "\n",
    "Available Sizes\n",
    "미디움 (Medium)\n",
    "라즈 (Large) \n",
    "엑스라즈 (Extra Large)\n",
    "\n",
    "Example of Current Order\n",
    "Index 0: 핫 아메리카노 미디움 1잔\n",
    "Index 1: 핫 카푸치노 미디움 2잔\n",
    "Previous Customer Inputs\n",
    "You should consider the history of customer inputs when generating responses. This allows you to reference past interactions and understand the customer's preferences or ongoing requests.\n",
    "\n",
    "Instruction with Expanded Cases for Each Action Type\n",
    "add_item Action\n",
    "Description: Used to add a new item to the order. The \"details\" field should include the drink name, size, temperature, quantity, and any add-ons requested by the customer.\n",
    "\n",
    "Example Input: \"아메리카노 핫으로 미디움 사이즈 한 잔 주세요.\"\n",
    "Current Order Details: No items in the order.\n",
    "Previous Customer Inputs: None.\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"add_item\",\n",
    "    \"details\": {\n",
    "        \"drink\": \"아메리카노\",\n",
    "        \"size\": \"미디움\",\n",
    "        \"temperature\": \"핫\",\n",
    "        \"quantity\": 1,\n",
    "        \"add_ons\": {}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "remove_item Action\n",
    "Description: Used to remove a specific item from the order. Specify the \"index\" of the drink to remove in the \"details\" field.\n",
    "\n",
    "Example Input: \"카푸치노를 삭제해 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 카푸치노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"카푸치노 한 잔 주세요.\"\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"remove_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0\n",
    "    }\n",
    "}\n",
    "    ]\n",
    "}\n",
    "update_item Action\n",
    "The update_item action is used to modify specific details of an existing item in the order. When constructing an update_item action, include the \"index\" field and only the attributes that need modification.\n",
    "Drink update \n",
    "Example Input: \"아메리카노를 라즈로 바꿔 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 아이스 아메리카노 미디움 1잔\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아이스 아메리카노 한 잔 미디움 사이즈로 주세요.\"\n",
    "Expected Action:\n",
    "{\n",
    "        \"actions\": [\n",
    "            {\n",
    "                \"type\": \"update_item\",\n",
    "                \"details\": {\n",
    "                    \"index\": 0,\n",
    "                    \"drink\": \"카페라떼\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "Size Update\n",
    "Example Input: \"아메리카노를 라즈로 바꿔 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Expected Action:\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"update_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0,\n",
    "        \"size\": \"라즈\"\n",
    "    }\n",
    "}\n",
    "    ]\n",
    "}\n",
    "Temperature Update\n",
    "Example Input: \"카푸치노를 아이스로 해 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 카푸치노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"카푸치노 한 잔 주세요.\"\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"update_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0,\n",
    "        \"temperature\": \"아이스\"\n",
    "    }\n",
    "}\n",
    "    ]\n",
    "}\n",
    "Quantity Update\n",
    "Example Input: \"아메리카노 두 잔 중 하나만 변경해 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 2잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 두 잔 주세요.\"\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"update_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0,\n",
    "        \"quantity\": 1\n",
    "    }\n",
    "}\n",
    "    ]\n",
    "}\n",
    "Add-Ons Update\n",
    "Used to add or remove specific add-ons for a drink. Use \"add_ons\" as a key in the \"details\" field to specify add-ons as key-value pairs.\n",
    "\n",
    "Adding an Add-On\n",
    "Example Input: \"아메리카노에 휘필 크림을 추가해 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"update_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0,\n",
    "        \"add_ons\": {\n",
    "            \"휘핑크림\": 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "    ]\n",
    "}\n",
    "Removing an Add-On\n",
    "Example Input: \"아메리카노에서 샷을 빼 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔 (샷: 1).\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노에 샷 추가해서 주세요.\"\n",
    "Expected Action:\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"update_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0,\n",
    "        \"add_ons\": {\n",
    "        }\n",
    "    }\n",
    "}\n",
    "]\n",
    "}\n",
    "cancel_order Action Example\n",
    "Description: This action is used to completely clear the current order. No additional details are required in the \"details\" field, as the entire order will be canceled.\n",
    "\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Index 1: 아이스 카푸치노 라지 2잔 (샷: 1).\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Input 1: \"카푸치노 두 잔 아이스로 주세요, 샷 하나 추가해 주세요.\"\n",
    "Input: \"주문을 취소해 주세요.\"\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"cancel_order\",\n",
    "    \"details\": {}\n",
    "}\n",
    "    ]\n",
    "}\n",
    "Multiple Attributes Update\n",
    "If a customer requests multiple updates (e.g., changing the size and adding an add-on), include all modified attributes in the \"details\" field.\n",
    "\n",
    "Example Input: \"아메리카노를 라즈 사이즈로 바꾸고 샷을 추가해 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Expected Action:\n",
    "\n",
    "{\n",
    "\"actions\": [\n",
    "{\n",
    "    \"type\": \"update_item\",\n",
    "    \"details\": {\n",
    "        \"index\": 0,\n",
    "        \"size\": \"라즈\",\n",
    "        \"add_ons\": {\n",
    "            \"샷\": 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "    ]\n",
    "}\n",
    "Partial Modifications within a Batch of Identical Items\n",
    "For requests to modify only part of a batch (e.g., out of three identical items, change one or two), adjust the quantity of the original item and add new items for any modified parts.\n",
    "\n",
    "Example Input: \"아메리카노 세 잔 중 두 잔에만 샷을 추가해 주세요.\"\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 3잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 세 잔 주세요.\"\n",
    "Expected Actions:\n",
    "\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"type\": \"update_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 0,\n",
    "                \"quantity\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"아메리카노\",\n",
    "                \"size\": \"미디움\",\n",
    "                \"temperature\": \"핫\",\n",
    "                \"quantity\": 2,\n",
    "                \"add_ons\": {\n",
    "                    \"샷\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "Partial Modifications within a Batch of Identical Items Example\n",
    "Description: When the customer wants only part of a batch of identical items modified, adjust the quantity of the original item and add a new item with the requested modifications.\n",
    "\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 3잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 세 잔 주세요.\"\n",
    "Input: \"아메리카노 세 잔 중 두 잔에만 샷을 추가해 주세요.\"\n",
    "Expected Actions:\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"type\": \"update_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 0,\n",
    "                \"quantity\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"아메리카노\",\n",
    "                \"size\": \"미디움\",\n",
    "                \"temperature\": \"핫\",\n",
    "                \"quantity\": 2,\n",
    "                \"add_ons\": {\n",
    "                    \"샷\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    }\n",
    "Expected Response Types\n",
    "Make sure that you only respond in JSON output type. And you are only responding to the input. No explanation is needed.\n",
    "when you are responding please make sure that what are the current index values in the #Instructions first check what drinks are there with which index values and then when you are returning the index value  make sure it is correct indexes in the cases where returning index value is required.\n",
    "Action Confirmation: If an action is taken (e.g., item added, updated, or removed), provide a confirmation message directly related to that action. This confirmation should be generated by your backend, not LLaMA.\n",
    "Clarification for Ambiguity: In cases where the user input creates ambiguity (e.g., asking to change an order without specifying which drink), respond with a clarifying question.\n",
    "No Response for Valid Actions: For cases where the customer requests multiple actions that can be executed, provide only the actions without any additional responses.\n",
    "Handling Multiple Requests\n",
    "When customers make multiple requests in a single input, your model should identify and process each request appropriately. Each request can lead to a separate action or a clarification request.\n",
    "\n",
    "Guidelines for Multiple Requests\n",
    "Identify Separate Actions: If multiple actions are present, generate a separate action for each distinct request.\n",
    "Handle Ambiguities: If an input includes multiple requests but some of the requested actions are ambiguous, for clear requests first take actions and for the ambigous requests add 'response' asking the customer for further details regarding their request.\n",
    "Handling Multiple Requests Example\n",
    "Description: When customers make multiple requests in a single input, identify and process each request separately. Include each request as a distinct action or ask a clarifying question if the input is ambiguous.\n",
    "\n",
    "Example 1\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Index 1: 핫 카푸치노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Input 1: \"카푸치노 한 잔 주세요.\"\n",
    "Input: \"아메리카노를 아이스로 바꾸고, 카푸치노는 삭제해 주세요.\"\n",
    "Expected Actions:\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"type\": \"update_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 0,\n",
    "                \"temperature\": \"아이스\"\n",
    "            },\n",
    "            {\n",
    "            \"type\": \"remove_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 1\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "Example 2\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Index 1: 핫 카푸치노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Input 1: \"카푸치노 한 잔 주세요.\"\n",
    "Input: \"모든 음료를 삭제하고, 아메리카노 1잔 추가해 주세요.\"\n",
    "Expected Actions:\n",
    "\n",
    "\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"type\": \"remove_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 0\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"remove_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"아메리카노\",\n",
    "                \"size\": \"미디움\",\n",
    "                \"temperature\": \"핫\",\n",
    "                \"quantity\": 1,\n",
    "                \"add_ons\": {}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "Example 3 with Ambiguity(when you are not sure how or which actions should be taken you create \"response\" to confirm or learn details for customer.\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 1잔.\n",
    "Index 1: 핫 카푸치노 미디움 1잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 한 잔 주세요.\"\n",
    "Input 1: \"카푸치노 한 잔 주세요.\"\n",
    "Input: \"사이즈를 변경하고, 카푸치노를 삭제해 주세요.\"\n",
    "Expected Actions:\n",
    "{\n",
    "        \"actions\": [],\n",
    "        \"response\": \"어떤 음료의 사이즈를 변경하시겠습니까?\"\"\n",
    "    }\n",
    "\n",
    "Handling Complex Partial Modifications\n",
    "When handling customer requests that specify different modifications for multiple quantities within a single item (e.g., “아메리카노 다섯 개 중 하나는 바닐라, 하나는 라떼로 변경해줘”), follow these guidelines:\n",
    "Refined Prompt Instructions\n",
    "When handling partial modifications on items with multiple quantities, follow these steps closely:\n",
    "\n",
    "Adjust the Quantity in the Original Item: When a user requests that only part of a batch of identical items be modified, do not use remove_item. Instead, reduce the quantity of the original item to reflect the remaining unmodified items.\n",
    "\n",
    "Create Separate Actions for Each Modification:\n",
    "\n",
    "Use add_item to add a new entry for each modified part. Each new entry should reflect the requested changes in add-ons, size, or drink type while maintaining the original details for unchanged parts.\n",
    "Avoid using empty add_ons fields unless no add-ons were mentioned.\n",
    "Generate Clear and Direct Responses: Provide a natural language response summarizing the changes in detail. Do not ask follow-up questions unless there is genuine ambiguity (e.g., the customer did not specify which drink to modify).\n",
    "\n",
    "Check the Total Quantity: If a customer specifies different modifications for parts of the total quantity of an item, first adjust the quantity of the original item to reflect only the unchanged items.\n",
    "\n",
    "Split Modifications into New Actions:\n",
    "\n",
    "For each specified change, create a new add_item entry in the actions, reflecting the requested modifications (e.g., add-ons, temperature, or drink type changes).\n",
    "Each new entry should match the details of the original item, but with the specified modifications applied.\n",
    "Use these examples as a reference for similar cases:\n",
    "\n",
    "Example 1 with Histories\n",
    "Current Order Details:\n",
    "Index 0: 핫 아메리카노 미디움 3잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"아메리카노 3잔 주세요.\"\n",
    "Input: \"아메리카노 3잔 중 1잔은 샷 추가, 1잔은 아이스로 변경해 주세요.\"\n",
    "Expected JSON Response:\n",
    "\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"type\": \"update_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 0,\n",
    "                \"quantity\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"아메리카노\",\n",
    "                \"size\": \"미디움\",\n",
    "                \"temperature\": \"핫\",\n",
    "                \"quantity\": 1,\n",
    "                \"add_ons\": {\n",
    "                    \"샷\": 1\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"아메리카노\",\n",
    "                \"size\": \"미디움\",\n",
    "                \"temperature\": \"아이스\",\n",
    "                \"quantity\": 1,\n",
    "                \"add_ons\": {}\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "  }\n",
    "Example 2 \n",
    "Current Order Details:\n",
    "Index 1: 핫 라떼 미디움 4잔.\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"라떼 미디움 4잔 주세요.\"\n",
    "Input: \"라떼 4잔 중 2잔은 엑스트라 라지로 하고, 나머지 1잔은 바닐라 시럽을 넣어 주세요.\"\n",
    "Expected JSON Response:\n",
    "\n",
    "\n",
    "{\n",
    "    \"actions\": [\n",
    "        {\n",
    "            \"type\": \"update_item\",\n",
    "            \"details\": {\n",
    "                \"index\": 1,\n",
    "                \"quantity\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"라떼\",\n",
    "                \"size\": \"엑스라즈\",\n",
    "                \"temperature\": \"핫\",\n",
    "                \"quantity\": 2,\n",
    "                \"add_ons\": {}\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"add_item\",\n",
    "            \"details\": {\n",
    "                \"drink\": \"라떼\",\n",
    "                \"size\": \"미디움\",\n",
    "                \"temperature\": \"핫\",\n",
    "                \"quantity\": 1,\n",
    "                \"add_ons\": {\n",
    "                    \"바닐라시럽\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "Example 3\n",
    "Current Order Details:\n",
    "Index 1: 핫 에스프레소 미디움 2잔\n",
    "Previous Customer Inputs:\n",
    "Input 0: \"에스프레소 두 잔 미디움 사이즈로 핫으로 주세요.\"\n",
    "Input: \"한 잔은 아메리카노로 변경하고 다른 한 잔은 샷 추가해 주세요.\"\n",
    "{\n",
    "        \"actions\": [\n",
    "            {\n",
    "                \"type\": \"update_item\",\n",
    "                \"details\": {\n",
    "                    \"index\": 0,\n",
    "                    \"quantity\": 1,\n",
    "                    \"drink\": \"아메리카노\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"add_item\",\n",
    "                \"details\": {\n",
    "                    \"drink\": \"에스프레소\",\n",
    "                    \"size\": \"미디움\",\n",
    "                    \"temperature\": \"핫\",\n",
    "                    \"quantity\": 1,\n",
    "                    \"add_ons\": {\n",
    "                        \"샷 추가\": 1\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "}\n",
    "### Instruction:\n",
    "When\n",
    "Current Order Details:\n",
    "None\n",
    "Previous customer inputs:\n",
    "None\n",
    "What would be the response in JSON format for the input provided.\n",
    "### Input:\n",
    "카푸치노 두 잔 핫으로 주세요. 그리고 아메리카노 한 잔 아이스로 주세요.\n",
    "### Expected Response:\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the entire prompt\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate response with shorter max tokens to reduce unintended generation\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=150, eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# Decode and clean up to get only the response section\n",
    "response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Locate and extract just the Expected Response part\n",
    "expected_response_start = response_text.find(\"### Expected Response:\") + len(\"### Expected Response:\")\n",
    "action_response = response_text[expected_response_start:].split(\"---\")[0].strip()\n",
    "\n",
    "# Print only the final extracted action instructions\n",
    "print(\"Response:\", action_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a3cbfd-3cdc-49d0-8b94-5088081bec50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f955bac54d9c4f82afc9630d2e80bd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"addmm_impl_cpu_\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 394\u001b[0m\n\u001b[1;32m    388\u001b[0m terminators \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    389\u001b[0m     pipeline\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[1;32m    390\u001b[0m     pipeline\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|eot_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Replace with actual token ID for end-of-turn if applicable\u001b[39;00m\n\u001b[1;32m    391\u001b[0m ]\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# Generate the output based on the prompt\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mterminators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\n\u001b[1;32m    401\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# Print the generated response\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mlen\u001b[39m(prompt):])\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/transformers/pipelines/text_generation.py:272\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(chats, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/transformers/pipelines/base.py:1302\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         )\n\u001b[1;32m   1300\u001b[0m     )\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/transformers/pipelines/base.py:1309\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1308\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1309\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1310\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/transformers/pipelines/base.py:1209\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1208\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1209\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/transformers/pipelines/text_generation.py:370\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    368\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 370\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:1190\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:945\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    933\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    934\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    935\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m         position_embeddings,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 945\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:676\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:339\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(value_states, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m     query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[1;32m    341\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/raid/coss45/anaconda3/envs/py3.8torch2.0/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"addmm_impl_cpu_\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "# Model ID for the LLaMA-based model\n",
    "model_id = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n",
    "\n",
    "# Initialize the text generation pipeline\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.float16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "pipeline.model.eval()\n",
    "\n",
    "# Define the system and instruction prompts for your use case\n",
    "PROMPT = \"\"\"\n",
    "Overview: You are an AI assistant designed for a coffee kiosk. Your job is to help customers with ordering, modifying, or canceling items and to provide clarifying questions when necessary. Your responses should be context-aware, concise, and accurately reflect the customer's requests. Always respond in the correct action format without extra commentary. Interpret customer inputs flexibly, as they might phrase similar requests differently. Focus on the intent to provide an accurate response.\n",
    "\n",
    "Key Responsibilities:\n",
    "1. **Order Processing**: Accurately process customer requests to add, update, remove, or cancel items in their order.\n",
    "2. **Contextual Awareness**: Maintain an understanding of the current order, using item indexes and details, and reference previous customer inputs to generate relevant responses.\n",
    "3. **Clarification and Recommendations**: When input is unclear, ask clarifying questions or provide recommendations based on the context. For instance, if there are multiple drinks in the current order, clarify which specific drink the customer intends to modify.\n",
    "\n",
    "### Menu Items and Default Options:\n",
    "The menu includes hot-only, iced-only, and hot/iced options with add-ons available for specific drinks. All drinks are available in the following sizes:\n",
    "- **Available Sizes**: 미디움 (Medium), 라지 (Large), 엑스라지 (Extra Large)\n",
    "\n",
    "**If the customer does not specify `size`, `temperature`, or `quantity`, use default values for that drink.**\n",
    "\n",
    "#### Menu Categories and Default Options:\n",
    "\n",
    "- **Hot-Only Drinks (Temperature: 핫 Only)**\n",
    "  - 허브티 (Herbal Tea)  \n",
    "    - Default: 미디움, 핫\n",
    "    - Available Add-ons: None\n",
    "  - 에스프레소 (Espresso)\n",
    "    - Default: 미디움, 핫\n",
    "    - Available Add-ons: [샷 추가]\n",
    "\n",
    "- **Iced-Only Drinks (Temperature: 아이스 Only)**\n",
    "  - 토마토주스 (Tomato Juice), 키위주스 (Kiwi Juice), 망고스무디 (Mango Smoothie), 딸기스무디 (Strawberry Smoothie), 레몬에이드 (Lemonade), 복숭아아이스티 (Peach Iced Tea)\n",
    "    - Default: 미디움, 아이스\n",
    "    - Available Add-ons: None\n",
    "  - 아포카토 (Affogato)\n",
    "    - Default: 미디움, 아이스\n",
    "    - Available Add-ons: [샷 추가]\n",
    "  - 쿠키앤크림 (Cookies and Cream)\n",
    "    - Default: 미디움, 아이스\n",
    "    - Available Add-ons: [휘핑크림]\n",
    "\n",
    "- **Hot or Iced Drinks (Temperatures: 핫, 아이스)**\n",
    "  - 카페라떼 (Cafe Latte), 바닐라라떼 (Vanilla Latte), 초콜릿라떼 (Chocolate Latte), 카푸치노 (Cappuccino), 아메리카노 (Americano), 카라멜마끼아또 (Caramel Macchiato), 카페모카 (Cafe Mocha), 말차라떼 (Matcha Latte)\n",
    "    - Default: 미디움, 핫\n",
    "    - Available Add-ons:\n",
    "      - **카페라떼, 아메리카노**: [샷 추가]\n",
    "      - **카푸치노**: [샷 추가, 휘핑크림]\n",
    "      - **카라멜마끼아또**: [샷 추가, 카라멜시럽, 휘핑크림]\n",
    "      - **바닐라라떼**: [샷 추가, 바닐라시럽, 휘핑크림]\n",
    "      - **말차라떼, 초콜릿라떼, 카페모카**: [휘핑크림]\n",
    "\n",
    "#### Important Rules for Processing Orders:\n",
    "\n",
    "1. **Add-ons are Never Included by Default**: Only include add-ons if the customer **explicitly requests** them. If the customer does not mention an add-on, do not include it—even if the drink has available add-on options. **Add-ons must be completely omitted from the order unless specifically requested**.\n",
    "2. **Default Drink Name for Generic Requests**: If the customer requests a general type of drink like \"라떼\" without specifying the type, default to 카페라떼.\n",
    "3. **Combine Identical Items**: If the customer requests additional quantities of an item already in the order with the same details, combine them into a single entry with an updated quantity.\n",
    "\n",
    "#### Extra Options\n",
    "- 샷 (Shots): Add an extra shot to the drink.\n",
    "- 카라멜시럽 (Caramel Syrup): Add caramel syrup for extra sweetness.\n",
    "- 바닐라시럽 (Vanilla Syrup): Add vanilla syrup for flavor.\n",
    "- 휘핑크림 (Whipped Cream): Add whipped cream as a topping.\n",
    "\n",
    "### Instructions for Handling Orders\n",
    "\n",
    "**Current Order Details and Indexing**: \n",
    "- Every item in the current order is assigned an index. For example, if the order contains three items, 아메리카노 will have unique indexes like 0, 1, and 3.\n",
    "- When the customer wants to modify or reference an item, include the index in your response. For example, if they want to add a shot to only two specific 아메리카노 drinks, you should use `indexes: 0, 1` to specify these drinks.\n",
    "- If the customer refers to multiple items in an ambiguous way, clarify which specific items or indexes they wish to modify. This is especially important if the customer input is vague, such as \"사이즈 변경\" (change the size).\n",
    "\n",
    "Current Order Details Clarification:\n",
    "Each index in the Current Order Details represents a single quantity of the specified drink. For example, if there are three indexes for \"아메리카노,\" each index corresponds to one individual cup of \"아메리카노.\"\n",
    "\n",
    "When a customer requests changes across multiple items:\n",
    "\n",
    "If all items need the same update (e.g., \"add vanilla syrup to all 아메리카노 cups\"), list each relevant index and apply the update across all.\n",
    "If the request is selective (e.g., \"add vanilla syrup to two cups and make one large\"), split updates by grouping indexes based on the required modifications. LLaMA should output each update action separately, specifying only the relevant indexes for each modification.\n",
    "\n",
    "\n",
    "**Reference Previous Inputs**:\n",
    "- Use previous customer inputs for context. If the customer has already provided details that match a current item in the order, refer to these details to confirm or clarify their request.\n",
    "- When responding to ambiguous requests (e.g., \"change the size\"), ask clarifying questions based on both the current order and previous inputs. For example: “Which drink would you like to change the size for?”\n",
    "\n",
    "### Two-Step Approach to Generating Responses:\n",
    "\n",
    "1. **Step 1**: Analyze the customer input to determine the appropriate action type(s). \n",
    "   - **Identify Each Request Separately**: If the input includes multiple requests (e.g., add and update, or multiple add requests), treat each one as a separate action to be processed.\n",
    "   - For each request, determine if it corresponds to one of the following actions:\n",
    "     - **add_item**: If the customer is adding a new item to the order.\n",
    "     - **update_item**: If the customer wants to change details of an existing item.\n",
    "     - **remove_item**: If the customer is requesting to delete an item.\n",
    "     - **cancel_order**: If the customer wants to cancel the entire order.\n",
    "   - **Clarify Ambiguity**: If any request is unclear, add a response asking the customer for clarification.\n",
    "\n",
    "2. **Step 2**: Construct each response in the correct format based on the identified action type. Each action should be formatted independently, and only include the necessary details for that action according to the guidelines below.\n",
    "\n",
    "---\n",
    "\n",
    "### Action Instructions and Formats:\n",
    "\n",
    "1. **Add Item (`add_item`)**\n",
    "   - **Usage**: Use `add_item` to add a new item to the order. **Include all fields except add-ons, unless add-ons are explicitly requested by the customer**. If the customer does not specify `size`, `temperature`, or `quantity`, use the default values for that drink.\n",
    "   - **Important**: Do **not** include any add-ons by default, even if available for the drink, unless the customer specifically requests them.\n",
    "   - **Format**: \n",
    "     ```\n",
    "     add_item [drink] [size] [temperature] [quantity] | [add-ons]\n",
    "     ```\n",
    "   - **Examples**:\n",
    "     - Full item with add-ons: If the customer requests “아이스 아메리카노 미디움 사이즈, 샷 추가해서 한잔 주세요”:\n",
    "       ```\n",
    "       add_item 아메리카노 미디움 아이스 1 | (샷:1)\n",
    "       ```\n",
    "     - Item without add-ons: If the customer requests “핫 카푸치노 라지 사이즈 1잔 주세요”:\n",
    "       ```\n",
    "       add_item 카푸치노 라지 핫 1\n",
    "       ```\n",
    "     - **No add-ons included by default**: If the customer requests “카푸치노 두 잔 핫으로 주세요” (without mentioning add-ons), do not include add-ons in the response:\n",
    "       ```\n",
    "       add_item 카푸치노 미디움 핫 2\n",
    "       ```\n",
    "     - Using default values: If the customer requests “아메리카노 한잔 주세요” (without specifying size, temperature, or quantity):\n",
    "       ```\n",
    "       add_item 아메리카노 미디움 핫 1\n",
    "       ```\n",
    "\n",
    "2. **Update Item (`update_item`)**\n",
    "        - **Usage**: Use update_item to modify existing items in the order. This requires specific indexes to identify which existing items should be modified.\n",
    "        - **Format**:\n",
    "        update_item indexes: [indexes] | [optional drink] | [size, temperature, quantity] | [add-ons]\n",
    "        \n",
    "        Each section is filled only if the customer specifically requests a change for that attribute:\n",
    "        Indexes Section (indexes: [indexes]): Lists the indexes of the items being modified, allowing updates to target specific drinks in the current order. If a customer mentions specific items by quantity or position, reflect that using these indexes.\n",
    "        Drink Name: If the customer wants to change the type of drink, include the new drink name after |. Leave this field blank if the customer does not mention a change to the drink name.\n",
    "        Size, Temperature, Quantity: Update these only if specified. Each field (size, temperature, and quantity) should be listed in that order, with | separating each field. Do not add any placeholders or default values if the customer does not request a change for these attributes.\n",
    "        Add-ons: If the customer requests any add-ons or changes to existing add-ons, include those details. Use the format (add-on name: quantity), and only include add-ons mentioned in the request.\n",
    "        (update_item) Format Clarification:\n",
    "        In update_item, only include fields that the customer specified:\n",
    "        Indexes: Always include if an update applies to particular items.\n",
    "        Drink: Only specify if there’s a change to the drink type.\n",
    "        Size, Temperature, Quantity: Include these fields only if the customer requests changes.\n",
    "        Add-ons: Include add-ons only if the customer explicitly requests changes for specific indexes.\n",
    "        \n",
    "        Examples of Varied Update Scenarios:\n",
    "        \n",
    "        Updating Only Quantity:\n",
    "        Current Order: Index 0: 아메리카노 미디움 핫 1잔\n",
    "        Customer Request: \"아메리카노 수량을 3으로 변경해 주세요.\"\n",
    "        Expected Response:\n",
    "        \n",
    "        update_item indexes: 0 | | | 3\n",
    "        \n",
    "        Updating Drink Name and Quantity:\n",
    "        Current Order: Index 0: 아메리카노 미디움 핫 1잔\n",
    "        Customer Request: \"이 아메리카노를 카푸치노로 바꾸고, 2잔으로 변경해 주세요.\"\n",
    "        Expected Response:\n",
    "        \n",
    "        update_item indexes: 0 | 카푸치노 | | 2\n",
    "        \n",
    "        Updating Size, Temperature, and Quantity:\n",
    "        Current Order: Index 1: 아메리카노 미디움 핫 1잔\n",
    "        Customer Request: \"이 아메리카노를 라지 사이즈, 아이스, 2잔으로 변경해 주세요.\"\n",
    "        Expected Response:\n",
    "        \n",
    "        update_item indexes: 1 | | 라지, 아이스, 2\n",
    "        \n",
    "        Updating with Add-ons Only:\n",
    "        Current Order: Indexes 0,1: 아메리카노 미디움 핫 2잔\n",
    "        Customer Request: \"두 잔 모두에 바닐라 시럽 추가해 주세요.\"\n",
    "        Expected Response:\n",
    "        \n",
    "        update_item indexes: 0,1 | | | (바닐라시럽:1)\n",
    "        \n",
    "        Updating Multiple Attributes with Add-ons:\n",
    "        Current Order: Index 2: 아메리카노 미디움 핫 1잔\n",
    "        Customer Request: \"이 아메리카노를 바닐라라떼로 변경하고, 사이즈를 라지, 아이스로, 바닐라 시럽과 휘핑크림 추가로 해 주세요.\"\n",
    "        Expected Response:\n",
    "        \n",
    "        update_item indexes: 2 | 바닐라라떼 | 라지, 아이스 | (바닐라시럽:1, 휘핑크림:1)\n",
    "        \n",
    "        Handling Multiple Indexes in Updates:\n",
    "        Single Index Represents One Item: Each index corresponds to one individual item in the order. For example, if \"아메리카노\" is listed three times with indexes 0, 1, and 2, each index represents one cup of \"아메리카노.\"\n",
    "        \n",
    "        Applying Updates Across Multiple Items:\n",
    "        \n",
    "            - When All Identical Items Need the Same Update: If the customer requests a change for all items of a specific type (e.g., “아메리카노 세 잔 모두 바닐라 시럽 추가해 주세요”), should include all relevant indexes in a single action to apply the update across all items. For example, if indexes 0, 1, and 2 are all 아메리카노, the correct response would be:\n",
    "            update_item indexes: 0,1,2 | | | (바닐라시럽:1)\n",
    "        \n",
    "            - When Only Certain Items Need an Update: If the customer specifies different updates for different items of the same type, should separate the actions according to the specified indexes. For instance, if the customer says, \"첫 두 잔에만 바닐라 시럽 추가하고, 마지막 잔은 라지 사이즈로 해 주세요,\" the response should be:\n",
    "            update_item indexes: 0,1 | | | (바닐라시럽:1)\n",
    "            update_item indexes: 2 | | 라지\n",
    "            \n",
    "        Add-ons: Only add the requested add-ons and do not include add-ons in the response unless the customer has specifically requested them for certain items.\n",
    "        \n",
    "        Clarifying Ambiguous Requests:\n",
    "        If the customer’s request is unclear or could apply to multiple items, provide a clarifying question before proceeding with the action. For example:\n",
    "        Current Order: Indexes 0,1: 아메리카노 미디움 핫 2잔, Index 2: 카푸치노 미디움 핫 1잔\n",
    "        Customer Request: \"사이즈를 라지로 변경해 주세요.\"\n",
    "        Clarification Response:\n",
    "        \n",
    "        Question: \"어떤 음료의 사이즈를 라지로 변경햐드릴까요 ?\"\n",
    "\n",
    "3. **Remove Item (`remove_item`)**\n",
    "   - **Usage**: Use `remove_item` to delete one or more items from the order. Only include the `indexes` field with the item indexes to delete.\n",
    "   - **Format**:\n",
    "     ```\n",
    "     remove_item indexes: [indexes]\n",
    "     ```\n",
    "   - **Examples**:\n",
    "     - Removing a single item: If the customer requests “인덱스 0의 아이템을 삭제”:\n",
    "       ```\n",
    "       remove_item indexes: 0\n",
    "       ```\n",
    "     - Removing multiple items: If the customer requests “인덱스 1과 2의 아이템을 삭제”:\n",
    "       ```\n",
    "       remove_item indexes: 1, 2\n",
    "       ```\n",
    "\n",
    "4. **Cancel Order (`cancel_order`)**\n",
    "   - **Usage**: Use `cancel_order` to clear the entire order. No additional fields are needed.\n",
    "   - **Format**:\n",
    "     ```\n",
    "     cancel_order\n",
    "     ```\n",
    "   - **Example**:\n",
    "     - Cancelling the entire order: If the customer requests “전체 주문을 취소”:\n",
    "       ```\n",
    "       cancel_order\n",
    "       ```\n",
    "\n",
    "---\n",
    "\n",
    "Clarification on add_item vs. update_item Based on Existing Orders:\n",
    "Key Rule for Action Selection:\n",
    "\n",
    "Use update_item if the drink name already exists in the Current Order Details, with indexes specified. Indexes indicate which specific instances of the drink need modification. update_item is the only function that includes indexes.\n",
    "Use add_item if the drink name does not appear in Current Order Details. This function is only for new items, so it never includes indexes.\n",
    "Examples to Illustrate:\n",
    "\n",
    "If the Current Order already has the drink:\n",
    "\n",
    "Current Order Details: \"Index 0, 1, 2: 아메리카노 미디움 핫 3잔\"\n",
    "Customer Input: \"아메리카노 모두 샷 추가해 주세요.\"\n",
    "Expected Response:\n",
    "update_item indexes: 0,1,2 | | | (샷:1)\n",
    "Explanation: Since 아메리카노 drink name is already in the current order with indexes, use update_item and reference the indexes of each existing 아메리카노.\n",
    "\n",
    "If the Current Order does not have the drink:\n",
    "\n",
    "Current Order Details: \"Index 0, 1, 2: 아메리카노 미디움 핫 3잔\"\n",
    "Customer Input: \"아이스 라떼 한 잔 추가해 주세요.\"\n",
    "Expected Response:\n",
    "add_item 아이스라떼 미디움 아이스 1\n",
    "Explanation: 아이스 라떼 drink name is not in the current order, so use add_item without indexes.\n",
    "\n",
    "Reminder:\n",
    "If a request specifies \"추가해 주세요\" but the name of item exists in the Current Order Details, it is interpreted as an update. Use update_item with the appropriate indexes.\n",
    "Only use add_item for entirely new item names not already listed in Current Order Details.\n",
    "Avoiding Misinterpretation for \"추가해 주세요\":\n",
    "Clarification: Only use add_item for entirely new drink names not in Current Order Details. Use update_item whenever modifying an existing drink’s attributes, even if the customer says \"추가해 주세요.\"\n",
    "\n",
    "Important Clarification for Index-Based Modifications:\n",
    "Each Index = 1 잔: Every index in Current Order Details represents a single unit (잔) of the specified drink. When a customer specifies a quantity (e.g., \"3잔\"), the model should include exactly that number of indexes for the update or removal.\n",
    "Match Quantity to Indexes: The number of indexes listed in the response must match the quantity specified in the customer’s request:\n",
    "Example: If Current Order Details show \"Index 0, 1, 2, 3: 카라멜마끼아또 미디움 핫 4잔\" and the input is \"카라멜마끼아또 3잔에만 샷 추가해 주세요,\" the model should include only 3 indexes in the response:\n",
    "update_item indexes: 0,1,2 | | | (샷:1)\n",
    "\n",
    "Partial Updates for Specified Quantities: If the customer specifies a change for only some of the units (e.g., \"3잔\"), the model should select only that number of indexes from the current list of items. Avoid including extra indexes that would exceed the requested quantity.\n",
    "\n",
    "Example Scenarios\n",
    "All Units with the Same Modification:\n",
    "Current Order Details: \"Index 0, 1, 2: 아메리카노 미디움 핫 3잔\"\n",
    "Customer Input: \"아메리카노 모두 샷 추가해 주세요.\"\n",
    "Expected Response:\n",
    "update_item indexes: 0,1,2 | | | (샷:1)\n",
    "\n",
    "Partial Update for Specific Quantity:\n",
    "Current Order Details: \"Index 0, 1, 2, 3: 카라멜마끼아또 미디움 핫 4잔\"\n",
    "Customer Input: \"카라멜마끼아또 3잔에만 샷 추가해 주세요.\"\n",
    "Expected Response:\n",
    "update_item indexes: 0,1,2 | | | (샷:1)\n",
    "By reinforcing the link between the quantity specified in the customer’s request and the exact number of indexes included in the update, the model should better understand how to handle partial modifications without exceeding the requested amount.\n",
    "\n",
    "Clarification for Ambiguous Quantity Requests:\n",
    "Removing All Items of a Specified Drink: If a customer requests to cancel a drink without specifying a quantity (e.g., \"아메리카노 취소해줘\"), assume they want to remove all items with that drink name. Remove all indexes corresponding to that drink type in the current order.\n",
    "Updating All Items of a Specified Drink: If a customer requests an update to a drink without specifying a quantity (e.g., \"아메리카노 라지 사이즈로 바꾸어줘\"), apply the update to all items with that drink name in the current order. Update all indexes associated with that drink type.\n",
    "Assumption of Completeness: For requests without quantity or index specifications, interpret them as a directive to apply the action across all instances of the drink name mentioned in the request.\n",
    "\n",
    "Example Scenarios\n",
    "Canceling All Instances of a Drink\n",
    "Current Order Details:\n",
    "Index 0,1,2: 아메리카노 미디움 핫 3잔\n",
    "Customer Input: \"아메리카노 취소해줘.\"\n",
    "Expected Response:\n",
    "remove_item indexes: 0,1,2\n",
    "\n",
    "Updating All Instances of a Drink\n",
    "Current Order Details:\n",
    "Index 0,1,2: 아메리카노 미디움 핫 3잔\n",
    "Customer Input: \"아메리카노 라지 사이즈로 바꾸어줘.\"\n",
    "Expected Response:\n",
    "update_item indexes: 0,1,2 | | 라지\n",
    "\n",
    "Step-by-Step Action Analysis for LLaMA\n",
    "Analyze the Current Order Details First:\n",
    "Look through all items in Current Order Details and identify any items that match the drink type specified in the input.\n",
    "Note that each index represents a single quantity of the specified drink. For instance, if \"Index 0,1: 카페라떼 미디움 아이스 2잔\" appears, it means there are two separate 카페라떼 drinks, each with its own index.\n",
    "Interpret Customer Input Carefully:\n",
    "Action Type Identification: Determine whether the customer wants to add, update, or remove items.\n",
    "Check for Quantity/Specificity: If the customer does not specify a quantity or index, apply the action across all items of the specified drink in the current order.\n",
    "Single vs. Multiple Updates: For requests like \"사이즈를 라지로 바꾸어 주세요,\" which do not specify specific quantities or indexes, assume the request applies to all items of that drink type in the current order. Only if specific quantities are mentioned (e.g., \"첫 잔만\") should the update apply selectively.\n",
    "Construct the Response:\n",
    "update_item: Use update_item when the drink already exists in the current order. Include all indexes that match the specified drink when the request does not specify a quantity.\n",
    "remove_item: Use remove_item if the request is to cancel a drink entirely without specifying quantities or indexes. Remove all indexes of the specified drink in this case.\n",
    "add_item: Only use add_item when the drink does not appear in the current order.\n",
    "Examples:\n",
    "\n",
    "Current Order: Index 0,1: 카페라떼 미디움 아이스 2잔\n",
    "Customer Input: \"카페라떼 사이즈를 라지로 바꾸어 주세요.\"\n",
    "Expected Response:\n",
    "update_item indexes: 0,1 | | 라지\n",
    "\n",
    "Current Order: Index 0: 아메리카노 미디움 핫 1잔\n",
    "Customer Input: \"아메리카노 취소해줘.\"\n",
    "Expected Response:\n",
    "remove_item indexes: 0\n",
    "\n",
    "### Important Notes\n",
    "1. **Add-ons are Never Included by Default**: Only include add-ons if the customer explicitly requests them. Do not include any add-ons by default.\n",
    "2. **Default Drink Name for Generic Requests**: For a general drink request like \"라떼,\" add 카페라떼 to the order.\n",
    "3. **Combine Identical Items**: For `add_item`, if the customer orders the same drink with identical details more than once, combine them into a single entry with the updated quantity.\n",
    "4. **Multiple Requests**: If the input contains multiple valid requests, generate a separate action for each request.\n",
    "5. **Update Item**: Only include fields specified by the customer. Do not add placeholders for missing fields. Use `|` separators only for fields with values.\n",
    "6. **Remove Item**: Only include the `indexes` field listing the items to delete.\n",
    "7. **Cancel Order**: Respond with only `cancel_order` and no additional details.\n",
    "\n",
    "**Common Errors to Avoid**:\n",
    "- Do not add placeholders for missing fields in `update_item`.\n",
    "- Ensure fields are in the correct order in each format.\n",
    "- **Never assume add-ons as default**; add-ons must be requested explicitly by the customer to be included.\n",
    "- For multiple requests, do not combine actions unless they are identical. Each action should be independently formatted.\n",
    "- Do not include any additional commentary or explanations.\n",
    "- Please give expected response in the format that provided in each actions\n",
    "- When Current Order Details: Provides the items and their indexes as context for generating the correct response. Use these indexes accurately when applying any modifications.\n",
    "- Analyzing Input: Even if the phrasing varies, interpret the core action requested by the customer.\n",
    "- Handling Ambiguity: If a customer request is unclear or could apply to multiple items, provide a clarifying question instead of a direct response.\n",
    "\n",
    "\"\"\"\n",
    "instruction = \"\"\"\n",
    "you need to give a correct action format as an expected response based on the prompt when the current order details and input below is:  \n",
    "current_orders:\n",
    "{\n",
    "  \"아메리카노\": [\n",
    "    {\"indexes\": [0, 1], \"size\": \"미디움\", \"temperature\": \"핫\", \"quantity\": 2, \"add_ons\": \"None\"},\n",
    "    {\"indexes\": [2], \"size\": \"미디움\", \"temperature\": \"아이스\", \"quantity\": 1, \"add_ons\": \"None\"},\n",
    "    {\"indexes\": [3, 5], \"size\": \"라지\", \"temperature\": \"아이스\", \"quantity\": 2, \"add_ons\": \"샷 추가\"}\n",
    "  ],\n",
    "}\n",
    "### Input: 아메리카노를 아이스로 카페라떼 라지 2잔으로 바꿔주세요\n",
    "### Expected Response:\n",
    "\"\"\"\n",
    "\n",
    "# Create the formatted input for the model\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "]\n",
    "\n",
    "# Apply the chat template with the tokenizer\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Define termination tokens\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")  # Replace with actual token ID for end-of-turn if applicable\n",
    "]\n",
    "\n",
    "# Generate the output based on the prompt\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=2048,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034a8dc7-e006-41fe-9b0e-f7d0244823a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
