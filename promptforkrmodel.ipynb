{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiaTyDDmPDY5"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import json\n",
        "\n",
        "# Initialize the Korean model for text generation\n",
        "model = pipeline('text-generation', model='Bllossom/llama-3.2-Korean-Bllossom-3B', device=0)\n",
        "\n",
        "# Initialize conversation history, summary history, and order confirmation flag\n",
        "conversation_history = []  # Stores each customer input as a string entry in the format: \"Customer's X Input: [input]\"\n",
        "summary_history = []       # Stores each cumulative summary of orders\n",
        "order_confirmed = False    # Tracks if the order is finalized\n",
        "\n",
        "# Function to generate prompt based on conversation history and new input\n",
        "def generate_prompt(conversation_history, user_input):\n",
        "    # Format the conversation history and cumulative summary as a single string\n",
        "    formatted_history = \"\\n\".join(conversation_history) if conversation_history else \"none\"\n",
        "    formatted_summary = \"\\n\".join(summary_history) if summary_history else \"none\"\n",
        "\n",
        "    base_prompt = f\"\"\"\n",
        "    You are operating a virtual coffee kiosk that receives speech-to-text (STT) inputs from customers placing coffee orders. Your role is to understand and process these inputs, respond naturally in Korean, and generate a structured JSON file with the correct details for backend processing.\n",
        "\n",
        "    **Key Requirements**:\n",
        "    - **Menu Items**: The kiosk offers the following drinks:\n",
        "    - Hot Drinks: 허브티 (always served hot)\n",
        "    - Iced Only Drinks: 토마토주스, 키위주스, 망고스무디, 딸기스무디, 레몬에이드, 복숭아아이스티 (always served iced)\n",
        "    - Hot and Iced Coffee: 아메리카노, 라떼, 카푸치노, 카페모카, 바닐라라떼, 에스프레소, 카라멜마끼아또\n",
        "    - Specialty Drinks: 초콜릿라떼 (available in both hot and iced versions)\n",
        "\n",
        "    - **Default Values**:\n",
        "        - Use default size \"미디움\" and temperature \"핫\" only if the customer does not specify these details.\n",
        "    - **Do Not Make Assumptions**:\n",
        "        - If the customer specifies temperature or size, do not override it with defaults. For instance, if they say \"아이스 라떼 두잔 주세요\", the output should indicate \"아이스\" without changing it to \"핫\".\n",
        "    - **Current Conversation History** is a single-line cumulative log of all customer requests so far in this session. starting from 1\n",
        "    **Customer Input and Expected Output Format**:\n",
        "    - Each response should have:\n",
        "      1. **Natural Language Confirmation**: Respond in Korean, starting with an action confirmation such as \"[Drink] [quantity] 주문되었습니다.\" and follow with a full summary of all items ordered so far, beginning with \"지금까지 주문하신 내용은 다음과 같습니다:\".(also if there are any instance in history it should be added after this sentence)\n",
        "      2. **Structured JSON Output**: Each JSON output should only contain the items directly requested in the latest input, not a full history.\n",
        "\n",
        "    **JSON Output Format**:\n",
        "    - The JSON should be structured as follows:\n",
        "      ```json\n",
        "      {{\n",
        "          \"action\": \"[action_type]\",\n",
        "          \"order_items\": [\n",
        "              {{\n",
        "                  \"drink\": \"[Drink Name]\",\n",
        "                  \"size\": \"[Size]\",\n",
        "                  \"temperature\": \"[Temperature]\",\n",
        "                  \"quantity\": [Quantity],\n",
        "                  \"add_ons\": [List of add-ons if any],\n",
        "                  \"extra_shots\": [Number of extra shots if any]\n",
        "              }}\n",
        "          ]\n",
        "      }}\n",
        "      ```\n",
        "      - **Example JSON Output**:\n",
        "        ```json\n",
        "        {{\n",
        "            \"action\": \"create_order\",\n",
        "            \"order_items\": [\n",
        "                {{\n",
        "                    \"drink\": \"아메리카노\",\n",
        "                    \"size\": \"미디움\",\n",
        "                    \"temperature\": \"핫\",\n",
        "                    \"quantity\": 1,\n",
        "                    \"add_ons\": [],\n",
        "                    \"extra_shots\": 0\n",
        "                }}\n",
        "            ]\n",
        "        }}\n",
        "        ```\n",
        "\n",
        "    **Available Actions for JSON Output**:\n",
        "    - **create_order**: For new drink orders.\n",
        "    - **add_item**: For adding a new item to the current order.\n",
        "    - **modify_order**: For changing an existing item (e.g., modifying size or temperature).\n",
        "    - **cancel_order**: To remove an order item or reset the order.\n",
        "    - **recommend_closest_item**: If a requested item is unavailable, recommend the closest item.\n",
        "    - **show_order_summary**: Display a summary of all items ordered so far.\n",
        "    - **complete_order**: Finalize the order after confirmation.\n",
        "\n",
        "    **Specific Scenarios and Expected Outputs**:\n",
        "    - **Creating a New Order**:\n",
        "      - **Customer Input**: \"아메리카노 4잔 주세요.\"\n",
        "      - **Natural Language Response**: \"아메리카노 4잔 주문되었습니다. 지금까지 주문하신 내용은 다음과 같습니다:\n",
        "      -아메리카노 4잔 (핫, 미디움)\"\n",
        "      - **JSON Output**:\n",
        "        ```json\n",
        "        {{\n",
        "          \"action\": \"create_order\",\n",
        "          \"order_items\": [\n",
        "            {{\n",
        "              \"drink\": \"아메리카노\",\n",
        "              \"size\": \"미디움\",\n",
        "              \"temperature\": \"핫\",\n",
        "              \"quantity\": 4,\n",
        "              \"add_ons\": [],\n",
        "              \"extra_shots\": 0\n",
        "            }}\n",
        "          ]\n",
        "        }}\n",
        "        ```\n",
        "\n",
        "    - **Requesting Order Summary**:\n",
        "      - **Customer Input**: \"내가 지금까지 뭘 주문했지?\"\n",
        "      - **Natural Language Response**: \"지금까지 주문하신 내용은 다음과 같습니다:\n",
        "      -아메리카노 4잔(핫, 미디움)\n",
        "      -카페라떼 라지 2잔 (핫, 라지)\"\n",
        "      - **JSON Output**: None (as it is just a summary request without any new action).\n",
        "\n",
        "    - **Modifying an Existing Order**:\n",
        "      - **Customer Input**: \"주문한거 아이스 라떼로 바꿔줘.\"\n",
        "      - **Natural Language Response**: \"주문이 아메리카노에서 아이스 라떼로 변경되었습니다. 주문하신 내용은 다음과 같습니다:\n",
        "      -라떼 1잔 (아이스, 미디움)\"\n",
        "      - **JSON Output**:\n",
        "        ```json\n",
        "        {{\n",
        "          \"action\": \"modify_order\",\n",
        "          \"old_drink\": \"아메리카노\",\n",
        "          \"new_drink\": \"라떼\",\n",
        "          \"size\": \"미디움\",\n",
        "          \"temperature\": \"아이스\",\n",
        "          \"quantity\": 1,\n",
        "          \"add_ons\": [],\n",
        "          \"extra_shots\": 0\n",
        "        }}\n",
        "        ```\n",
        "\n",
        "    - **Short Names or Misspellings**:\n",
        "      - Recognize common shorthand or misspellings. For example:\n",
        "        - \"아아\" should be interpreted as \"아이스 아메리카노\".\n",
        "        - \"뜨아\" should be interpreted as \"핫 아메리카노\".\n",
        "\n",
        "    - **Unavailable Items**:\n",
        "      - If the customer requests an item not on the menu, respond politely and recommend a similar item if available.\n",
        "      - **Example**:\n",
        "        - **Customer Input**: \"초코라떼 주세요.\"\n",
        "        - **Natural Language Response**: \"죄송합니다, 초코라떼는 메뉴에 없습니다. 대신 초콜릿라떼를 추천드립니다.\"\n",
        "        - **JSON Output**:\n",
        "          ```json\n",
        "          {{\n",
        "            \"action\": \"recommend_closest_item\",\n",
        "            \"requested_item\": \"초코라떼\",\n",
        "            \"recommended_item\": \"초콜릿라떼\"\n",
        "          }}\n",
        "          ```\n",
        "\n",
        "    - **Order Confirmation**:\n",
        "      - **Customer Input**: \"주문 완료할게요.\"\n",
        "      - **Natural Language Response**: \"주문이 완료되었습니다. 결제는 카드리더기를 사용해주세요. 감사합니다.\"\n",
        "      - **JSON Output**: Clear/reset for the next session.\n",
        "\n",
        "    **Response Rules**:\n",
        "    - Treat each new input as part of the same order until \"주문 완료할게\" is received, which finalizes the order.\n",
        "    - Always confirm the latest action first in the natural language response, followed by a full order summary.\n",
        "    - Ensure each JSON output reflects only the latest request, not the entire order history.\n",
        "\n",
        "    Based on this information,\n",
        "    (keep in mind that) Each JSON output should only contain the items directly requested in **Customer's New Input**, not a full history.\n",
        "    if **Current Conversation History**:\n",
        "    {formatted_history}\n",
        "\n",
        "    based on **Cumulative Order Summary So Far**:\n",
        "    {formatted_summary}\n",
        "\n",
        "    and **Customer's New Input**: \"{user_input}\"\n",
        "\n",
        "    generate the appropriate natural language response and JSON output\n",
        "    \"\"\"\n",
        "    return base_prompt.strip()\n",
        "\n",
        "# Function to get response from the Korean model pipeline\n",
        "def get_response(prompt):\n",
        "    response = model(prompt, max_new_tokens=150, num_return_sequences=1, temperature=0.1, top_p=0.9, truncation=True)\n",
        "    return response[0]['generated_text']\n",
        "\n",
        "# Function to parse response into natural language and JSON output\n",
        "def parse_response(response):\n",
        "    try:\n",
        "        natural_language_response, json_output = response.split(\"JSON Output:\")\n",
        "        json_data = json.loads(json_output.strip())\n",
        "        return natural_language_response.strip(), json_data\n",
        "    except ValueError as e:\n",
        "        print(\"Error parsing response:\", e)\n",
        "        return response, None\n",
        "\n",
        "# Main interaction loop\n",
        "print(\"Welcome to the virtual coffee kiosk! What would you like to order?\")\n",
        "input_counter = 1\n",
        "\n",
        "while not order_confirmed:\n",
        "    # Take user input\n",
        "    user_input = input(\"Customer: \")\n",
        "\n",
        "    # Check if customer confirms the order\n",
        "    if \"주문 완료할게\" in user_input:\n",
        "        order_confirmed = True\n",
        "        print(\"Kiosk: 주문이 완료되었습니다. 결제는 카드리더기를 사용해주세요. 감사합니다.\")\n",
        "        conversation_history.clear()\n",
        "        summary_history.clear()\n",
        "        continue\n",
        "\n",
        "\n",
        "    # Generate the prompt based on the conversation history and new user input\n",
        "    prompt = generate_prompt(conversation_history, user_input)\n",
        "\n",
        "    # Get the model's response\n",
        "    response = get_response(prompt)\n",
        "\n",
        "    # Add the latest user input to the conversation history\n",
        "    conversation_history.append(f\"Customer's {input_counter} Input: {user_input}\")\n",
        "    input_counter += 1\n",
        "\n",
        "    # Parse the model's response\n",
        "    natural_language_response, json_output = parse_response(response)\n",
        "\n",
        "    # Save natural language order summary to `summary_history`\n",
        "    if natural_language_response:\n",
        "        summary_line = natural_language_response.split(\"\\n\", 1)[1]  # Extracts summary part\n",
        "        summary_history.append(summary_line)\n",
        "\n",
        "    # Print the final natural language response for the customer\n",
        "    #print(\"Kiosk:\", natural_language_response)\n",
        "    # Print only the Natural Language Response and JSON Output in the required format\n",
        "    print(\"**Natural Language Response**:\")\n",
        "    print(natural_language_response)\n",
        "    print(\"\\n**JSON Output**:\")\n",
        "    print(json.dumps(json_output, indent=2, ensure_ascii=False))  # Pretty-print JSON output\n",
        "\n",
        "    # Special handling for order summary requests\n",
        "    if \"내가 지금까지 뭘 주문했지\" in user_input:\n",
        "        # Provide cumulative order summary as a natural response without JSON output\n",
        "        print(\"Kiosk:\", \"지금까지의 주문내역입니다:\\n\" + \"\\n\".join(summary_history))\n",
        "\n",
        "    # Handle order cancellation requests\n",
        "    if \"주문 취소\" in user_input:\n",
        "        # Clear conversation history and summary history for a reset\n",
        "        print(\"Kiosk: 주문이 취소되었습니다. 새 주문을 시작해 주세요.\")\n",
        "        conversation_history.clear()\n",
        "        summary_history.clear()\n",
        "        input_counter = 1\n",
        "\n",
        "# End of the session\n",
        "print(\"Thank you for using the coffee kiosk!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwLEaWeygLRM",
        "outputId": "db490500-ca6b-432b-928e-e9ea7bae03b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"fatih0122\"\n",
        "!git config --global user.email \"m.fatih012001@gmail.com\""
      ],
      "metadata": {
        "id": "sN8DsYpogNz9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AI-coffee-Kiosk/Prompting-for-llama.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKP4h02-hPkq",
        "outputId": "6389e5db-f01b-46e0-9f7c-f3fedd23c4bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Prompting-for-llama'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!cp \"/content/promptforkrmodel.ipynb\" \"/content/Prompting-for-llama/\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNgTQATLi7dS",
        "outputId": "844dfe44-f014-483d-bc91-175993d54cc0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/promptforkrmodel.ipynb': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}