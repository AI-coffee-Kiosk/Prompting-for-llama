{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d0a84780ec844a2b56e62595e4ea546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_196744c857fc452a9dbf1d70e9fd01e7",
              "IPY_MODEL_893fc9abbfa64b5fbaa2ab279a14a723",
              "IPY_MODEL_da6bf22606f24e298ea752830c90cb8d"
            ],
            "layout": "IPY_MODEL_2a318e6b4bd24de0921ff1b17fdb798a"
          }
        },
        "196744c857fc452a9dbf1d70e9fd01e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b096709ab6344ae81cf30b73bd2b2a6",
            "placeholder": "​",
            "style": "IPY_MODEL_862bcaf6aa3d4b999b631b6a9cc41d0a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "893fc9abbfa64b5fbaa2ab279a14a723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdbc9c7b96684628b4e18ca40da4c9cc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0978507310bf4775aea9c9e4e830d2f5",
            "value": 2
          }
        },
        "da6bf22606f24e298ea752830c90cb8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be00f38974c142208eeadaa66cfecdfa",
            "placeholder": "​",
            "style": "IPY_MODEL_9cca94219596472c9ed6f8992495d31f",
            "value": " 2/2 [00:26&lt;00:00, 11.92s/it]"
          }
        },
        "2a318e6b4bd24de0921ff1b17fdb798a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b096709ab6344ae81cf30b73bd2b2a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "862bcaf6aa3d4b999b631b6a9cc41d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdbc9c7b96684628b4e18ca40da4c9cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0978507310bf4775aea9c9e4e830d2f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be00f38974c142208eeadaa66cfecdfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cca94219596472c9ed6f8992495d31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a01999060184b2cb2f7fa49fc7ea2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d68e76fd3de44fdbdf70ce4f4cf56a5",
              "IPY_MODEL_f33ae5b3e1bd48fc8670b85f80ab3c2e",
              "IPY_MODEL_e70394190082444e9015ccb2d24c042d"
            ],
            "layout": "IPY_MODEL_5703d63fed2a4a89baec743a8e62ee88"
          }
        },
        "2d68e76fd3de44fdbdf70ce4f4cf56a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_436f4603c40b4621a123d96cf3065248",
            "placeholder": "​",
            "style": "IPY_MODEL_396a9b55609548168490e4d74c5cc52c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f33ae5b3e1bd48fc8670b85f80ab3c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c6b583a61ff41f593abdd566ef82bcc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_823d5f70ef1f40da85d16ba7852d6474",
            "value": 2
          }
        },
        "e70394190082444e9015ccb2d24c042d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_417b3d9c87434dd0a6391bc19f0738f6",
            "placeholder": "​",
            "style": "IPY_MODEL_0fb9b775ba6c4e7b8fed957c73de8a0d",
            "value": " 2/2 [00:26&lt;00:00, 11.93s/it]"
          }
        },
        "5703d63fed2a4a89baec743a8e62ee88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "436f4603c40b4621a123d96cf3065248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "396a9b55609548168490e4d74c5cc52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c6b583a61ff41f593abdd566ef82bcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "823d5f70ef1f40da85d16ba7852d6474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "417b3d9c87434dd0a6391bc19f0738f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fb9b775ba6c4e7b8fed957c73de8a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79c30191b7214cf598c2bb1a883a8cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_555e650fd5544f838921fc993186b2f6",
              "IPY_MODEL_a67cd84efcec4d4896f41955e272c9ab",
              "IPY_MODEL_600d532ac4a144a7990d9fa22e6dd4b8"
            ],
            "layout": "IPY_MODEL_e8c5340032c748f58e3b452713f3cfd3"
          }
        },
        "555e650fd5544f838921fc993186b2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c96412a7509f4b7ea1d232feafe4f414",
            "placeholder": "​",
            "style": "IPY_MODEL_38f172da07c541bc9901d20ab0b8d50b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a67cd84efcec4d4896f41955e272c9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c54dba6d08624c89acc65026ec65fa4f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_941532563bf84f09935623eb9e0772ac",
            "value": 2
          }
        },
        "600d532ac4a144a7990d9fa22e6dd4b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0c79001d814488c807dede50d9ec315",
            "placeholder": "​",
            "style": "IPY_MODEL_3b2a8691fb3043e59e4c07def420c428",
            "value": " 2/2 [00:05&lt;00:00,  2.99s/it]"
          }
        },
        "e8c5340032c748f58e3b452713f3cfd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c96412a7509f4b7ea1d232feafe4f414": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38f172da07c541bc9901d20ab0b8d50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c54dba6d08624c89acc65026ec65fa4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "941532563bf84f09935623eb9e0772ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0c79001d814488c807dede50d9ec315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2a8691fb3043e59e4c07def420c428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "9d0a84780ec844a2b56e62595e4ea546",
            "196744c857fc452a9dbf1d70e9fd01e7",
            "893fc9abbfa64b5fbaa2ab279a14a723",
            "da6bf22606f24e298ea752830c90cb8d",
            "2a318e6b4bd24de0921ff1b17fdb798a",
            "8b096709ab6344ae81cf30b73bd2b2a6",
            "862bcaf6aa3d4b999b631b6a9cc41d0a",
            "fdbc9c7b96684628b4e18ca40da4c9cc",
            "0978507310bf4775aea9c9e4e830d2f5",
            "be00f38974c142208eeadaa66cfecdfa",
            "9cca94219596472c9ed6f8992495d31f"
          ]
        },
        "id": "VPF1UFtrEAyE",
        "outputId": "d65a0d64-7c6d-4f03-a787-22ae7688bf90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d0a84780ec844a2b56e62595e4ea546"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coffee Kiosk initialized and ready to take orders.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer  # Assuming Bllossom's llama model uses the Hugging Face transformers library\n",
        "import torch\n",
        "import json\n",
        "\n",
        "# Define our coffee kiosk class to handle orders, responses, and JSON generation\n",
        "class CoffeeKiosk:\n",
        "    def __init__(self):\n",
        "        # Model name for Bllossom's Llama\n",
        "        model_name = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n",
        "\n",
        "        # Initialize the tokenizer and model\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "        # Available menu items\n",
        "        self.menu_items = [\n",
        "            \"아메리카노\", \"라떼\", \"카푸치노\", \"카페모카\", \"바닐라라떼\",\n",
        "            \"에스프레소\", \"카라멜마끼아또\", \"허브티\", \"홍차\", \"초콜릿라떼\",\n",
        "            \"레몬에이드\", \"복숭아아이스티\", \"딸기스무디\", \"망고스무디\",\n",
        "            \"키위주스\", \"토마토주스\"\n",
        "        ]\n",
        "\n",
        "        # Initialize order history and defaults\n",
        "        self.order_history = []\n",
        "        self.default_size = \"미디움\"\n",
        "        self.default_temperature = \"핫\"\n",
        "\n",
        "    # Function to reset order history for a new session\n",
        "    def reset_order(self):\n",
        "        self.order_history = []\n",
        "\n",
        "    # Function to check if a drink is available in the menu\n",
        "    def is_menu_item(self, drink_name):\n",
        "        return drink_name in self.menu_items\n",
        "\n",
        "# Initialize CoffeeKiosk instance\n",
        "kiosk = CoffeeKiosk()\n",
        "\n",
        "print(\"Coffee Kiosk initialized and ready to take orders.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CoffeeKiosk:\n",
        "    def __init__(self):\n",
        "        # Initialize menu, order history, and defaults\n",
        "        self.menu_items = [\n",
        "            \"아메리카노\", \"라떼\", \"카푸치노\", \"카페모카\", \"바닐라라떼\",\n",
        "            \"에스프레소\", \"카라멜마끼아또\", \"허브티\", \"홍차\", \"초콜릿라떼\",\n",
        "            \"레몬에이드\", \"복숭아아이스티\", \"딸기스무디\", \"망고스무디\",\n",
        "            \"키위주스\", \"토마토주스\"\n",
        "        ]\n",
        "        self.order_history = []\n",
        "        self.default_size = \"미디움\"\n",
        "        self.default_temperature = \"핫\"\n",
        "        self.shorthand_mapping = {\n",
        "            \"아아\": \"아이스 아메리카노\",\n",
        "            \"뜨아\": \"핫 아메리카노\"\n",
        "        }\n",
        "\n",
        "    def reset_order(self):\n",
        "        \"\"\"Reset the order history for a new customer session.\"\"\"\n",
        "        self.order_history = []\n",
        "\n",
        "    def is_menu_item(self, drink_name):\n",
        "        \"\"\"Check if a drink is on the menu, including shorthand names.\"\"\"\n",
        "        return drink_name in self.menu_items or drink_name in self.shorthand_mapping\n",
        "\n",
        "    def suggest_alternative(self, drink_name):\n",
        "        \"\"\"Suggest a similar item if requested item is unavailable.\"\"\"\n",
        "        if drink_name == \"초코라떼\":\n",
        "            return \"초콜릿라떼\"\n",
        "        return None\n",
        "\n",
        "    def add_order_item(self, drink, quantity=1, temperature=None, size=None, add_ons=None, extra_shots=0):\n",
        "        \"\"\"Add a new item to the order.\"\"\"\n",
        "        # Map shorthand to full drink name if necessary\n",
        "        drink = self.shorthand_mapping.get(drink, drink)\n",
        "\n",
        "        # Default values if not specified\n",
        "        size = size or self.default_size\n",
        "        temperature = temperature or self.default_temperature\n",
        "        add_ons = add_ons or []\n",
        "\n",
        "        item = {\n",
        "            \"drink\": drink,\n",
        "            \"quantity\": quantity,\n",
        "            \"temperature\": temperature,\n",
        "            \"size\": size,\n",
        "            \"add_ons\": add_ons,\n",
        "            \"extra_shots\": extra_shots\n",
        "        }\n",
        "\n",
        "        self.order_history.append(item)\n",
        "\n",
        "        latest_item_response = f\"{drink} {quantity}잔 주문되었습니다.\"\n",
        "        full_summary = self.get_order_summary()\n",
        "        response = f\"{latest_item_response} {full_summary}\"\n",
        "\n",
        "        # JSON output only for the latest item\n",
        "        json_output = {\n",
        "            \"action\": \"create_order\",\n",
        "            \"order_items\": [new_item]\n",
        "        }\n",
        "        return response, json_output\n",
        "\n",
        "    def modify_order(self, old_drink, new_drink, temperature=None, size=None, add_ons=None, extra_shots=0):\n",
        "        \"\"\"Modify an existing order item.\"\"\"\n",
        "        # Locate the item in order history\n",
        "        for item in self.order_history:\n",
        "            if item[\"drink\"] == old_drink:\n",
        "                # Update details\n",
        "                item.update({\n",
        "                    \"drink\": new_drink,\n",
        "                    \"temperature\": temperature or item[\"temperature\"],\n",
        "                    \"size\": size or item[\"size\"],\n",
        "                    \"add_ons\": add_ons or item[\"add_ons\"],\n",
        "                    \"extra_shots\": extra_shots or item[\"extra_shots\"]\n",
        "                })\n",
        "\n",
        "                response = f\"주문이 {old_drink}에서 {new_drink}로 변경되었습니다. {self.get_order_summary()}\"\n",
        "                json_output = {\n",
        "                    \"action\": \"modify_order\",\n",
        "                    \"old_drink\": old_drink,\n",
        "                    \"new_drink\": new_drink,\n",
        "                    \"temperature\": item[\"temperature\"],\n",
        "                    \"size\": item[\"size\"],\n",
        "                    \"quantity\": item[\"quantity\"],\n",
        "                    \"add_ons\": item[\"add_ons\"],\n",
        "                    \"extra_shots\": item[\"extra_shots\"]\n",
        "                }\n",
        "                return response, json_output\n",
        "\n",
        "        # If not found\n",
        "        return f\"{old_drink}는 주문 내역에 없습니다.\", None\n",
        "\n",
        "    def get_order_summary(self):\n",
        "      \"\"\"Generate a comprehensive summary of the current order history.\"\"\"\n",
        "      if not self.order_history:\n",
        "        return \"현재 주문된 항목이 없습니다.\"\n",
        "\n",
        "      summary = \"주문하신 내용은 다음과 같습니다:\"\n",
        "      for item in self.order_history:\n",
        "            drink_summary = (\n",
        "                f\"- {item['drink']} {item['quantity']}잔 \"\n",
        "                f\"({item['temperature']}, {item['size']}\"\n",
        "            )\n",
        "            if item['add_ons']:\n",
        "                drink_summary += f\", 추가 옵션: {', '.join(item['add_ons'])}\"\n",
        "            if item['extra_shots']:\n",
        "                drink_summary += f\", 샷 추가: {item['extra_shots']}회\"\n",
        "            drink_summary += \")\"\n",
        "            summary += f\"\\n{drink_summary}\"\n",
        "      return summary\n",
        "\n",
        "    def summarize_order_history(self):\n",
        "        \"\"\"Provide a summary of the entire order history without adding new JSON output.\"\"\"\n",
        "        if not self.order_history:\n",
        "           return \"현재 주문된 항목이 없습니다.\", None\n",
        "\n",
        "           response = f\"지금까지의 주문내역입니다:\\n{self.get_order_summary()}\"\n",
        "           return response, None\n",
        "\n",
        "    def process_input(self, input_text):\n",
        "        \"\"\"Process customer input and route to the correct functionality.\"\"\"\n",
        "        # Check for order completion\n",
        "        if \"주문 완료할게\" in input_text:\n",
        "            response = \"주문이 완료되었습니다. 결제는 카드리더기를 사용해주세요. 감사합니다.\"\n",
        "            json_output = {\n",
        "                \"action\": \"complete_order\",\n",
        "                \"order_items\": self.order_history\n",
        "            }\n",
        "            self.reset_order()\n",
        "            return response, json_output\n",
        "\n",
        "        if \"지금까지 뭘 주문했지\" in input_text:\n",
        "            response = self.get_order_summary()\n",
        "            json_output = None  # No JSON output for history summary\n",
        "            return response, json_output\n",
        "\n",
        "        # Handle new order or modification based on input\n",
        "        drink = None\n",
        "        for item in self.menu_items + list(self.shorthand_mapping.keys()):\n",
        "            if item in input_text:\n",
        "                drink = self.shorthand_mapping.get(item, item)\n",
        "                break\n",
        "\n",
        "        # If drink is not found, suggest alternatives\n",
        "        if not drink:\n",
        "            alternative = self.suggest_alternative(input_text)\n",
        "            if alternative:\n",
        "                response = f\"죄송합니다, {input_text}는 메뉴에 없습니다. 대신 {alternative}를 추천드립니다.\"\n",
        "                json_output = {\n",
        "                    \"action\": \"recommend_closest_item\",\n",
        "                    \"requested_item\": input_text,\n",
        "                    \"recommended_item\": alternative\n",
        "                }\n",
        "            else:\n",
        "                response = f\"죄송합니다, {input_text}는 메뉴에 없습니다.\"\n",
        "                json_output = None\n",
        "            return response, json_output\n",
        "\n",
        "        # Process adding the new item to the order\n",
        "        parsed_order = self.parse_order_input(input_text)\n",
        "        if parsed_order:\n",
        "            response, json_output = self.add_order_item(\n",
        "                drink=parsed_order[\"drink\"],\n",
        "                quantity=parsed_order.get(\"quantity\", 1),\n",
        "                temperature=parsed_order.get(\"temperature\"),\n",
        "                size=parsed_order.get(\"size\"),\n",
        "                add_ons=parsed_order.get(\"add_ons\", []),\n",
        "                extra_shots=parsed_order.get(\"extra_shots\", 0)\n",
        "            )\n",
        "            return response, json_output\n",
        "\n",
        "\n",
        "    def parse_order_input(self, input_text):\n",
        "        \"\"\"Parse input text to determine drink details.\"\"\"\n",
        "        # Example parsing logic\n",
        "        drink = None\n",
        "        for item in self.menu_items:\n",
        "            if item in input_text:\n",
        "                drink = item\n",
        "                break\n",
        "\n",
        "        if not drink:\n",
        "            return None\n",
        "\n",
        "        quantity = 1\n",
        "        if \"두잔\" in input_text:\n",
        "            quantity = 2\n",
        "        elif \"세잔\" in input_text:\n",
        "            quantity = 3\n",
        "\n",
        "        temperature = \"아이스\" if \"아이스\" in input_text else None\n",
        "        size = \"라지\" if \"라지\" in input_text else None\n",
        "\n",
        "        return {\n",
        "            \"drink\": drink,\n",
        "            \"quantity\": quantity,\n",
        "            \"temperature\": temperature,\n",
        "            \"size\": size\n",
        "        }\n"
      ],
      "metadata": {
        "id": "tm66uW6LUm3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import json\n",
        "\n",
        "# Define our coffee kiosk class to handle orders, responses, and JSON generation\n",
        "class CoffeeKiosk:\n",
        "    def __init__(self):\n",
        "        # Initialize menu, order history, and defaults\n",
        "        self.menu_items = [\n",
        "            \"아메리카노\", \"라떼\", \"카푸치노\", \"카페모카\", \"바닐라라떼\",\n",
        "            \"에스프레소\", \"카라멜마끼아또\", \"허브티\", \"홍차\", \"초콜릿라떼\",\n",
        "            \"레몬에이드\", \"복숭아아이스티\", \"딸기스무디\", \"망고스무디\",\n",
        "            \"키위주스\", \"토마토주스\"\n",
        "        ]\n",
        "        self.order_history = []\n",
        "        self.default_size = \"미디움\"\n",
        "        self.default_temperature = \"핫\"\n",
        "        self.shorthand_mapping = {\n",
        "            \"아아\": \"아이스 아메리카노\",\n",
        "            \"뜨아\": \"핫 아메리카노\"\n",
        "        }\n",
        "\n",
        "    def reset_order(self):\n",
        "        \"\"\"Reset the order history for a new customer session.\"\"\"\n",
        "        self.order_history = []\n",
        "\n",
        "    def is_menu_item(self, drink_name):\n",
        "        \"\"\"Check if a drink is on the menu, including shorthand names.\"\"\"\n",
        "        return drink_name in self.menu_items or drink_name in self.shorthand_mapping\n",
        "\n",
        "    def suggest_alternative(self, drink_name):\n",
        "        \"\"\"Suggest a similar item if requested item is unavailable.\"\"\"\n",
        "        if drink_name == \"초코라떼\":\n",
        "            return \"초콜릿라떼\"\n",
        "        return None\n",
        "\n",
        "    def add_order_item(self, drink, quantity=1, temperature=None, size=None, add_ons=None, extra_shots=0):\n",
        "        \"\"\"Add a new item to the order.\"\"\"\n",
        "        # Map shorthand to full drink name if necessary\n",
        "        drink = self.shorthand_mapping.get(drink, drink)\n",
        "\n",
        "        # Default values if not specified\n",
        "        size = size or self.default_size\n",
        "        temperature = temperature or self.default_temperature\n",
        "        add_ons = add_ons or []\n",
        "\n",
        "        item = {\n",
        "            \"drink\": drink,\n",
        "            \"quantity\": quantity,\n",
        "            \"temperature\": temperature,\n",
        "            \"size\": size,\n",
        "            \"add_ons\": add_ons,\n",
        "            \"extra_shots\": extra_shots\n",
        "        }\n",
        "\n",
        "        self.order_history.append(item)\n",
        "\n",
        "        latest_item_response = f\"{drink} {quantity}잔 주문되었습니다.\"\n",
        "        full_summary = self.get_order_summary()\n",
        "        response = f\"{latest_item_response} {full_summary}\"\n",
        "\n",
        "        # JSON output only for the latest item\n",
        "        json_output = {\n",
        "            \"action\": \"create_order\",\n",
        "            \"order_items\": [item]\n",
        "        }\n",
        "        return response, json_output\n",
        "\n",
        "    def modify_order(self, old_drink, new_drink, temperature=None, size=None, add_ons=None, extra_shots=0):\n",
        "        \"\"\"Modify an existing order item.\"\"\"\n",
        "        # Locate the item in order history\n",
        "        for item in self.order_history:\n",
        "            if item[\"drink\"] == old_drink:\n",
        "                # Update details\n",
        "                item.update({\n",
        "                    \"drink\": new_drink,\n",
        "                    \"temperature\": temperature or item[\"temperature\"],\n",
        "                    \"size\": size or item[\"size\"],\n",
        "                    \"add_ons\": add_ons or item[\"add_ons\"],\n",
        "                    \"extra_shots\": extra_shots or item[\"extra_shots\"]\n",
        "                })\n",
        "\n",
        "                response = f\"주문이 {old_drink}에서 {new_drink}로 변경되었습니다. {self.get_order_summary()}\"\n",
        "                json_output = {\n",
        "                    \"action\": \"modify_order\",\n",
        "                    \"old_drink\": old_drink,\n",
        "                    \"new_drink\": new_drink,\n",
        "                    \"temperature\": item[\"temperature\"],\n",
        "                    \"size\": item[\"size\"],\n",
        "                    \"quantity\": item[\"quantity\"],\n",
        "                    \"add_ons\": item[\"add_ons\"],\n",
        "                    \"extra_shots\": item[\"extra_shots\"]\n",
        "                }\n",
        "                return response, json_output\n",
        "\n",
        "        # If not found\n",
        "        return f\"{old_drink}는 주문 내역에 없습니다.\", None\n",
        "\n",
        "    def get_order_summary(self):\n",
        "        \"\"\"Generate a comprehensive summary of the current order history.\"\"\"\n",
        "        if not self.order_history:\n",
        "            return \"현재 주문된 항목이 없습니다.\"\n",
        "\n",
        "        summary = \"주문하신 내용은 다음과 같습니다:\"\n",
        "        for item in self.order_history:\n",
        "            drink_summary = (\n",
        "                f\"- {item['drink']} {item['quantity']}잔 \"\n",
        "                f\"({item['temperature']}, {item['size']}\"\n",
        "            )\n",
        "            if item['add_ons']:\n",
        "                drink_summary += f\", 추가 옵션: {', '.join(item['add_ons'])}\"\n",
        "            if item['extra_shots']:\n",
        "                drink_summary += f\", 샷 추가: {item['extra_shots']}회\"\n",
        "            drink_summary += \")\"\n",
        "            summary += f\"\\n{drink_summary}\"\n",
        "        return summary\n",
        "\n",
        "    def summarize_order_history(self):\n",
        "        \"\"\"Provide a summary of the entire order history without adding new JSON output.\"\"\"\n",
        "        if not self.order_history:\n",
        "            return \"현재 주문된 항목이 없습니다.\", None\n",
        "\n",
        "        response = f\"지금까지의 주문내역입니다:\\n{self.get_order_summary()}\"\n",
        "        return response, None\n",
        "\n",
        "    def process_input(self, input_text):\n",
        "        \"\"\"Process customer input and route to the correct functionality.\"\"\"\n",
        "        # Check for order completion\n",
        "        if \"주문 완료할게\" in input_text:\n",
        "            response = \"주문이 완료되었습니다. 결제는 카드리더기를 사용해주세요. 감사합니다.\"\n",
        "            json_output = {\n",
        "                \"action\": \"complete_order\",\n",
        "                \"order_items\": self.order_history\n",
        "            }\n",
        "            self.reset_order()\n",
        "            return response, json_output\n",
        "\n",
        "        if \"지금까지 뭘 주문했지\" in input_text:\n",
        "            response = self.get_order_summary()\n",
        "            json_output = None  # No JSON output for history summary\n",
        "            return response, json_output\n",
        "\n",
        "        # Handle new order or modification based on input\n",
        "        drink = None\n",
        "        for item in self.menu_items + list(self.shorthand_mapping.keys()):\n",
        "            if item in input_text:\n",
        "                drink = self.shorthand_mapping.get(item, item)\n",
        "                break\n",
        "\n",
        "        # If drink is not found, suggest alternatives\n",
        "        if not drink:\n",
        "            alternative = self.suggest_alternative(input_text)\n",
        "            if alternative:\n",
        "                response = f\"죄송합니다, {input_text}는 메뉴에 없습니다. 대신 {alternative}를 추천드립니다.\"\n",
        "                json_output = {\n",
        "                    \"action\": \"recommend_closest_item\",\n",
        "                    \"requested_item\": input_text,\n",
        "                    \"recommended_item\": alternative\n",
        "                }\n",
        "            else:\n",
        "                response = f\"죄송합니다, {input_text}는 메뉴에 없습니다.\"\n",
        "                json_output = None\n",
        "            return response, json_output\n",
        "\n",
        "        # Process adding the new item to the order\n",
        "        parsed_order = self.parse_order_input(input_text)\n",
        "        if parsed_order:\n",
        "            response, json_output = self.add_order_item(\n",
        "                drink=parsed_order[\"drink\"],\n",
        "                quantity=parsed_order.get(\"quantity\", 1),\n",
        "                temperature=parsed_order.get(\"temperature\"),\n",
        "                size=parsed_order.get(\"size\"),\n",
        "                add_ons=parsed_order.get(\"add_ons\", []),\n",
        "                extra_shots=parsed_order.get(\"extra_shots\", 0)\n",
        "            )\n",
        "            return response, json_output\n",
        "\n",
        "\n",
        "    def parse_order_input(self, input_text):\n",
        "        \"\"\"Parse input text to determine drink details.\"\"\"\n",
        "        # Example parsing logic\n",
        "        drink = None\n",
        "        for item in self.menu_items:\n",
        "            if item in input_text:\n",
        "                drink = item\n",
        "                break\n",
        "\n",
        "        if not drink:\n",
        "            return None\n",
        "\n",
        "        quantity = 1\n",
        "        if \"두잔\" in input_text:\n",
        "            quantity = 2\n",
        "        elif \"세잔\" in input_text:\n",
        "            quantity = 3\n",
        "\n",
        "        temperature = \"아이스\" if \"아이스\" in input_text else None\n",
        "        size = \"라지\" if \"라지\" in input_text else None\n",
        "\n",
        "        return {\n",
        "            \"drink\": drink,\n",
        "            \"quantity\": quantity,\n",
        "            \"temperature\": temperature,\n",
        "            \"size\": size\n",
        "        }\n",
        "\n",
        "# Initialize the coffee kiosk instance\n",
        "kiosk = CoffeeKiosk()\n",
        "\n",
        "# Interactive loop to simulate continuous conversation\n",
        "print(\"Coffee Kiosk initialized and ready to take orders.\")\n",
        "while True:\n",
        "    customer_input = input(\"Customer: \")\n",
        "    response, json_output = kiosk.process_input(customer_input)\n",
        "    print(\"Kiosk:\", response)\n",
        "    if json_output:\n",
        "        print(\"JSON Output:\", json.dumps(json_output, ensure_ascii=False, indent=2))\n",
        "    if \"주문 완료할게\" in customer_input:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a5Ad3UrIU2Ok",
        "outputId": "1e214a39-f529-4ea3-9d4b-3c1553e86c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coffee Kiosk initialized and ready to take orders.\n",
            "Customer: 아메리카노 한잔주세요\n",
            "Kiosk: 아메리카노 1잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
            "- 아메리카노 1잔 (핫, 미디움)\n",
            "JSON Output: {\n",
            "  \"action\": \"create_order\",\n",
            "  \"order_items\": [\n",
            "    {\n",
            "      \"drink\": \"아메리카노\",\n",
            "      \"quantity\": 1,\n",
            "      \"temperature\": \"핫\",\n",
            "      \"size\": \"미디움\",\n",
            "      \"add_ons\": [],\n",
            "      \"extra_shots\": 0\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Customer:  에스프레소 두잔 시원하게 주실래요?\n",
            "Kiosk: 에스프레소 2잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
            "- 아메리카노 1잔 (핫, 미디움)\n",
            "- 에스프레소 2잔 (핫, 미디움)\n",
            "JSON Output: {\n",
            "  \"action\": \"create_order\",\n",
            "  \"order_items\": [\n",
            "    {\n",
            "      \"drink\": \"에스프레소\",\n",
            "      \"quantity\": 2,\n",
            "      \"temperature\": \"핫\",\n",
            "      \"size\": \"미디움\",\n",
            "      \"add_ons\": [],\n",
            "      \"extra_shots\": 0\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Customer: 핫 아메리카노 2잔이랑 아이스 아메리카노 3잔 주세요\n",
            "Kiosk: 아메리카노 1잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
            "- 아메리카노 1잔 (핫, 미디움)\n",
            "- 에스프레소 2잔 (핫, 미디움)\n",
            "- 아메리카노 1잔 (아이스, 미디움)\n",
            "JSON Output: {\n",
            "  \"action\": \"create_order\",\n",
            "  \"order_items\": [\n",
            "    {\n",
            "      \"drink\": \"아메리카노\",\n",
            "      \"quantity\": 1,\n",
            "      \"temperature\": \"아이스\",\n",
            "      \"size\": \"미디움\",\n",
            "      \"add_ons\": [],\n",
            "      \"extra_shots\": 0\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7d176ec75a69>\u001b[0m in \u001b[0;36m<cell line: 211>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Coffee Kiosk initialized and ready to take orders.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mcustomer_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Customer: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkiosk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomer_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Kiosk:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import json\n",
        "\n",
        "# Define our coffee kiosk class to handle orders, responses, and JSON generation\n",
        "class CoffeeKiosk:\n",
        "    def __init__(self):\n",
        "        # Model name for Bllossom's Llama\n",
        "        model_name = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n",
        "\n",
        "        # Initialize the tokenizer and model\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "        # Available menu items\n",
        "        self.menu_items = [\n",
        "            \"아메리카노\", \"라떼\", \"카푸치노\", \"카페모카\", \"바닐라라떼\",\n",
        "            \"에스프레소\", \"카라멜마끼아또\", \"허브티\", \"홍차\", \"초콜릿라떼\",\n",
        "            \"레몬에이드\", \"복숭아아이스티\", \"딸기스무디\", \"망고스무디\",\n",
        "            \"키위주스\", \"토마토주스\"\n",
        "        ]\n",
        "        self.order_history = []\n",
        "        self.default_size = \"미디움\"\n",
        "        self.default_temperature = \"핫\"\n",
        "        self.shorthand_mapping = {\n",
        "            \"아아\": \"아이스 아메리카노\",\n",
        "            \"뜨아\": \"핫 아메리카노\"\n",
        "        }\n",
        "\n",
        "    def reset_order(self):\n",
        "        \"\"\"Reset the order history for a new customer session.\"\"\"\n",
        "        self.order_history = []\n",
        "\n",
        "    def is_menu_item(self, drink_name):\n",
        "        \"\"\"Check if a drink is on the menu, including shorthand names.\"\"\"\n",
        "        return drink_name in self.menu_items or drink_name in self.shorthand_mapping\n",
        "\n",
        "    def suggest_alternative(self, drink_name):\n",
        "        \"\"\"Suggest a similar item if requested item is unavailable.\"\"\"\n",
        "        if drink_name == \"초코라떼\":\n",
        "            return \"초콜릿라떼\"\n",
        "        return None\n",
        "\n",
        "    def add_order_item(self, drink, quantity=1, temperature=None, size=None, add_ons=None, extra_shots=0):\n",
        "        \"\"\"Add a new item to the order.\"\"\"\n",
        "        # Map shorthand to full drink name if necessary\n",
        "        drink = self.shorthand_mapping.get(drink, drink)\n",
        "\n",
        "        # Default values if not specified\n",
        "        size = size or self.default_size\n",
        "        temperature = temperature or self.default_temperature\n",
        "        add_ons = add_ons or []\n",
        "\n",
        "        item = {\n",
        "            \"drink\": drink,\n",
        "            \"quantity\": quantity,\n",
        "            \"temperature\": temperature,\n",
        "            \"size\": size,\n",
        "            \"add_ons\": add_ons,\n",
        "            \"extra_shots\": extra_shots\n",
        "        }\n",
        "\n",
        "        self.order_history.append(item)\n",
        "\n",
        "        latest_item_response = f\"{drink} {quantity}잔 주문되었습니다.\"\n",
        "        full_summary = self.get_order_summary()\n",
        "        response = f\"{latest_item_response} {full_summary}\"\n",
        "\n",
        "        # JSON output only for the latest item\n",
        "        json_output = {\n",
        "            \"action\": \"create_order\",\n",
        "            \"order_items\": [item]\n",
        "        }\n",
        "        return response, json_output\n",
        "\n",
        "    def modify_order(self, old_drink, new_drink, temperature=None, size=None, add_ons=None, extra_shots=0):\n",
        "        \"\"\"Modify an existing order item.\"\"\"\n",
        "        # Locate the item in order history\n",
        "        for item in self.order_history:\n",
        "            if item[\"drink\"] == old_drink:\n",
        "                # Update details\n",
        "                item.update({\n",
        "                    \"drink\": new_drink,\n",
        "                    \"temperature\": temperature or item[\"temperature\"],\n",
        "                    \"size\": size or item[\"size\"],\n",
        "                    \"add_ons\": add_ons or item[\"add_ons\"],\n",
        "                    \"extra_shots\": extra_shots or item[\"extra_shots\"]\n",
        "                })\n",
        "\n",
        "                response = f\"주문이 {old_drink}에서 {new_drink}로 변경되었습니다. {self.get_order_summary()}\"\n",
        "                json_output = {\n",
        "                    \"action\": \"modify_order\",\n",
        "                    \"old_drink\": old_drink,\n",
        "                    \"new_drink\": new_drink,\n",
        "                    \"temperature\": item[\"temperature\"],\n",
        "                    \"size\": item[\"size\"],\n",
        "                    \"quantity\": item[\"quantity\"],\n",
        "                    \"add_ons\": item[\"add_ons\"],\n",
        "                    \"extra_shots\": item[\"extra_shots\"]\n",
        "                }\n",
        "                return response, json_output\n",
        "\n",
        "        # If not found\n",
        "        return f\"{old_drink}는 주문 내역에 없습니다.\", None\n",
        "\n",
        "    def get_order_summary(self):\n",
        "      \"\"\"Generate a comprehensive summary of the current order history.\"\"\"\n",
        "      if not self.order_history:\n",
        "        return \"현재 주문된 항목이 없습니다.\"\n",
        "\n",
        "      summary = \"주문하신 내용은 다음과 같습니다:\"\n",
        "      for item in self.order_history:\n",
        "            drink_summary = (\n",
        "                f\"- {item['drink']} {item['quantity']}잔 \"\n",
        "                f\"({item['temperature']}, {item['size']}\"\n",
        "            )\n",
        "            if item['add_ons']:\n",
        "                drink_summary += f\", 추가 옵션: {', '.join(item['add_ons'])}\"\n",
        "            if item['extra_shots']:\n",
        "                drink_summary += f\", 샷 추가: {item['extra_shots']}회\"\n",
        "            drink_summary += \")\"\n",
        "            summary += f\"\\n{drink_summary}\"\n",
        "      return summary\n",
        "\n",
        "    def summarize_order_history(self):\n",
        "        \"\"\"Provide a summary of the entire order history without adding new JSON output.\"\"\"\n",
        "        if not self.order_history:\n",
        "           return \"현재 주문된 항목이 없습니다.\", None\n",
        "\n",
        "           response = f\"지금까지의 주문내역입니다:\\n{self.get_order_summary()}\"\n",
        "           return response, None\n",
        "\n",
        "    def process_input(self, input_text):\n",
        "        \"\"\"Process customer input and route to the correct functionality.\"\"\"\n",
        "        # Check for order completion\n",
        "        if \"주문 완료할게\" in input_text:\n",
        "            response = \"주문이 완료되었습니다. 결제는 카드리더기를 사용해주세요. 감사합니다.\"\n",
        "            json_output = {\n",
        "                \"action\": \"complete_order\",\n",
        "                \"order_items\": self.order_history\n",
        "            }\n",
        "            self.reset_order()\n",
        "            return response, json_output\n",
        "\n",
        "        if \"지금까지 뭘 주문했지\" in input_text:\n",
        "            response = self.get_order_summary()\n",
        "            json_output = None  # No JSON output for history summary\n",
        "            return response, json_output\n",
        "\n",
        "        # Handle new order or modification based on input\n",
        "        drink = None\n",
        "        for item in self.menu_items + list(self.shorthand_mapping.keys()):\n",
        "            if item in input_text:\n",
        "                drink = self.shorthand_mapping.get(item, item)\n",
        "                break\n",
        "\n",
        "        # If drink is not found, suggest alternatives\n",
        "        if not drink:\n",
        "            alternative = self.suggest_alternative(input_text)\n",
        "            if alternative:\n",
        "                response = f\"죄송합니다, {input_text}는 메뉴에 없습니다. 대신 {alternative}를 추천드립니다.\"\n",
        "                json_output = {\n",
        "                    \"action\": \"recommend_closest_item\",\n",
        "                    \"requested_item\": input_text,\n",
        "                    \"recommended_item\": alternative\n",
        "                }\n",
        "            else:\n",
        "                response = f\"죄송합니다, {input_text}는 메뉴에 없습니다.\"\n",
        "                json_output = None\n",
        "            return response, json_output\n",
        "\n",
        "        # Process adding the new item to the order\n",
        "        parsed_order = self.parse_order_input(input_text)\n",
        "        if parsed_order:\n",
        "            response, json_output = self.add_order_item(\n",
        "                drink=parsed_order[\"drink\"],\n",
        "                quantity=parsed_order.get(\"quantity\", 1),\n",
        "                temperature=parsed_order.get(\"temperature\"),\n",
        "                size=parsed_order.get(\"size\"),\n",
        "                add_ons=parsed_order.get(\"add_ons\", []),\n",
        "                extra_shots=parsed_order.get(\"extra_shots\", 0)\n",
        "            )\n",
        "            return response, json_output\n",
        "\n",
        "\n",
        "    def parse_order_input(self, input_text):\n",
        "        \"\"\"Parse input text to determine drink details.\"\"\"\n",
        "        # Example parsing logic\n",
        "        drink = None\n",
        "        for item in self.menu_items:\n",
        "            if item in input_text:\n",
        "                drink = item\n",
        "                break\n",
        "\n",
        "        if not drink:\n",
        "            return None\n",
        "\n",
        "        quantity = 1\n",
        "        if \"두잔\" in input_text:\n",
        "            quantity = 2\n",
        "        elif \"세잔\" in input_text:\n",
        "            quantity = 3\n",
        "\n",
        "        temperature = \"아이스\" if \"아이스\" in input_text else None\n",
        "        size = \"라지\" if \"라지\" in input_text else None\n",
        "\n",
        "        return {\n",
        "            \"drink\": drink,\n",
        "            \"quantity\": quantity,\n",
        "            \"temperature\": temperature,\n",
        "            \"size\": size\n",
        "        }\n",
        "\n",
        "    # Initialize the coffee kiosk instance\n",
        "kiosk = CoffeeKiosk()\n",
        "\n",
        "# Interactive loop to simulate continuous conversation\n",
        "print(\"Coffee Kiosk initialized and ready to take orders.\")\n",
        "while True:\n",
        "    customer_input = input(\"Customer: \")\n",
        "    response, json_output = kiosk.process_input(customer_input)\n",
        "    print(\"Kiosk:\", response)\n",
        "    if json_output:\n",
        "        print(\"JSON Output:\", json.dumps(json_output, ensure_ascii=False, indent=2))\n",
        "    if \"주문 완료할게\" in customer_input:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0a01999060184b2cb2f7fa49fc7ea2ca",
            "2d68e76fd3de44fdbdf70ce4f4cf56a5",
            "f33ae5b3e1bd48fc8670b85f80ab3c2e",
            "e70394190082444e9015ccb2d24c042d",
            "5703d63fed2a4a89baec743a8e62ee88",
            "436f4603c40b4621a123d96cf3065248",
            "396a9b55609548168490e4d74c5cc52c",
            "8c6b583a61ff41f593abdd566ef82bcc",
            "823d5f70ef1f40da85d16ba7852d6474",
            "417b3d9c87434dd0a6391bc19f0738f6",
            "0fb9b775ba6c4e7b8fed957c73de8a0d"
          ]
        },
        "id": "AHROVbl5iLSf",
        "outputId": "9e75ae89-84fe-425c-936e-d9c93de2a87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a01999060184b2cb2f7fa49fc7ea2ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coffee Kiosk initialized and ready to take orders.\n",
            "Customer: 카페라떼 라지로 2잔 주세요\n",
            "Kiosk: 라떼 1잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
            "- 라떼 1잔 (핫, 라지)\n",
            "JSON Output: {\n",
            "  \"action\": \"create_order\",\n",
            "  \"order_items\": [\n",
            "    {\n",
            "      \"drink\": \"라떼\",\n",
            "      \"quantity\": 1,\n",
            "      \"temperature\": \"핫\",\n",
            "      \"size\": \"라지\",\n",
            "      \"add_ons\": [],\n",
            "      \"extra_shots\": 0\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Customer: 에스프레소 두잔 시원하게 주실래요?\n",
            "Kiosk: 에스프레소 2잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
            "- 라떼 1잔 (핫, 라지)\n",
            "- 에스프레소 2잔 (핫, 미디움)\n",
            "JSON Output: {\n",
            "  \"action\": \"create_order\",\n",
            "  \"order_items\": [\n",
            "    {\n",
            "      \"drink\": \"에스프레소\",\n",
            "      \"quantity\": 2,\n",
            "      \"temperature\": \"핫\",\n",
            "      \"size\": \"미디움\",\n",
            "      \"add_ons\": [],\n",
            "      \"extra_shots\": 0\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Customer: 아메리카노 한잔 주시고 카라멜마끼아또도 엑스라지로 한잔만 주세요\n",
            "Kiosk: 아메리카노 1잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
            "- 라떼 1잔 (핫, 라지)\n",
            "- 에스프레소 2잔 (핫, 미디움)\n",
            "- 아메리카노 1잔 (핫, 라지)\n",
            "JSON Output: {\n",
            "  \"action\": \"create_order\",\n",
            "  \"order_items\": [\n",
            "    {\n",
            "      \"drink\": \"아메리카노\",\n",
            "      \"quantity\": 1,\n",
            "      \"temperature\": \"핫\",\n",
            "      \"size\": \"라지\",\n",
            "      \"add_ons\": [],\n",
            "      \"extra_shots\": 0\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Customer: 초콜릿라떼 두잔이랑 바닐라라떼 한잔 주세요\n",
            "Kiosk: 라떼 2잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
            "- 라떼 1잔 (핫, 라지)\n",
            "- 에스프레소 2잔 (핫, 미디움)\n",
            "- 아메리카노 1잔 (핫, 라지)\n",
            "- 라떼 2잔 (핫, 미디움)\n",
            "JSON Output: {\n",
            "  \"action\": \"create_order\",\n",
            "  \"order_items\": [\n",
            "    {\n",
            "      \"drink\": \"라떼\",\n",
            "      \"quantity\": 2,\n",
            "      \"temperature\": \"핫\",\n",
            "      \"size\": \"미디움\",\n",
            "      \"add_ons\": [],\n",
            "      \"extra_shots\": 0\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Customer: 아이스 아메리카노 4잔이랑 카페라떼 라지로 2잔 아이스 카라멜마끼아또 엑스라지로 휘핑크림 추가해서 3잔 주세요\n",
            "Kiosk: 아메리카노 1잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
            "- 라떼 1잔 (핫, 라지)\n",
            "- 에스프레소 2잔 (핫, 미디움)\n",
            "- 아메리카노 1잔 (핫, 라지)\n",
            "- 라떼 2잔 (핫, 미디움)\n",
            "- 아메리카노 1잔 (아이스, 라지)\n",
            "JSON Output: {\n",
            "  \"action\": \"create_order\",\n",
            "  \"order_items\": [\n",
            "    {\n",
            "      \"drink\": \"아메리카노\",\n",
            "      \"quantity\": 1,\n",
            "      \"temperature\": \"아이스\",\n",
            "      \"size\": \"라지\",\n",
            "      \"add_ons\": [],\n",
            "      \"extra_shots\": 0\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c2302a7b7673>\u001b[0m in \u001b[0;36m<cell line: 220>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Coffee Kiosk initialized and ready to take orders.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mcustomer_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Customer: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkiosk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomer_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Kiosk:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import json\n",
        "\n",
        "class CoffeeKiosk:\n",
        "    def __init__(self):\n",
        "        # Model setup for Llama\n",
        "        model_name = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n",
        "\n",
        "        # Load tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        # Set device to GPU if available, otherwise CPU\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Load model and move to specified device\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_name).to(self.device)\n",
        "\n",
        "\n",
        "        # Menu items and shorthand mappings\n",
        "        self.menu_items = [\n",
        "            \"아메리카노\", \"라떼\", \"카푸치노\", \"카페모카\", \"바닐라라떼\",\n",
        "            \"에스프레소\", \"카라멜마끼아또\", \"허브티\", \"홍차\", \"초콜릿라떼\",\n",
        "            \"레몬에이드\", \"복숭아아이스티\", \"딸기스무디\", \"망고스무디\",\n",
        "            \"키위주스\", \"토마토주스\"\n",
        "        ]\n",
        "        self.order_history = []\n",
        "        self.default_size = \"미디움\"\n",
        "        self.default_temperature = \"핫\"\n",
        "        self.shorthand_mapping = {\"아아\": \"아이스 아메리카노\", \"뜨아\": \"핫 아메리카노\"}\n",
        "\n",
        "    def is_menu_item(self, drink_name):\n",
        "        \"\"\"Check if a drink is on the menu, including shorthand names.\"\"\"\n",
        "        return drink_name in self.menu_items or drink_name in self.shorthand_mapping\n",
        "\n",
        "    def suggest_alternative(self, drink_name):\n",
        "        \"\"\"Suggest a similar item if requested item is unavailable.\"\"\"\n",
        "        if drink_name == \"초코라떼\":\n",
        "            return \"초콜릿라떼\"\n",
        "        return None\n",
        "\n",
        "    def reset_order(self):\n",
        "        \"\"\"Reset the order history for a new customer session.\"\"\"\n",
        "        self.order_history = []\n",
        "\n",
        "    def generate_response_with_model(self, prompt):\n",
        "        # Tokenize input and move input tensor to the device\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        # Generate output from the model\n",
        "        output = self.model.generate(**inputs,max_new_tokens=100)\n",
        "\n",
        "        # Decode the output and return the generated response\n",
        "        response = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        return response\n",
        "    def parse_order_input(self, input_text):\n",
        "        \"\"\"Parse input text to determine drink details.\"\"\"\n",
        "        # Example parsing logic\n",
        "        drink = None\n",
        "        for item in self.menu_items:\n",
        "            if item in input_text:\n",
        "                drink = item\n",
        "                break\n",
        "\n",
        "        if not drink:\n",
        "            return None\n",
        "\n",
        "        quantity = 1\n",
        "        if \"두잔\" in input_text:\n",
        "            quantity = 2\n",
        "        elif \"세잔\" in input_text:\n",
        "            quantity = 3\n",
        "\n",
        "        temperature = \"아이스\" if \"아이스\" in input_text else None\n",
        "        size = \"라지\" if \"라지\" in input_text else None\n",
        "\n",
        "        return {\n",
        "            \"drink\": drink,\n",
        "            \"quantity\": quantity,\n",
        "            \"temperature\": temperature,\n",
        "            \"size\": size\n",
        "        }\n",
        "\n",
        "    def process_input(self, input_text):\n",
        "        \"\"\"Process customer input and route to the correct functionality.\"\"\"\n",
        "        # Check for order completion\n",
        "        if \"주문 완료할게\" in input_text:\n",
        "            response = \"주문이 완료되었습니다. 결제는 카드리더기를 사용해주세요. 감사합니다.\"\n",
        "            json_output = {\n",
        "                \"action\": \"complete_order\",\n",
        "                \"order_items\": self.order_history\n",
        "            }\n",
        "            self.reset_order()\n",
        "            return response, json_output\n",
        "\n",
        "        if \"지금까지 뭘 주문했지\" in input_text:\n",
        "            response = self.get_order_summary()\n",
        "            json_output = None  # No JSON output for history summary\n",
        "            return response, json_output\n",
        "\n",
        "        # Handle new order or modification based on input\n",
        "        drink = None\n",
        "        for item in self.menu_items + list(self.shorthand_mapping.keys()):\n",
        "            if item in input_text:\n",
        "                drink = self.shorthand_mapping.get(item, item)\n",
        "                break\n",
        "\n",
        "        # If drink is not found, suggest alternatives\n",
        "        if not drink:\n",
        "            alternative = self.suggest_alternative(input_text)\n",
        "            if alternative:\n",
        "                response = f\"죄송합니다, {input_text}는 메뉴에 없습니다. 대신 {alternative}를 추천드립니다.\"\n",
        "                json_output = {\n",
        "                    \"action\": \"recommend_closest_item\",\n",
        "                    \"requested_item\": input_text,\n",
        "                    \"recommended_item\": alternative\n",
        "                }\n",
        "            else:\n",
        "                response = f\"죄송합니다, {input_text}는 메뉴에 없습니다.\"\n",
        "                json_output = None\n",
        "            return response, json_output\n",
        "\n",
        "        # Process adding the new item to the order\n",
        "        parsed_order = self.parse_order_input(input_text)\n",
        "        if parsed_order:\n",
        "            response, json_output = self.add_order_item(\n",
        "                drink=parsed_order[\"drink\"],\n",
        "                quantity=parsed_order.get(\"quantity\", 1),\n",
        "                temperature=parsed_order.get(\"temperature\"),\n",
        "                size=parsed_order.get(\"size\"),\n",
        "                add_ons=parsed_order.get(\"add_ons\", []),\n",
        "                extra_shots=parsed_order.get(\"extra_shots\", 0)\n",
        "            )\n",
        "            return response, json_output\n",
        "\n",
        "\n",
        "    def parse_llama_response(self, response_text):\n",
        "        \"\"\"Parse Llama-generated text to determine drink details.\"\"\"\n",
        "        # Extract drink, quantity, temperature, size, add-ons from the model's response\n",
        "        drink = None\n",
        "        for item in self.menu_items + list(self.shorthand_mapping.keys()):\n",
        "            if item in response_text:\n",
        "                drink = self.shorthand_mapping.get(item, item)\n",
        "                break\n",
        "\n",
        "        if not drink:\n",
        "            return None\n",
        "\n",
        "        # Parse quantity, temperature, size, add-ons based on Llama output\n",
        "        quantity = 1\n",
        "        if \"두잔\" in response_text:\n",
        "            quantity = 2\n",
        "        elif \"세잔\" in response_text:\n",
        "            quantity = 3\n",
        "        elif \"네잔\" in response_text:\n",
        "            quantity = 4\n",
        "\n",
        "        temperature = \"아이스\" if \"아이스\" in response_text else \"핫\"\n",
        "        size = \"라지\" if \"라지\" in response_text or \"엑스라지\" in response_text else self.default_size\n",
        "        add_ons = [\"휘핑크림\"] if \"휘핑크림 추가\" in response_text else []\n",
        "\n",
        "        return {\n",
        "            \"drink\": drink,\n",
        "            \"quantity\": quantity,\n",
        "            \"temperature\": temperature,\n",
        "            \"size\": size,\n",
        "            \"add_ons\": add_ons\n",
        "        }\n",
        "\n",
        "    def add_order_item(self, drink, quantity=1, temperature=None, size=None, add_ons=None, extra_shots=0):\n",
        "        \"\"\"Add a new item to the order.\"\"\"\n",
        "        item = {\n",
        "            \"drink\": drink,\n",
        "            \"quantity\": quantity,\n",
        "            \"temperature\": temperature or self.default_temperature,\n",
        "            \"size\": size or self.default_size,\n",
        "            \"add_ons\": add_ons or [],\n",
        "            \"extra_shots\": extra_shots\n",
        "        }\n",
        "        self.order_history.append(item)\n",
        "\n",
        "        latest_item_response = f\"{drink} {quantity}잔 주문되었습니다.\"\n",
        "        full_summary = self.get_order_summary()\n",
        "        response = f\"{latest_item_response} {full_summary}\"\n",
        "\n",
        "        # JSON output only for the latest item\n",
        "        json_output = {\n",
        "            \"action\": \"create_order\",\n",
        "            \"order_items\": [item]\n",
        "        }\n",
        "        return response, json_output\n",
        "    def modify_order(self, old_drink, new_drink, temperature=None, size=None, add_ons=None, extra_shots=0):\n",
        "        \"\"\"Modify an existing order item.\"\"\"\n",
        "        # Locate the item in order history\n",
        "        for item in self.order_history:\n",
        "            if item[\"drink\"] == old_drink:\n",
        "                # Update details\n",
        "                item.update({\n",
        "                    \"drink\": new_drink,\n",
        "                    \"temperature\": temperature or item[\"temperature\"],\n",
        "                    \"size\": size or item[\"size\"],\n",
        "                    \"add_ons\": add_ons or item[\"add_ons\"],\n",
        "                    \"extra_shots\": extra_shots or item[\"extra_shots\"]\n",
        "                })\n",
        "\n",
        "                response = f\"주문이 {old_drink}에서 {new_drink}로 변경되었습니다. {self.get_order_summary()}\"\n",
        "                json_output = {\n",
        "                    \"action\": \"modify_order\",\n",
        "                    \"old_drink\": old_drink,\n",
        "                    \"new_drink\": new_drink,\n",
        "                    \"temperature\": item[\"temperature\"],\n",
        "                    \"size\": item[\"size\"],\n",
        "                    \"quantity\": item[\"quantity\"],\n",
        "                    \"add_ons\": item[\"add_ons\"],\n",
        "                    \"extra_shots\": item[\"extra_shots\"]\n",
        "                }\n",
        "                return response, json_output\n",
        "\n",
        "        # If not found\n",
        "        return f\"{old_drink}는 주문 내역에 없습니다.\", None\n",
        "\n",
        "    def get_order_summary(self):\n",
        "        \"\"\"Generate a comprehensive summary of the current order history.\"\"\"\n",
        "        if not self.order_history:\n",
        "            return \"현재 주문된 항목이 없습니다.\"\n",
        "\n",
        "        summary = \"주문하신 내용은 다음과 같습니다:\"\n",
        "        for item in self.order_history:\n",
        "            drink_summary = (\n",
        "                f\"- {item['drink']} {item['quantity']}잔 \"\n",
        "                f\"({item['temperature']}, {item['size']}\"\n",
        "            )\n",
        "            if item['add_ons']:\n",
        "                drink_summary += f\", 추가 옵션: {', '.join(item['add_ons'])}\"\n",
        "            if item['extra_shots']:\n",
        "                drink_summary += f\", 샷 추가: {item['extra_shots']}회\"\n",
        "            drink_summary += \")\"\n",
        "            summary += f\"\\n{drink_summary}\"\n",
        "        return summary\n",
        "\n",
        "    def summarize_order_history(self):\n",
        "        \"\"\"Provide a summary of the entire order history without adding new JSON output.\"\"\"\n",
        "        if not self.order_history:\n",
        "           return \"현재 주문된 항목이 없습니다.\", None\n",
        "\n",
        "           response = f\"지금까지의 주문내역입니다:\\n{self.get_order_summary()}\"\n",
        "           return response, None\n",
        "\n",
        "\n",
        "# Initialize Coffee Kiosk\n",
        "kiosk = CoffeeKiosk()\n",
        "\n",
        "# Simulate conversation loop\n",
        "print(\"Coffee Kiosk initialized and ready to take orders.\")\n",
        "while True:\n",
        "    customer_input = input(\"Customer: \")\n",
        "    response, json_output = kiosk.process_input(customer_input)\n",
        "    print(\"Kiosk:\", response)\n",
        "    if json_output:\n",
        "        print(\"JSON Output:\", json.dumps(json_output, ensure_ascii=False, indent=2))\n",
        "    if \"주문 완료할게\" in customer_input:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "zow6skBUmX9C",
        "outputId": "9f2e8c68-5749-40d8-d1ea-d39b9b874053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "data did not match any variant of untagged enum ModelWrapper at line 1251003 column 3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bd53f7dc6635>\u001b[0m in \u001b[0;36m<cell line: 252>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;31m# Initialize Coffee Kiosk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m \u001b[0mkiosk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoffeeKiosk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;31m# Simulate conversation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-bd53f7dc6635>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Load tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Set device to GPU if available, otherwise CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m                     \u001b[0;34mf\"Tokenizer class {tokenizer_class_candidate} does not exist or is not currently imported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                 )\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;31m# Otherwise we have to be creative.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2269\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2271\u001b[0;31m         return cls._from_pretrained(\n\u001b[0m\u001b[1;32m   2272\u001b[0m             \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2273\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2503\u001b[0m         \u001b[0;31m# Instantiate the tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2505\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2507\u001b[0m             raise OSError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfast_tokenizer_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_slow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# We have a serialization from tokenizers which let us directly build the backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mfast_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfast_tokenizer_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mslow_tokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# We need to convert a slow tokenizer to build the backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: data did not match any variant of untagged enum ModelWrapper at line 1251003 column 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import json\n",
        "import re\n",
        "\n",
        "class CoffeeKiosk:\n",
        "    def __init__(self):\n",
        "        # Model setup for Llama\n",
        "        model_name = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        # Set device to GPU if available, otherwise CPU\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Load model and move to specified device with trust_remote_code=True\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_name).to(self.device)\n",
        "\n",
        "        # Menu items and shorthand mappings\n",
        "        self.menu_items = [\n",
        "            \"아메리카노\", \"라떼\", \"카푸치노\", \"카페모카\", \"바닐라라떼\",\n",
        "            \"에스프레소\", \"카라멜마끼아또\", \"허브티\", \"홍차\", \"초콜릿라떼\",\n",
        "            \"레몬에이드\", \"복숭아아이스티\", \"딸기스무디\", \"망고스무디\",\n",
        "            \"키위주스\", \"토마토주스\"\n",
        "        ]\n",
        "        self.order_history = []\n",
        "        self.default_size = \"미디움\"\n",
        "        self.default_temperature = \"핫\"\n",
        "        self.shorthand_mapping = {\"아아\": \"아이스 아메리카노\", \"뜨아\": \"핫 아메리카노\"}\n",
        "\n",
        "    def is_menu_item(self, drink_name):\n",
        "        \"\"\"Check if a drink is on the menu, including shorthand names.\"\"\"\n",
        "        return drink_name in self.menu_items or drink_name in self.shorthand_mapping\n",
        "\n",
        "    def suggest_alternative(self, drink_name):\n",
        "        \"\"\"Suggest a similar item if requested item is unavailable.\"\"\"\n",
        "        if drink_name == \"초코라떼\":\n",
        "            return \"초콜릿라떼\"\n",
        "        return None\n",
        "\n",
        "    def reset_order(self):\n",
        "        \"\"\"Reset the order history for a new customer session.\"\"\"\n",
        "        self.order_history = []\n",
        "\n",
        "    def generate_response_with_model(self, prompt):\n",
        "        # Tokenize input and move input tensor to the device\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        # Remove 'token_type_ids' if it exists to avoid errors\n",
        "        inputs.pop(\"token_type_ids\", None)\n",
        "\n",
        "        # Generate output from the model with a specified max_new_tokens\n",
        "        output = self.model.generate(**inputs, max_new_tokens=100)\n",
        "\n",
        "        # Decode the output and return the generated response\n",
        "        response = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        return response\n",
        "\n",
        "    def parse_order_input(self, input_text):\n",
        "        \"\"\"Parse input text to determine drink details.\"\"\"\n",
        "        # Example parsing logic\n",
        "        drink = None\n",
        "        for item in self.menu_items:\n",
        "            if item in input_text:\n",
        "                drink = item\n",
        "                break\n",
        "\n",
        "        if not drink:\n",
        "            return None\n",
        "\n",
        "        quantity = 1\n",
        "        if \"두잔\" in input_text:\n",
        "            quantity = 2\n",
        "        elif \"세잔\" in input_text:\n",
        "            quantity = 3\n",
        "\n",
        "        temperature = \"아이스\" if \"아이스\" in input_text else None\n",
        "        size = \"라지\" if \"라지\" in input_text else None\n",
        "\n",
        "        return {\n",
        "            \"drink\": drink,\n",
        "            \"quantity\": quantity,\n",
        "            \"temperature\": temperature,\n",
        "            \"size\": size\n",
        "        }\n",
        "\n",
        "    def parse_multiple_items(self, input_text):\n",
        "        \"\"\"Parse multiple items in a single input for better handling.\"\"\"\n",
        "        # Regex pattern to match drink items with quantity, temperature, and size\n",
        "        pattern = r\"(아이스|핫)?\\s*([가-힣]+)\\s*(엑스라지|라지|미디움)?\\s*(\\d+)?잔?\"\n",
        "        items = re.findall(pattern, input_text)\n",
        "\n",
        "        orders = []\n",
        "        for temp, drink, size, qty_text in items:\n",
        "            drink = self.shorthand_mapping.get(drink, drink)  # Expand shorthand if necessary\n",
        "            quantity = int(qty_text) if qty_text else 1\n",
        "            temperature = temp if temp else self.default_temperature\n",
        "            size = size if size else self.default_size\n",
        "\n",
        "            # Only add items that are on the menu\n",
        "            if drink in self.menu_items:\n",
        "                orders.append({\n",
        "                    \"drink\": drink,\n",
        "                    \"quantity\": quantity,\n",
        "                    \"temperature\": temperature,\n",
        "                    \"size\": size,\n",
        "                    \"add_ons\": [],\n",
        "                    \"extra_shots\": 0\n",
        "                })\n",
        "\n",
        "        return orders\n",
        "\n",
        "    def process_input(self, input_text):\n",
        "        \"\"\"Process customer input by routing it through the model and parsing the response.\"\"\"\n",
        "        # Generate response from the Llama model\n",
        "        response = self.generate_response_with_model(input_text)\n",
        "\n",
        "        # Check if the user asked for order completion\n",
        "        if \"주문 완료할게\" in response:\n",
        "            final_response = \"주문이 완료되었습니다. 결제는 카드리더기를 사용해주세요. 감사합니다.\"\n",
        "            json_output = {\n",
        "                \"action\": \"complete_order\",\n",
        "                \"order_items\": self.order_history\n",
        "            }\n",
        "            self.reset_order()\n",
        "            return final_response, json_output\n",
        "\n",
        "        # Check if the user asked for a summary of current orders\n",
        "        if \"지금까지 뭘 주문했지\" in response:\n",
        "            order_summary = self.get_order_summary()\n",
        "            return order_summary, None\n",
        "\n",
        "        # Parse the response for adding or modifying orders\n",
        "        parsed_orders = self.parse_multiple_items(input_text)\n",
        "\n",
        "        if parsed_orders:\n",
        "            # If parsed orders are found, add each item to order history\n",
        "            for parsed_order in parsed_orders:\n",
        "                self.order_history.append(parsed_order)\n",
        "\n",
        "            # Generate the response and JSON for the cumulative order\n",
        "            response = self.create_order_summary_response(parsed_orders)\n",
        "            json_output = {\n",
        "                \"action\": \"create_order\",\n",
        "                \"order_items\": parsed_orders\n",
        "            }\n",
        "            return response, json_output\n",
        "\n",
        "        # Handle change requests, if detected in the input text\n",
        "        old_drink, new_drink = self.extract_change_request(input_text)\n",
        "        if old_drink and new_drink:\n",
        "            response, json_output = self.modify_order(old_drink, new_drink)\n",
        "            return response, json_output\n",
        "\n",
        "        # Fallback if no specific action is determined\n",
        "        return response, None\n",
        "\n",
        "    def extract_change_request(self, input_text):\n",
        "        \"\"\"Identify drinks to change and new drink preferences.\"\"\"\n",
        "        match = re.search(r\"(\\S+)\\s+.*?를\\s+(\\S+)\\s+로\\s+바꿔줘\", input_text)\n",
        "        if match:\n",
        "            old_drink, new_drink = match.groups()\n",
        "            return old_drink, new_drink\n",
        "        return None, None\n",
        "\n",
        "    def add_order_item(self, drink, quantity=1, temperature=None, size=None, add_ons=None, extra_shots=0):\n",
        "        \"\"\"Add a new item to the order.\"\"\"\n",
        "        item = {\n",
        "            \"drink\": drink,\n",
        "            \"quantity\": quantity,\n",
        "            \"temperature\": temperature or self.default_temperature,\n",
        "            \"size\": size or self.default_size,\n",
        "            \"add_ons\": add_ons or [],\n",
        "            \"extra_shots\": extra_shots\n",
        "        }\n",
        "        self.order_history.append(item)\n",
        "\n",
        "        latest_item_response = f\"{drink} {quantity}잔 주문되었습니다.\"\n",
        "        full_summary = self.get_order_summary()\n",
        "        response = f\"{latest_item_response} {full_summary}\"\n",
        "\n",
        "        # JSON output only for the latest item\n",
        "        json_output = {\n",
        "            \"action\": \"create_order\",\n",
        "            \"order_items\": [item]\n",
        "        }\n",
        "        return response, json_output\n",
        "    def parse_llama_response(self, response_text):\n",
        "        \"\"\"Parse Llama-generated text to determine drink details.\"\"\"\n",
        "        # Extract drink, quantity, temperature, size, add-ons from the model's response\n",
        "        drink = None\n",
        "        for item in self.menu_items + list(self.shorthand_mapping.keys()):\n",
        "            if item in response_text:\n",
        "                drink = self.shorthand_mapping.get(item, item)\n",
        "                break\n",
        "\n",
        "        if not drink:\n",
        "            return None\n",
        "\n",
        "        # Parse quantity, temperature, size, add-ons based on Llama output\n",
        "        quantity = 1\n",
        "        if \"두잔\" in response_text:\n",
        "            quantity = 2\n",
        "        elif \"세잔\" in response_text:\n",
        "            quantity = 3\n",
        "        elif \"네잔\" in response_text:\n",
        "            quantity = 4\n",
        "\n",
        "        temperature = \"아이스\" if \"아이스\" in response_text else \"핫\"\n",
        "        size = \"라지\" if \"라지\" in response_text or \"엑스라지\" in response_text else self.default_size\n",
        "        add_ons = [\"휘핑크림\"] if \"휘핑크림 추가\" in response_text else []\n",
        "\n",
        "        return {\n",
        "            \"drink\": drink,\n",
        "            \"quantity\": quantity,\n",
        "            \"temperature\": temperature,\n",
        "            \"size\": size,\n",
        "            \"add_ons\": add_ons\n",
        "        }\n",
        "\n",
        "    def modify_order(self, old_drink, new_drink, temperature=None, size=None, add_ons=None, extra_shots=0):\n",
        "        \"\"\"Modify an existing order item.\"\"\"\n",
        "        # Locate the item in order history\n",
        "        for item in self.order_history:\n",
        "            if item[\"drink\"] == old_drink:\n",
        "                # Update details\n",
        "                item.update({\n",
        "                    \"drink\": new_drink,\n",
        "                    \"temperature\": temperature or item[\"temperature\"],\n",
        "                    \"size\": size or item[\"size\"],\n",
        "                    \"add_ons\": add_ons or item[\"add_ons\"],\n",
        "                    \"extra_shots\": extra_shots or item[\"extra_shots\"]\n",
        "                })\n",
        "\n",
        "                response = f\"주문이 {old_drink}에서 {new_drink}로 변경되었습니다. {self.get_order_summary()}\"\n",
        "                json_output = {\n",
        "                    \"action\": \"modify_order\",\n",
        "                    \"old_drink\": old_drink,\n",
        "                    \"new_drink\": new_drink,\n",
        "                    \"temperature\": item[\"temperature\"],\n",
        "                    \"size\": item[\"size\"],\n",
        "                    \"quantity\": item[\"quantity\"],\n",
        "                    \"add_ons\": item[\"add_ons\"],\n",
        "                    \"extra_shots\": item[\"extra_shots\"]\n",
        "                }\n",
        "                return response, json_output\n",
        "\n",
        "        # If not found\n",
        "        return f\"{old_drink}는 주문 내역에 없습니다.\", None\n",
        "\n",
        "    def get_order_summary(self):\n",
        "        \"\"\"Generate a comprehensive summary of the current order history.\"\"\"\n",
        "        if not self.order_history:\n",
        "            return \"현재 주문된 항목이 없습니다.\"\n",
        "\n",
        "        summary = \"주문하신 내용은 다음과 같습니다:\"\n",
        "        for item in self.order_history:\n",
        "            drink_summary = (\n",
        "                f\"- {item['drink']} {item['quantity']}잔 \"\n",
        "                f\"({item['temperature']}, {item['size']}\"\n",
        "            )\n",
        "            if item['add_ons']:\n",
        "                drink_summary += f\", 추가 옵션: {', '.join(item['add_ons'])}\"\n",
        "            if item['extra_shots']:\n",
        "                drink_summary += f\", 샷 추가: {item['extra_shots']}회\"\n",
        "            drink_summary += \")\"\n",
        "            summary += f\"\\n{drink_summary}\"\n",
        "        return summary\n",
        "\n",
        "    def create_order_summary_response(self, parsed_orders):\n",
        "        \"\"\"Create a summary response for the current and cumulative orders.\"\"\"\n",
        "        latest_items = \", \".join(\n",
        "            [f\"{item['drink']} {item['quantity']}잔 ({item['temperature']}, {item['size']})\" for item in parsed_orders]\n",
        "        )\n",
        "        latest_item_response = f\"{latest_items} 주문되었습니다.\"\n",
        "\n",
        "        # Generate a full summary of all items in the order history\n",
        "        full_summary = self.get_order_summary()\n",
        "        response = f\"{latest_item_response}\\n{full_summary}\"\n",
        "\n",
        "        return response\n",
        "\n",
        "    def summarize_order_history(self):\n",
        "        \"\"\"Provide a summary of the entire order history without adding new JSON output.\"\"\"\n",
        "        if not self.order_history:\n",
        "           return \"현재 주문된 항목이 없습니다.\", None\n",
        "\n",
        "           response = f\"지금까지의 주문내역입니다:\\n{self.get_order_summary()}\"\n",
        "           return response, None\n",
        "\n",
        "# Initialize Coffee Kiosk\n",
        "kiosk = CoffeeKiosk()\n",
        "\n",
        "# Simulate conversation loop\n",
        "print(\"Coffee Kiosk initialized and ready to take orders.\")\n",
        "while True:\n",
        "    customer_input = input(\"Customer: \")\n",
        "    response, json_output = kiosk.process_input(customer_input)\n",
        "    print(\"Kiosk:\", response)\n",
        "    if json_output:\n",
        "        print(\"JSON Output:\", json.dumps(json_output, ensure_ascii=False, indent=2))\n",
        "    if \"주문 완료할게\" in customer_input:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "79c30191b7214cf598c2bb1a883a8cdb",
            "555e650fd5544f838921fc993186b2f6",
            "a67cd84efcec4d4896f41955e272c9ab",
            "600d532ac4a144a7990d9fa22e6dd4b8",
            "e8c5340032c748f58e3b452713f3cfd3",
            "c96412a7509f4b7ea1d232feafe4f414",
            "38f172da07c541bc9901d20ab0b8d50b",
            "c54dba6d08624c89acc65026ec65fa4f",
            "941532563bf84f09935623eb9e0772ac",
            "b0c79001d814488c807dede50d9ec315",
            "3b2a8691fb3043e59e4c07def420c428"
          ]
        },
        "id": "v7kx7QyHwYg7",
        "outputId": "354f8eaf-2442-451b-826e-6a78a1b6686e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79c30191b7214cf598c2bb1a883a8cdb"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coffee Kiosk initialized and ready to take orders.\n",
            "Customer: 아이스 아메리카노 6잔 주세요\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kiosk: 아메리카노 6잔 (아이스, 미디움) 주문되었습니다.\n",
            "주문하신 내용은 다음과 같습니다:\n",
            "- 아메리카노 6잔 (아이스, 미디움)\n",
            "JSON Output: {\n",
            "  \"action\": \"create_order\",\n",
            "  \"order_items\": [\n",
            "    {\n",
            "      \"drink\": \"아메리카노\",\n",
            "      \"quantity\": 6,\n",
            "      \"temperature\": \"아이스\",\n",
            "      \"size\": \"미디움\",\n",
            "      \"add_ons\": [],\n",
            "      \"extra_shots\": 0\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Customer: 쿠키앤크림 3잔 주세요\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kiosk: 쿠키앤크림 3잔 주세요! (제목: 쿠키앤크림 3잔 주세요!) - 네이트 뉴스\n",
            "쿠키앤크림 3잔 주세요! (제목: 쿠키앤크림 3잔 주세요!)\n",
            "\n",
            "쿠키앤크림 3잔 주세요! (제목: 쿠키앤크림 3잔 주세요!)\n",
            "\n",
            "2023-04-05 10:\n",
            "Customer: 카페 모카 2잔\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kiosk: 카페 모카 2잔, 카페 모카 2잔, 카페 모카 2잔, 카페 모카 2잔, 카페 모카 2잔, 카페 모카 2잔, 카페 모카 2잔, 카페 모카 2잔, 카페 모카 2잔, 카페 모카 2잔, 카페 모카 2잔, 카페 모카 2잔, 카페 모카 2잔, 카페 모\n",
            "Customer: 복숭아 아이스티 한잔 주세요\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kiosk: 복숭아 아이스티 한잔 주세요! 복숭아 아이스티는 맛있는 음료로, 주로 여름철에 즐기기 좋습니다. 이 음료는 주로 복숭아의 맛을 뽐내며, 아이스와 함께 마시면 더욱 맛있게 느껴집니다. 복숭아 아이스티는 다양한 맛의 복숭아를 사용하여 다양한 hương을 즐길 수 있습니다. 또한, 복숭아 아이스티는 보다 건강한\n",
            "Customer: 카페라때 한잔 주세요\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kiosk: 카페라때 한잔 주세요. (Café au lait, please.) - \"나의 아내는 한 잔을 마시기 전에 항상 한 잔 더 남겼습니다. 나는 그 아내가 나의 아내가 아니라는 것을 알았습니다. 나는 그 아내가 나의 아내가 아니라는 것을 알았습니다.\" - \"나는 그 아내가 나의 아내가 아니라는 것을 알았습니다. 나는 그 아내가 나의 아내가 아니라는 것을\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-50a0ee3ce795>\u001b[0m in \u001b[0;36m<cell line: 297>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Coffee Kiosk initialized and ready to take orders.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0mcustomer_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Customer: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkiosk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomer_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Kiosk:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}