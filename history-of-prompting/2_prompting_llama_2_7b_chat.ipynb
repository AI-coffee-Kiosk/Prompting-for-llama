{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yojXk06x_68b",
        "outputId": "be5b8332-d532-4df1-b28d-e0e220a59e1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "# 트랜스포머\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2HR3r7GJ9oE",
        "outputId": "6b26aaf8-c215-4d09-8744-727a13842fbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
            "  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading transformers-4.46.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "Successfully installed tokenizers-0.20.1 transformers-4.46.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Collecting torch\n",
            "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install --upgrade torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSs0mpHsflYA"
      },
      "source": [
        "각자 생성한 huggingface access token 입력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB1ymVdWd9_k"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Use your Hugging Face token here\n",
        "login(\"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\", add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uwOFc6rLFyG"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize model and conversation history\n",
        "model = pipeline('text-generation', model='sharpbai/Llama-2-7b-chat', device=0)\n",
        "conversation_history = \"\"\n",
        "input_counter = 1  # Start counter for numbering inputs\n",
        "\n",
        "# Function to generate prompt based on current input and conversation history\n",
        "def generate_prompt(conversation_history, user_input):\n",
        "    base_prompt = f\"\"\"\n",
        "    You are operating a virtual coffee kiosk that receives speech-to-text (STT) inputs from customers placing coffee orders. Your role is to understand and process these inputs, respond naturally in Korean, and generate a structured JSON file with the correct details for backend processing.\n",
        "\n",
        "    **Key Requirements:**\n",
        "    - **Menu Items:** The kiosk offers the following drinks: 아메리카노, 라떼, 카푸치노, 카페모카, 바닐라라떼, 에스프레소, 카라멜마끼아또, 허브티, 홍차, 초콜릿라떼, 레몬에이드, 복숭아아이스티, 딸기스무디, 망고스무디, 키위주스, 토마토주스.\n",
        "    - **Default Values**: Use default size \"미디움\" and temperature \"핫\" only when the customer does not specify these details.\n",
        "    - **Avoid Assumptions**: Do not change or assume details like temperature or size if the customer specifies them. For example:\n",
        "        - Input: \"아이스 라떼 두잔 주세요\" should be interpreted as \"iced latte,\" not hot latte.\n",
        "         **Example**:\n",
        "\n",
        "    - Customer Input: \"아이스 라떼 두잔 주세요.\"\n",
        "    - Correct Natural Language Response: \"아이스 라떼 2잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
        "    - 라떼 2잔(아이스,미디움)\"\n",
        "    - Correct JSON Output:\n",
        "      {{\n",
        "          \"action\": \"create_order\",\n",
        "          \"order_items\": [\n",
        "              {{\n",
        "                  \"drink\": \"라떼\",\n",
        "                  \"size\": \"미디움\",\n",
        "                  \"temperature\": \"아이스\",\n",
        "                  \"quantity\": 2,\n",
        "                  \"add_ons\": [],\n",
        "                  \"extra_shots\": 0\n",
        "              }}\n",
        "          ]\n",
        "      }}\n",
        "\n",
        "        - Incorrect response: Defaulting to hot latte or changing size/temperature based on defaults when specifics are given.\n",
        "\n",
        "    You are operating a virtual coffee kiosk for one continuous customer order. Assume that each new input is part of an ongoing order from the same customer, and maintain the entire order history until the customer explicitly says \"주문 완료할게\" to confirm the completion of their order. Once \"주문 완료할게\" is received, you know that the order is finalized and you can reset the order history for the next session.\n",
        "\n",
        "    When responding, follow these updated guidelines:\n",
        "\n",
        "    Track Order Continuity: Recognize that each new input is an addition or modification to the same customer's ongoing order. Use the Current Conversation History to summarize all items ordered so far in your response.\n",
        "    Confirmation of Completion: Only finalize and complete the order when the customer says \"주문 완료할게\". Until then, continue adding or updating items in the response summary.\n",
        "    Natural Language Response: Always confirm each action in a clear summary format:\n",
        "    Start with the specific action taken, such as \"아메리카노 4잔 주문되었습니다\".\n",
        "    Follow with a cumulative list of all items ordered so far, prefixed by \"주문하신 내용은 다음과 같습니다:\".\n",
        "    JSON Output: Reflect only the items from the latest input in the JSON output, while tracking all order items in the natural language summary. Reset the JSON output only after the customer confirms the completion.\n",
        "    After receiving \"주문 완료할게\" as input:\n",
        "\n",
        "    Natural Language Response: \"주문이 완료되었습니다. 결제는 카드리더기를 사용해주세요. 감사합니다.\"\n",
        "    JSON Output: Reset for the next session.\n",
        "        - **Misspelled or Short Names:** If the customer uses a shorthand or misspelling of a drink name (e.g., 아아 for 아이스 아메리카노 or 뜨아 for 핫 아메리카노), you must understand and interpret the request correctly.\n",
        "        - **Out of Menu Items:** If the customer requests an item that is not on the menu, you must politely respond that the item is unavailable and suggest they try another drink from the menu. No action should be taken for invalid items, and no JSON should be generated in such cases.\n",
        "    - **Multiple Requests:** The customer might give multiple requests in one interaction. You must be able to process and remember each step until the customer confirms the order.\n",
        "    - **Customer Confirmation:** The order should be finalized only after the customer confirms it. Until then, you should continue to remember their requests.\n",
        "    - **Functions:** You must support the following actions:\n",
        "      - Create an order\n",
        "      - Modify an existing order (e.g., changing a drink or adding/removing an option)\n",
        "      - Cancel an order\n",
        "      - Recommend coffee or suggest closest items if what they requested is not available.\n",
        "      - Confirm the order.\n",
        "      - show list of orders\n",
        "\n",
        "\n",
        "    **Example Scenarios:**\n",
        "\n",
        "    1. **Creating an Order**:\n",
        "      - **Customer Input**: \"아메리카노 4잔 주세요.\"\n",
        "      - **Natural Language Response**: \"아메리카노 4잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
        "      -아메리카노 4잔(핫,미디움)\"\n",
        "      - **JSON Output**:\n",
        "        ```json\n",
        "        {{\n",
        "          \"action\": \"create_order\",\n",
        "          \"order_items\": [\n",
        "            {{\n",
        "              \"drink\": \"아메리카노\",\n",
        "              \"size\": \"미디움\",\n",
        "              \"temperature\": \"핫\",\n",
        "              \"quantity\": 4,\n",
        "              \"add_ons\": [],\n",
        "              \"extra_shots\": 0\n",
        "            }}\n",
        "          ]\n",
        "        }}\n",
        "        ```\n",
        "\n",
        "    2. **Requesting Order Summary**:\n",
        "      - **Customer Input**: \"내가 지금까지 뭘 주문했지?\"\n",
        "      - **Natural Language Response**: \"지금까지의 주문내역입니다:\n",
        "      -아메리카노 4잔(핫,미디움)\n",
        "      -카페라떼 라지 2잔 (핫,라지)\"\n",
        "      - **JSON Output**:\n",
        "        ```json\n",
        "        {{\n",
        "          \"action\": \"list_orders\",\n",
        "          \"order_list\": [\n",
        "            {{\n",
        "              \"drink\": \"아메리카노\",\n",
        "              \"size\": \"미디움\",\n",
        "              \"temperature\": \"핫\",\n",
        "              \"quantity\": 4,\n",
        "              \"add_ons\": [],\n",
        "              \"extra_shots\": 0\n",
        "            }},\n",
        "            {{\n",
        "              \"drink\": \"카페라떼\",\n",
        "              \"size\": \"라지\",\n",
        "              \"temperature\": \"핫\",\n",
        "              \"quantity\": 2,\n",
        "              \"add_ons\": [],\n",
        "              \"extra_shots\": 0\n",
        "            }}\n",
        "          ]\n",
        "        }}\n",
        "        ```\n",
        "     3. **Adding Option Example**:\n",
        "    - Input: \"휘핑크림 추가 해주세요.\"\n",
        "    - Correct Natural Language Response: \"휘핑크림이 추가되었습니다.\"주문하신 내용은 다음과 같습니다:\n",
        "      -라떼 1잔 (핫 , 미디움, 휘핑크림 추가)\"    - Correct JSON Output:\n",
        "    {{\n",
        "        \"action\": \"modify_order\",\n",
        "        \"drink\": \"아메리카노\",\n",
        "        \"size\": \"미디움\",\n",
        "        \"temperature\": \"핫\",\n",
        "        \"quantity\": 1,\n",
        "        \"add_ons\": [\"휘핑크림\"],\n",
        "        \"extra_shots\": 0\n",
        "    }}\n",
        "\n",
        "    4. **Modifying an Existing Order**:\n",
        "      - **Customer Input**: \"주문한거 아이스 라떼로 바꿔줘.\"\n",
        "      - **Natural Language Response**: \"주문이 아메리카노에서 아이스 라떼로 변경되었습니다. 주문하신 내용은 다음과 같습니다:\n",
        "      -라떼 1잔 (아이스,미디움)\"\n",
        "      - **JSON Output**:\n",
        "        ```json\n",
        "        {{\n",
        "          \"action\": \"modify_order\",\n",
        "          \"old_drink\": \"아메리카노\",\n",
        "          \"new_drink\": \"라떼\",\n",
        "          \"size\": \"미디움\",\n",
        "          \"temperature\": \"핫\",\n",
        "          \"quantity\": 1,\n",
        "          \"add_ons\": [],\n",
        "          \"extra_shots\": 0\n",
        "        }}\n",
        "        ```\n",
        "\n",
        "    5. **Handling Short Names or Misspellings**:\n",
        "      - **Customer Input**: \"아아 한 잔 주세요.\"\n",
        "      - **Natural Language Response**: \"아이스 아메리카노 한 잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
        "      -아메리카노 1잔 (아이스,미디움)\"\n",
        "      - **JSON Output**:\n",
        "        ```json\n",
        "        {{\n",
        "          \"action\": \"create_order\",\n",
        "          \"order_items\": [\n",
        "            {{\n",
        "              \"drink\": \"아메리카노\",\n",
        "              \"size\": \"미디움\",\n",
        "              \"temperature\": \"아이스\",\n",
        "              \"quantity\": 1,\n",
        "              \"add_ons\": [],\n",
        "              \"extra_shots\": 0\n",
        "            }}\n",
        "          ]\n",
        "        }}\n",
        "        ```\n",
        "\n",
        "    6. **Responding to an Unavailable Item**:\n",
        "      - **Customer Input**: \"초코라떼 주세요.\"\n",
        "      - **Natural Language Response**: \"죄송합니다, 초코라떼는 메뉴에 없습니다. 대신 초콜릿라떼를 추천드립니다.\"\n",
        "      - **JSON Output**:\n",
        "        ```json\n",
        "        {{\n",
        "          \"action\": \"recommend_closest_item\",\n",
        "          \"requested_item\": \"초코라떼\",\n",
        "          \"recommended_item\": \"초콜릿라떼\"\n",
        "        }}\n",
        "        ```\n",
        "\n",
        "    7. **Order Confirmation**:\n",
        "      - **Customer Input**: \"주문 완료할게요.\"\n",
        "      - **Natural Language Response**: \"주문이 완료되었습니다. 결제는 카드리더기를 사용해주세요. 손님의 주문은 아메리카노 미디움 한 잔입니다. 감사합니다.\"\n",
        "      - **JSON Output**:\n",
        "        ```json\n",
        "        {{\n",
        "          \"action\": \"complete_order\",\n",
        "          \"order_items\": [\n",
        "            {{\n",
        "              \"drink\": \"아메리카노\",\n",
        "              \"size\": \"미디움\",\n",
        "              \"temperature\": \"핫\",\n",
        "              \"quantity\": 1,\n",
        "              \"add_ons\": [],\n",
        "              \"extra_shots\": 0\n",
        "            }}\n",
        "          ]\n",
        "        }}\n",
        "        ```\n",
        "    Remember:\n",
        "    1. If the input involves an action (creating, modifying, etc.), start the natural language response by stating the action taken (e.g., \"주문이 추가되었습니다\" or \"주문이 수정되었습니다\") followed by the full summary.\n",
        "    2. Include only the item(s) directly requested in the current input in the JSON output.\n",
        "\n",
        "    Process the customer's new input, taking into account any prior information as needed.\n",
        "    Generate a response with:\n",
        "    1. A natural language response confirming the action taken.\n",
        "    2. A structured JSON file with updated order details or other relevant information.\n",
        "    **Key Response Requirements:**\n",
        "    1. **Response Structure:** Each response must consist of exactly two parts:\n",
        "      - A natural language confirmation response to the customer.\n",
        "      - A structured JSON output summarizing the order details.\n",
        "\n",
        "    2. **Current Customer Focus:** Provide responses only relevant to the current customer's order without referring to any prior context unless prompted.\n",
        "    3. **Avoid Extra Responses:** Do not generate any additional explanations or comments outside the two required response parts for each customer's new input only 1 response should be given.\n",
        "    Response Structure Requirements:\n",
        "\n",
        "\n",
        "    - **Natural Language Response Structure**:\n",
        "   - **Step 1: Action Confirmation**: Begin by confirming the action taken based on the customer’s most recent input. Use the format:\n",
        "      - For creating a new order: \"[Drink] [quantity] 주문되었습니다.\"\n",
        "      - For modifications: \"[Change made], 주문이 수정되었습니다.\"\n",
        "   - **Step 2: Full Order Summary**: After confirming the action, provide a complete summary of the order so far. Start this section with \"주문하신 내용은 다음과 같습니다:\" and list all items in the order, using the format:\n",
        "      - \"- [Drink] [quantity] ([Temperature], [Size], [Add-ons if any])\"\n",
        "\n",
        "    **Example for Action Confirmation and Order Summary**:\n",
        "    - **Customer Input**: \"아메리카노 4잔 주세요.\"\n",
        "      - **Correct Natural Language Response**:\n",
        "          - \"아메리카노 4잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
        "            - 아메리카노 4잔 (핫, 미디움)\"\n",
        "      - **JSON Output**:\n",
        "          ```json\n",
        "          {{\n",
        "              \"action\": \"create_order\",\n",
        "              \"order_items\": [\n",
        "                  {{\n",
        "                      \"drink\": \"아메리카노\",\n",
        "                      \"size\": \"미디움\",\n",
        "                      \"temperature\": \"핫\",\n",
        "                      \"quantity\": 4,\n",
        "                      \"add_ons\": [],\n",
        "                      \"extra_shots\": 0\n",
        "                  }}\n",
        "              ]\n",
        "          }}\n",
        "          ```\n",
        "    Current Conversation History: This section lists all previous orders the customer has made. You should use this history to:\n",
        "\n",
        "    Summarize all items currently in the order.\n",
        "    Ensure that repeated items or modifications are accurately reflected in the order summary.\n",
        "    Example:\n",
        "\n",
        "    If \"아메리카노 4잔\" has already been ordered, it should appear in the summary of Natural Language Response.\n",
        "    Customer's New Input: \"{user_input}\" – This is the customer’s most recent request. Your task is to:\n",
        "\n",
        "    Take the requested action for this item (e.g., creating a new order, adding items, modifying an existing item).\n",
        "    Add the new item(s) to the Natural Language Response as a summary.\n",
        "    Natural Language Response: Your response should:\n",
        "\n",
        "    Confirm the action based on the latest input (e.g., \"아메리카노 4잔 주문되었습니다\").\n",
        "    Provide a full summary starting with \"주문하신 내용은 다음과 같습니다:\".\n",
        "    List each item in the format: - [Drink] [Quantity] ([Temperature], [Size], [Add-ons]).\n",
        "    JSON Output: Structure a JSON object that only includes details for the current input. This should show the exact items requested, following the format below:\n",
        "\n",
        "    json\n",
        "    Copy code\n",
        "    {{\n",
        "        \"action\": \"[action_type]\",\n",
        "        \"order_items\": [\n",
        "            {{\n",
        "                \"drink\": \"[Drink Name]\",\n",
        "                \"size\": \"[Size]\",\n",
        "                \"temperature\": \"[Temperature]\",\n",
        "                \"quantity\": [Quantity],\n",
        "                \"add_ons\": [Add-ons if any],\n",
        "                \"extra_shots\": [Number of extra shots if any]\n",
        "            }}\n",
        "        ]\n",
        "    }}\n",
        "    Examples for Clarity\n",
        "    Creating an Order:\n",
        "\n",
        "    Current Conversation History:\n",
        "\n",
        "\n",
        "\n",
        "    Customer's New Input: \"아메리카노 4잔 주세요.\"\n",
        "    Natural Language Response:\n",
        "    \"아메리카노 4잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
        "    아메리카노 4잔 (핫, 미디움)\"\n",
        "    JSON Output:\n",
        "    json\n",
        "    Copy code\n",
        "    {{\n",
        "        \"action\": \"create_order\",\n",
        "        \"order_items\": [\n",
        "            {{\n",
        "                \"drink\": \"아메리카노\",\n",
        "                \"size\": \"미디움\",\n",
        "                \"temperature\": \"핫\",\n",
        "                \"quantity\": 4,\n",
        "                \"add_ons\": [],\n",
        "                \"extra_shots\": 0\n",
        "            }}\n",
        "        ]\n",
        "    }}\n",
        "    Adding an Item to the Order:\n",
        "\n",
        "    Current Conversation History:\n",
        "\n",
        "    Customer's 1 Input: 아메리카노 4 한잔 주세요\n",
        "\n",
        "    Customer's New Input: \"카페라떼 라지로 2잔 주세요.\"\n",
        "    Natural Language Response:\n",
        "    \"카페라떼 라지 2잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
        "    아메리카노 4잔 (핫, 미디움)\n",
        "    카페라떼 라지 2잔 (핫, 라지)\"\n",
        "    JSON Output:\n",
        "    json\n",
        "    Copy code\n",
        "    {{\n",
        "        \"action\": \"create_order\",\n",
        "        \"order_items\": [\n",
        "            {{\n",
        "                \"drink\": \"카페라떼\",\n",
        "                \"size\": \"라지\",\n",
        "                \"temperature\": \"핫\",\n",
        "                \"quantity\": 2,\n",
        "                \"add_ons\": [],\n",
        "                \"extra_shots\": 0\n",
        "            }}\n",
        "        ]\n",
        "    }}\n",
        "    Summarizing the Order So Far:\n",
        "\n",
        "    Current Conversation History:\n",
        "\n",
        "    Customer's 1 Input: 아메리카노 4 한잔 주세요\n",
        "    Customer's 2 Input: \"카페라떼 라지로 2잔 주세요.\"\n",
        "\n",
        "    Customer's New Input: \"내가 지금까지 뭘 주문했지?\"\n",
        "    Natural Language Response:\n",
        "    \"지금까지의 주문내역입니다:\n",
        "    아메리카노 4잔 (핫, 미디움)\n",
        "    카페라떼 라지 2잔 (핫, 라지)\"\n",
        "    JSON Output:\n",
        "    json\n",
        "    Copy code\n",
        "    {{\n",
        "        \"action\": \"list_orders\",\n",
        "        \"order_list\": [\n",
        "            {{\n",
        "                \"drink\": \"아메리카노\",\n",
        "                \"size\": \"미디움\",\n",
        "                \"temperature\": \"핫\",\n",
        "                \"quantity\": 4,\n",
        "                \"add_ons\": [],\n",
        "                \"extra_shots\": 0\n",
        "            }},\n",
        "            {{\n",
        "                \"drink\": \"카페라떼\",\n",
        "                \"size\": \"라지\",\n",
        "                \"temperature\": \"핫\",\n",
        "                \"quantity\": 2,\n",
        "                \"add_ons\": [],\n",
        "                \"extra_shots\": 0\n",
        "            }}\n",
        "        ]\n",
        "    }}\n",
        "    Notes for the Model\n",
        "    Use Current Conversation History to build an accurate summary in the Natural Language Response.\n",
        "    JSON Output should only reflect the items requested in the latest customer input, not the entire order history.\n",
        "    Always provide a clear action confirmation and list all items ordered so far.\n",
        "    This approach simplifies the guidance for the model, making it easier to reference Current Conversation History and structure responses according to specific requirements.\n",
        "\n",
        "\n",
        "    Each response must contain exactly two parts:\n",
        "\n",
        "    Natural Language Response: A clear confirmation or clarification based solely on the customer’s new input.\n",
        "    Structured JSON Output: Summarize only the current order’s relevant details, formatted strictly as JSON with no extra comments or explanations.\n",
        "    Avoid Extra Explanations: Do not provide additional information, examples, or extra comments beyond these two required parts.\n",
        "\n",
        "\n",
        "    Correct Responses:\n",
        "    **Examples:**\n",
        "\n",
        "    Customer: \"아이스 아메리카노 한잔 주세요.\"\n",
        "    Correct Natural Language Response: \"아메리카노 1잔 주문되었습니다. 주문하신 내용은 다음과 같습니다:\n",
        "      -아메리카노 1잔(아이스,미디움)\"\n",
        "    Correct JSON Output:\n",
        "      {{\n",
        "           \"action\": \"create_order\",\n",
        "           \"drink\": \"아메리카노\",\n",
        "           \"size\": \"미디움\",\n",
        "           \"temperature\": \"아이스\",\n",
        "           \"quantity\": 1,\n",
        "           \"add_ons\": [],\n",
        "           \"extra_shots\": 0\n",
        "       }}\n",
        "\n",
        "\n",
        "\n",
        "    Based on information above, generate the correct natural language response and JSON output\n",
        "\n",
        "    if  **Current Conversation History**:\n",
        "    {conversation_history}\n",
        "\n",
        "    and **Customer's New Input:** \"{user_input}\".\n",
        "\n",
        "    \"\"\"\n",
        "    return base_prompt\n",
        "\n",
        "# Function to get response from the model\n",
        "def get_model_response(prompt):\n",
        "    response = model(prompt, max_new_tokens=300, truncation=True)[0]['generated_text']\n",
        "\n",
        "    # Parsing to get the expected response parts\n",
        "    try:\n",
        "        natural_response, json_response = response.split(\"JSON Output:\", 1)\n",
        "    except ValueError:\n",
        "        natural_response, json_response = \"Error: Invalid response format\", \"{}\"\n",
        "    return natural_response.strip(), json_response.strip()\n",
        "\n",
        "# Interaction loop to keep track of orders\n",
        "while True:\n",
        "    user_input = input(\"Customer: \")\n",
        "\n",
        "    # Generate prompt with conversation history\n",
        "    prompt = generate_prompt(conversation_history, user_input)\n",
        "\n",
        "    # Get the response from the model\n",
        "    natural_response, json_response = get_model_response(prompt)\n",
        "\n",
        "    # Update conversation history with the customer's input and the model's response\n",
        "    conversation_history += f\"\\nCustomer's {input_counter} Input: {user_input}\"\n",
        "    input_counter += 1  # Increment counter for the next input\n",
        "\n",
        "    # Print current response\n",
        "    print(f\"Model Response: {natural_response}\")\n",
        "    print(f\"JSON Output: {json_response}\")\n",
        "\n",
        "    # Break the loop if the customer confirms the order\n",
        "    if \"주문 완료\" in user_input:\n",
        "        print(\"Order confirmed. Thank you!\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEYW1GEhK6e5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}